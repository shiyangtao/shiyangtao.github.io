<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《趣谈网络协议》笔记]]></title>
    <url>%2F2019%2F08%2F14%2F%E3%80%8A%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ifconfig 和 ip addr的区别]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F14%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8Bhashmap%E6%AD%BB%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[title: 多线程下hashmap死循环tags: java并发编程 java基础 ‘’categories: []author: ‘’date: 2019-02-16 12:40:00 问题由于HashMap并非是线程安全的，所以在高并发的情况下必然会出现问题，可能发生死循环，导致cpu100%，服务重启之后，问题消失，过段时间可能又复现了。这是为什么 原因分析在了解来龙去脉之前，我们先看看HashMap的数据结构。在内部，HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，算法很简单，根据key的hash值，对数组的大小取模 hash &amp; (length-1)，并把结果插入数组该位置，如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。 实现HashMap的put方法实现： 判断key是否已经存在123456789101112131415161718192021public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); // 如果key已经存在，则替换value，并返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // key不存在，则插入新的元素 addEntry(hash, key, value, i); return null;&#125; 检查容量是否达到阈值threshold123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 复制代码如果元素个数已经达到阈值，则扩容，并把原来的元素移动过去。 扩容实现1234567891011void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; ... Entry[] newTable = new Entry[newCapacity]; ... transfer(newTable, rehash); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 这里会新建一个更大的数组，并通过transfer方法，移动元素。123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 移动的逻辑也很清晰，遍历原来table中每个位置的链表，并对每个元素进行重新hash，在新的newTable找到归宿，并插入。 案例分析假设HashMap初始化大小为4，插入个3节点，不巧的是，这3个节点都hash到同一个位置，如果按照默认的负载因子的话，插入第3个节点就会扩容，为了验证效果，假设负载因子是1.123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 以上是节点移动的相关逻辑。 两个线程同时rehash插入第4个节点时，发生rehash，假设现在有两个线程同时进行，线程1和线程2，两个线程都会新建新的数组。 线程2Block线程1继续执行假设 线程2 在执行到Entry&lt;K,V&gt; next = e.next;之后，cpu时间片用完了，这时变量e指向节点a，变量next指向节点b。线程1继续执行，很不巧，a、b、c节点rehash之后又是在同一个位置7，开始移动节点第一步，移动节点a 第二步，移动节点b 注意，这里的顺序是反过来的，继续移动节点c 线程1Block线程2开始执行这个时候 线程1 的时间片用完，内部的table还没有设置成新的newTable， 线程2 开始执行，这时内部的引用关系如下： 线程2继续循环剩余逻辑这时，在 线程2 中，变量e指向节点a，变量next指向节点b，开始执行循环体的剩余逻辑。12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行之后的引用关系如下图执行后，变量e指向节点b，因为e不是null，则继续执行循环体 线程2第二次循环12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行后的引用关系 变量e又重新指回节点a，只能继续执行循环体 线程2第三次循环(出现环)12345678// 目前节点a没有next，所以变量next指向null；Entry&lt;K,V&gt; next = e.next;// 其中 newTable[i] 指向节点b，那就是把a的next指向了节点b，这样a和b就相互引用了，形成了一个环e.next = newTable[i]; // 把节点a放到了数组i位置；newTable[i] = e // 把变量e赋值为null，因为第一步中变量next就是指向null；e = next; 所以最终的引用关系是这样的： 节点a和b互相引用，形成了一个环，当在数组该位置get寻找对应的key时，就发生了死循环。另外，如果线程2把newTable设置成到内部的table，节点c的数据就丢了，看来还有数据遗失的问题。 总结所以在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。 文章参考 占小狼和coolshell的博客]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F02%2F14%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[title: ThreadLocalauthor: sytaotags: java基础 ‘’categories: []date: 2019-02-13 17:42:00 ThreadLocal是什么jdk文档介绍1234567891011121314/** * This class provides thread-local variables. These variables differ from * their normal counterparts in that each thread that accesses one (via its * &#123;@code get&#125; or &#123;@code set&#125; method) has its own, independently initialized * copy of the variable. &#123;@code ThreadLocal&#125; instances are typically private * static fields in classes that wish to associate state with a thread (e.g., * a user ID or Transaction ID). * * &lt;p&gt;For example, the class below generates unique identifiers local to each * thread. * A thread's id is assigned the first time it invokes &#123;@code ThreadId.get()&#125; * and remains unchanged on subsequent calls. */ 结合我的总结可以这样理解：ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离～。简要言之：往ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是隔离的。 作用是什么从上面可以得出：ThreadLocal可以让我们拥有当前线程的变量，那这个作用有什么用呢？？？最常见的ThreadLocal使用场景为用来解决 数据库连接、Session管理、避免一些参数传递等例如12345678910private static ThreadLocal&lt;Connection&gt; connectionHolder= new ThreadLocal&lt;Connection&gt;() &#123;public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL);&#125;&#125;; public static Connection getConnection() &#123;return connectionHolder.get();&#125; 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 实现原理Thread、ThreadLocal、ThreadLocalMap、Entry之间的关系 ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。 也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 ThreadLocalMap由一个个Entry对象构成，Entry的代码如下：12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;，一个Entry由ThreadLocal对象和Object构成。由此可见，Entry的key是ThreadLocal对象，并且是一个弱引用。当没指向key的强引用后，该key就会被垃圾收集器回收。 那么，ThreadLocal是如何工作的呢？下面来看set和get方法。1234567891011121314151617181920212223242526public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; ThreadLocal为什么会内存泄漏ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话(比如线程池线程循环利用)，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal有外部强引用，延长了ThreadLocal的生命周期，可能导致的内存泄漏 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。(虽然ThreadLocal回收了但是value没有被回收) 为什么使用弱引用从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.为了应对非常大和长时间的用途，哈希表使用弱引用的 key。 下面我们分两种情况讨论： key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 避免内存泄漏综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，thread的生命周期很长的情况下，没有及时清理ThreadLocal，导致内存泄漏随着应用运行的时间越来越长会导致内存溢出。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F02%2F01%2F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[title: 链表tags: 数据结构与算法date: 2019-01-29 13:29:25 相比数组，链表是一种稍微复杂一点的数据结构。对于初学者来说，掌握起来也要比数组稍难一些。这两个非常基础、非常常用的数据结构，我们常常将会放到一块儿来比较。所以我们先来看，这两者有什么区别。 链表和数组的区别为了直观地对比，我画了一张图。从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。 单链表我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作“后继指针” 从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址NULL，表示这是链表上最后一个结点。 与数组一样，链表也支持数据的查找、插入和删除操作。 我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 为了方便你理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。 循环链表循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。和单链表相比，循环列表的优点是是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。 双向链表单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。 从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。 你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。我再来带你分析一下链表的两个操作。 删除操作在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中“值等于某个给定值”的结点；这种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。 删除给定指针指向的结点。对于这种种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。你可以参照我刚刚讲过的删除操作自己分析一下。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。 双向循环链表 数组vs链表性能比拼通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。 开发中如何选择不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 我举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？ 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。 链表实现LRU缓存我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果次数据不在链表里 链表满了，删除尾结点，该数据插入头结点 链表还有空间，插入头结点 代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。 实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。 问题数组实现LRU缓存除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？我把这个问题留给你思考。我的思路是这样：维护一个数组，越靠近尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从数组第一个元素开始遍历 如果此数据已经被缓存，我们遍历得到这个数据的下标，并将前面的所有数据都往右移动一位，然后在把该元素放到数据下标0的位置 如果数组不在数组里 数组满了，把最后一个元素之前的元素向右平移一位，最后一个元素自然也就丢弃了，然后把该数据放到下标为0的位置 数组还有空间，把数组里所有元素向右平移一位，然后把该数据放到下标为0的位置代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍数组，所以这种基于数组的实现思路，缓存访问的时间复杂度为 O(n)。 如何判断一个字符串是回文串如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的思题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？我的思路是：使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。最后比较中点两侧的链表是否相等。代码地址 常见单链表编程题 单链表反转 链表中环的检测 两个有序链表合并 删除倒数第n个代码 求链表中间结点代码地址]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F01%2F29%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[title: 数组author: sytaotags: 数据结构与算法categories: []date: 2019-01-29 10:31:00 如何实现随机访问什么是数组？数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 这个定义里有几个关键词 线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。 而与他对立的是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。 连续的内存空间和相同类型的数据正是有了这个特性，他才有了随机访问这个“杀手锏”。但是有利就有弊，比如删除添加为了保证连续性，必须要做数据搬移工作。说到数据的访问，那你知道数组是如何实现根据下标随机访问数组元素的吗？我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址。1a[i]_address = base_address + i * data_type_size 其中data_type_size表示每个元素的大小。我们这个例子数组中存储的是int类型数组，所以date_type_size就为4个字节。这里特别纠正一个“错误”。面试中经常会问到数组和链表的区别，很多人都会回答，“链表适合插入、删除、时间复杂度O(1);数组适合查找，查找时间复杂度为O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但查找时间复杂度不是O(1)。即便是排序好的数组，你用二分查找时间复杂度才是O(logn)。所以正确的表述是数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。 低效的插入和删除前面提到，数组为了保证内存数组连续性，会导致插入、删除两个操作会比较低效。 插入操作假设数组长度为n，现在，需要把一个数据插入到数组第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要把k～n这部分元素都顺序往后挪一下，那时间复杂度是多少呢？如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。如果数组中的数据是有序的，我们在某个位置插入一个新元素，就必须按照刚才的方法搬移k之后的数组。但是如果数组中的数据没有任何规律，数组只是存储集合。在这种情况下，如果把数据插入第k个位置，为了避免大规模搬移，直接将第k个位置的数据插入到数组最后，把新的元素放在第k个位置。如下图所示 利用这个技巧，在特定场景下，在第k个位置插入元素的复杂度就降到了O(1) 删除操作跟插入操作类似，如果删除第k个位置的数据，为了内存连续性，也需要搬移数据，不然会出现空洞，内存就不连续了。和插入类似，如果删除末尾的数据，时间复杂度O(1);如果删除开头的数据，则最坏情况时间复杂度为O(n);平均情况时间复杂度也为O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。 为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。 容器能否代替数组？针对数组类型，很多语言提供了容器类，比如java中的ArrayList。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？因为我是java开发，几乎每天都在用ArrayList。个人觉得ArrayList的最大优势就是可以把很多数组操作的细节封装起来。比如插入、删除、动态扩容。 数组本身在定义时需要预先指定大小，因为需要分配连续的内存空间。乳沟我们申请了大小为10的数组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后在插入新的数据。 如果使用ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList已经帮我们实现好了。每次空间不够时，他都会自动扩容为1.5倍大小。 不过，这里需要注意一点，因为扩容需要内存申请和数据搬移，比较耗时。所以，如果事先能去定需要存储数据的大小，最后在创建ArrayList的时候事先指定数据大小。 作为高级语言编程者，是不是数组就无用武之地了？当然不是，一下情况可以用数组。 Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList array。 我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 为什么大多数编程语言数组下标要从0开始而不是1从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：1a[k]_address = base_address + k * type_size 但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：1a[k]_address = base_address + (k-1)*type_size 对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。 数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。 不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非 0 开始不可。所以我觉得最主要的原因可能是历史原因。 C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F01%2F28%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[title: ‘策略模式’author: sytaotags: 设计模式categories: 设计模式date: 2019-01-26 12:19:00 第一版鸭子游戏我们设计了一个鸭子游戏项目，游戏中会出现各种鸭子，为此Joe实现了一个超类Duck，让鸭子子类都继承这个类，如下图所示。 加鸭子会飞的需求使用继承过了几天主管找到Joe说希望有的鸭子能飞，Joe说so easy，只需在超类里增加一个fly()方法就ok了。但是过了几天主管对外演示时发现，橡皮鸭子在屏幕上飞来飞去，非常尴尬。主管打电话开始喷Joe:你可以去看看boss直聘了。Joe忽略了一件事，并非所有鸭子都会飞，他在超类里加上新的行为，会使得不该拥有这个行为的子类也拥有了这个行为。他体会了一件事：当涉及维护时为了复用目的使用继承结局并不完美。 Joe：那么橡皮鸭子类可以重写这个fly方法里边什么也不做，不就可以了吗？主管：那么所有不能飞的子类都得重写一遍fly，然后如果加入木鸭(不会飞不会叫)，也得把quack()方法重写。Joe意思到继承可能无法解决这个问题： 使用接口Joe：那么可以把fly()和quack()方法从超类里拆出来，只有能飞/能叫的鸭子子类实现这个接口主管：这真是个超级糟糕的设计，如果你认为重写几个方法很差劲，但是48个子类都稍微修改下飞行的行为呢？Joe：我去还真是，虽然Flayable和Quackable能解决一部分问题（不再有会飞的橡皮鸭），但是却造成代码无法复用啊，每个会飞的鸭子子类都得实现一个fly()方法哪怕他们的飞的行为是一样的，如果每个fly方法里增加打印日志得需要改48个子类。那咋办呀？ 设计原则一主管：把问题归零把，下面给你介绍一个设计原则：找出应用中可能需要变化的地方，把他们独立出来，不要在和哪些不变的代码混在一起了，把会变化的代码封装起来，好让其他部分不受影响，代码变化引起的bug变少，系统更加有弹性 下面是这个设计原则的另一种思考方式：“把会变化的部分取出并封装起来，以便以后可以轻易的改动或者扩展此部分，而不影响不需要变化的部分“主管：Joe是时候把鸭子的行为从Duck里行为拆出来了！Joe：ok，那么Duck里的行为除了fly和quack有问题外，其他行为一切还算正常，现在要分开变化部分和不变部分了，我打算建立两组类看图 设计原则二那么如何设计那组实现飞行和呱呱叫的的行为的类呢？我们希望一切能有弹性，毕竟，正是一开始鸭子行为没有弹性，才让我们走上现在这条路。我们还想能够“指定”行为到鸭子的实例。比方说，我们想要产生一个新的绿头鸭的实例，并指定特定的“类型”的飞行行为给它。干脆让鸭子的行为可以动态地改变好了。换句话说，我们应该在鸭子类中包含设定行为的方法，这样就可以在“运行时”动态地“改变”绿头鸭的飞行行为。有了这些目标要实现，接着看看第二个设计原则： 我们利用接口代表每个行为，比方说，FlyBehavior和QuackBehavior接口。所以这次鸭子类不回负责实现Fly与Quack接口，反而是由我们制造一组其他类专门实现FlyBehavior与QuackBehavior,这些就称为“行为”类。 这样的设计，可以让飞行和呱呱叫的动作被其他的对象复用，因为这些行为已经与鸭子类无关了。而我们可以新增一些行为，不会影响到既有的行为类，也不会影响“使用”到飞行行为的鸭子类。这么一来，有了继承的“复用”的好处，却没有继承所带来的包袱。 整合鸭子的行为关键在于，鸭子现在会将飞行和呱呱叫“委托”(delegate)别人处理，而不是定义在Duck类(或子类)内的呱呱叫和飞行方法。 1234567891011public class Duck &#123; //每只鸭子都会引用实现QuackBehavior接口的对象。 QuackBehavior quackBehavior; // 还有更多 ....... //鸭子对象不亲自处理呱呱叫的行为，而是委托给quackBehavior引用的对象 public void performQuack()&#123; quckBehavior.quack(); &#125;&#125; UML图 设计原则三“有一个”可能比“是一个”更好。“有一个”关系相当有趣：每一鸭子都有一个FlyBehavior和一个QuackBehavior，好将飞行和呱呱叫委托给它们代为处理。当你将两个类结合起来使用，如同本例一般，这就是组合(composition)。这种做法和“继承”不同的地方在于，鸭子的行为不是继承来的，而是和适当的行为对像“组合来的”。这是一个很重要的技巧。其实是使用了我们的第三个设计原则：]]></content>
  </entry>
  <entry>
    <title><![CDATA[shell启动socket]]></title>
    <url>%2F2018%2F12%2F03%2Fshell%E5%90%AF%E5%8A%A8socket%2F</url>
    <content type="text"><![CDATA[nc -l localhost 3000 servernc localhost 3000 client]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep]]></title>
    <url>%2F2018%2F11%2F03%2Fgrep%2F</url>
    <content type="text"><![CDATA[grep 后面带上-A -B -C 参数可以多显示几行内容 grep -A 5 可以显示匹配内容以及后面的5行内容grep -B 5 可以显示匹配内容以及前面的5行内容grep -C 5 可以显示匹配内容以及前后面的5行内容 grep “” logfile|wc -l 显示匹配的行数]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在同一个类中，一个方法调用另外一个有注解（比如@Async，@Transational）的方法，注解失效的原因和解决方法]]></title>
    <url>%2F2016%2F12%2F05%2F%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%B8%AD%EF%BC%8C%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E6%9C%89%E6%B3%A8%E8%A7%A3%EF%BC%88%E6%AF%94%E5%A6%82%40Async%EF%BC%8C%40Transational%EF%BC%89%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E6%B3%A8%E8%A7%A3%E5%A4%B1%E6%95%88%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/clementad/article/details/47339519]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2015%2F01%2F31%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[java静态代理和动态代理 代理的优点 职责清晰 真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后期的代理完成一件完成事务，附带的结果就是编程简洁清晰。 代理对象可以在客户端和目标对象之间起到中介的作用，这样起到了中介的作用和保护了目标对象的作用。 高扩展性，可以在代理方法前后增加额外的处理逻辑。 被代理的对象一个接口123public interface Subject &#123; void doSomething();&#125; 它的实现类1234567public class SubjectImpl implements Subject &#123; @Override public void doSomething() &#123; System.out.println( "call doSomething()" ); &#125;&#125; 静态代理静态代理是由程序员创建或工具生成代理类的源码，再编译代理类。也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。缺点是被代理对象和代理紧耦合在一起。而且代理类都是针对被代理类创建的。12345678910public class SubjectProxy implements Subject &#123; Subject subject = new SubjectImpl(); @Override public void doSomething() &#123; System.out.println("before"); //调用目标对象之前可以做相关操作 subject.doSomething(); System.out.println("after");//调用目标对象之后可以做相关操作 &#125;&#125; 动态代理动态代理在运行阶段才指定被代理的对象，通过实现InvocationHandler接口，调用具体的方法。123456789101112131415161718public class ProxyHandler implements InvocationHandler &#123; private Object tar; public Object bind(Object tar) &#123; this.tar = tar; return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; System.out.println("before"); //调用目标对象之前可以做相关操作 result = method.invoke(tar, args); System.out.println("after");//调用目标对象之后可以做相关操作 return result; &#125;&#125; 运行12345678public class Test &#123; public static void main(String[] args) &#123; ProxyHandler proxy = new ProxyHandler(); //绑定该类实现的所有接口 Subject sub = (Subject) proxy.bind(new SubjectImpl()); sub.doSomething(); &#125;&#125;]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
</search>
