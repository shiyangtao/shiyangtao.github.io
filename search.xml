<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2019年度总结·调整心态]]></title>
    <url>%2F2020%2F01%2F10%2F2019%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%C2%B7%E8%B0%83%E6%95%B4%E5%BF%83%E6%80%81%2F</url>
    <content type="text"><![CDATA[从今年开始，我会写年度总结，对比去年的变化，本年的收获和不足，并制定下一年的的计划。 2019年感觉对我是比较关键的一年，工作方面晋升到下一等级，个人成长方面一直在不断努力，虽然收效甚微，但是万事开头难，做总是比不做强，我相信坚持下去总会有收获。 2019年总结主要是心态的转变，下面是心态转变的几个阶段。 盲目追新名词2017-2019，好多新名词层出不穷，人工智能、区块链、k8s容器化，然后自己的内心也跟着着急起来。想着与时俱进，自己想着赶紧学点啥，然后购买了极客时间的《区块链课程》，看的时候感觉太难了，各种没听过的算法，中途放弃，进入自我怀疑的心态。然后受某个大佬的博客启发，不要盲目追新技术，新技术万变不离其宗，都是基础知识加上新的理念构成。文中有这么一句话，基础扎实的人可能很快掌握这种新技术，但是为了学新名词的菜鸟可能得花上几个月的时间，所以菜鸟要追新技术太难了，成本太高了。不如回归基础。 莫以浮沙筑高楼受到上述启发后，制定了一些针对基础知识的专项训练。包括计算机网络、算法、linux操作系统、网络编程等方面的计划。2019年基本完成了计算机网络的学习，对于TCP协议有了清晰的认识，由当时只了解为了应付面试的三次握手四次挥手，到了解了重传策略、流控制、拥塞控制、keepalive，并用wireshark分析报文。 这个过程的不足 贪多这个阶段效率确实比较低，因为我学新知识点有个毛病，总是想把关于这个知识点的所有书籍和专栏都看一遍。所以关于计算机网络，我看了极客时间的专栏《趣谈网络协议》和正在看的专栏《Web协议详解与抓包实战》，看了书籍《网络是怎样连接的》、《图解TCP/IP》。所以这个基础知识大概进行了5个月，目前还未完结。 缺少好的学习习惯学的过程不爱记笔记总结，所以基本看完一个专栏或书籍，就忘了，然后就有个重新在读一遍的念头闪现出来，然后整个人就开始浮躁，感觉进入了一怪圈里边，心里想着放弃吧，又不甘心。所以学习过程比较痛苦，这也是效率不高的一个原因。 浮躁这一年自己一直以一种特别浮躁的心态来学东西，总是感觉要学的东西太多了，所以比较着急。举个例子，因为技术好多层次都是相关的，比如今天看到一个知识点，里边有另一个领域的一个知识点，我就会顺藤摸瓜的去学另外一个知识点，然后又发现另外一个知识点…，这样层层追溯下去，自己把自己逼得放弃了，会很苦恼。时间花了不少，因为学习过程是一个不断自我否定的过程，最后自己放弃了。 以上不足归结到一点还是浮躁。虽然每次都想到放弃，但是值得欣慰的一点是自己2019年没有放弃。因为听到过一句话，大概是这样「平庸的人和优秀的人都会遇到类似问题，但是优秀的人会去总结，然后调整策略继续投入进去，平庸的人到这里就结束了。」 摆正心态根据上述不足，自己复盘反思了下，觉得自己并不是学习意念不够强烈，而是心态不对。 不浮躁：学习是一个循序渐进的过程，有一个好心态，能事半功倍 学习方法论：养成好的学习习惯，学完一个知识点，要整理学习笔记，不要怕花时间，经常反思，要借鉴别人的学习方法。 不急功近利：从2017年到2019年经历了立志-放弃-立志-放弃的n次循环后，往往都是不断的自我怀疑和自我否定占据上风，这种想法一直在提醒我，你差的太多了，补起来无从下手，在这种思想压力下自己索性就放弃了。2019年我坚持下来了，因为当你前面敌人太多的时候，你总要挑一个下手，收拾完一个，就会有信心收拾另外一个，而不是因为敌人多而停止脚步。 2020年展望作为一个码农，技术是安身立命之根本，所以优先从技术层面开始。因为自己达不到程序员的标准，所以姑且认为自己就是个码农吧。 技术编程能力由于上级人事变动，新来的leader更关注写代码的能力，而自己之前的观点是「能完成功能是主要的，代码可以适当抽象，不必过分较真」。但是这个观点是错误的，质量好的代码，能避免好多问题。 编程能力是软件工程师最重要的能力，很多工程师在讨论分布式、高可用系统时都能把别人说的一愣一愣的，张嘴闭嘴就是五个九的可用性，异地多活，但是一旦落到编程能力上，实现一个小功能都能漏洞百出，更不用说写出真正高可用的系统了。 今年要提升代码抽象能力，计划阅读相关书籍《Clean Code》和《Head First 设计模式》，多看成熟框架的源码。工作中的编码任务，要仔细推敲，好好抽象，不能为了完成任务而糊弄。 架构能力2019年阅读了极客时间的专栏《从0开始学架构》、《从0开始学微服务》、《微服务架构核心20讲》、《微服务架构实战160讲》和书籍《大型网站技术架构》，因为没有实际参与过架构设计，但是看了这些专栏和书籍，对架构和微服务有了一些浅显的认知。2020年希望能结合公司目前的架构设计，加深对架构的理解。 技术栈2019年基本没有接触其他技术栈。2020年还是以巩固基础能力为主，其他技术栈也可以适当了解。 2020年会看《Java核心技术 卷一》等Java基础书籍，关于新技术栈目前对容齐比较感兴趣，希望系统的了解下Kubernetes领域。 软能力沟通一个好的程序员，需要有好的学习能力，这样你才能为成为技术专家，但是，你还要有好的沟通能力，不然你的技术能力发挥不出来。就像一棵大树一样，学习能力能让你根越来越深，无论遇到什么狂风暴雨，你都可以屹立不倒，而沟通能力则是树干和树叶，它们能让你延伸到更远的天空。 自己沟通能力欠佳，逻辑有时会混乱，容易激动，语速加快，不能很准确的表达出心里的想法。 2020年会看下《简单的逻辑学》和《金字塔理论》，并在沟通的时候有意的注意下以上问题。 写作能力今年感觉自己基本没有写作能力和画技术流程图、架构图的能力，把技术方案输出为文档能力很差。 2020年会着重注意这个问题。 英语搜索尽量google，经常看下medium里的文章。 总结2020年，自己会调整好心态，一步一个脚印，积少成多。浮躁的时候，要多想想这句话「学习是一辈子的事，没有速成」。带着浮躁的心态学习，过程很痛苦，而且最后收获很少。所以2020会从以下几个方面入手 端正学习态度，摆正心态 在实践中总结出适合自己的学习方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[TCP协议详解]]></title>
    <url>%2F2020%2F01%2F10%2FTCP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"></content>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《趣谈网络协议》云计算中的网络24-28]]></title>
    <url>%2F2019%2F11%2F01%2F%E3%80%8A%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E3%80%8B%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C24-28%2F</url>
    <content type="text"><![CDATA[虚拟网卡的原理 虚拟机互联在物理机上，应该有一个虚拟的交换机，在 Linux 上有一个命令叫作 brctl，可以创建虚拟的网桥 brctl addbr br0。创建出来以后，将两个虚拟机的虚拟网卡，都连接到虚拟网桥 brctl addif br0 tap0 上，这样将两个虚拟机配置相同的子网网段，两台虚拟机就能够相互通信了。 这里面，host-only 的网络对应的，其实就是上面两个虚拟机连到一个 br0 虚拟网桥上，而且不考虑访问外部的场景，只要虚拟机之间能够相互访问就可以了。 虚拟机连接外网 桥接 虚拟交换机就是br0 如果使用桥接网络，当你登录虚拟机里看 IP 地址的时候会发现，你的虚拟机的地址和你的笔记本电脑的，以及你旁边的同事的电脑的网段是一个网段。这是为什么呢？这其实相当于将物理机和虚拟机放在同一个网桥上，相当于这个网桥上有三台机器，是一个网段的，全部打平了。我将图画成下面的样子你就好理解了。 在数据中心里面，采取的也是类似的技术，只不过都是 Linux，在每台机器上都创建网桥 br0，虚拟机的网卡都连到 br0 上，物理网卡也连到 br0 上，所有的 br0 都通过物理网卡出来连接到物理交换机上。 同样我们换一个角度看待这个拓扑图。同样是将网络打平，虚拟机会和你的物理网络具有相同的网段。 在这种方式下，不但解决了同一台机器的互通问题，也解决了跨物理机的互通问题，因为都在一个二层网络里面，彼此用相同的网段访问就可以了。但是当规模很大的时候，会存在问题。你还记得吗？在一个二层网络里面，最大的问题是广播。 NAT 在这种方式下，你登录到虚拟机里面查看 IP 地址，会发现虚拟机的网络是虚拟机的，物理机的网络是物理机的，两个不相同。虚拟机要想访问物理机的时候，需要将地址 NAT 成为物理机的地址。 除此之外，它还会在你的笔记本电脑里内置一个 DHCP 服务器，为笔记本电脑上的虚拟机动态分配 IP 地址。因为虚拟机的网络自成体系，需要进行 IP 管理。为什么桥接方式不需要呢？因为桥接将网络打平了，虚拟机的 IP 地址应该由物理网络的 DHCP 服务器分配。 如果是你自己登录到物理机上做个简单配置，你可以简化一下。例如将虚拟机所在网络的网关的地址直接配置到 br0 上，不用 DHCP Server，手动配置每台虚拟机的 IP 地址，通过命令 iptables -t nat -A POSTROUTING -o ethX -j MASQUERADE，直接在物理网卡 ethX 上进行 NAT，所有从这个网卡出去的包都 NAT 成这个网卡的地址。通过设置 net.ipv4.ip_forward = 1，开启物理机的转发功能，直接做路由器，而不用单独的路由器，这样虚拟机就能直接上网了 隔离问题如果一台机器上的两个虚拟机不属于同一个用户，怎么办呢？ 好在 brctl 创建的网桥也是支持 VLAN 功能的，可以设置两个虚拟机的 tag，这样在这个虚拟网桥上，两个虚拟机是不互通的。 但是如何跨物理机互通，并且实现 VLAN 的隔离呢？由于 brctl 创建的网桥上面的 tag 是没办法在网桥之外的范围内起作用的，于是我们需要寻找其他的方式。有一个命令vconfig可以基于物理网卡 eth0 创建带 VLAN 的虚拟网卡，所有从这个虚拟网卡出去的包，都带这个 VLAN，如果这样，跨物理机的互通和隔离就可以通过这个网卡来实现。 首先为每个用户分配不同的 VLAN，例如有一个用户 VLAN 10，一个用户 VLAN 20。 在一台物理机上，基于物理网卡，为每个用户用 vconfig 创建一个带 VLAN 的网卡。 不同的用户使用不同的虚拟网桥，带 VLAN 的虚拟网卡也连接到虚拟网桥上。 不同的用户由于网桥不通，不能相互通信，一旦出了网桥，由于 VLAN 不同，也不会将包转发到另一个网桥上。另外，出了物理机，也是带着 VLAN ID 的。只要物理交换机也是支持 VLAN 的，到达另一台物理机的时候，VLAN ID 依然在，它只会将包转发给相同 VLAN 的网卡和网桥，所以跨物理机，不同的 VLAN 也不会相互通信。 缺点： 使用 brctl 创建出来的网桥功能是简单的，基于 VLAN 的虚拟网卡也能实现简单的隔离。但是这都不是大规模云平台能够满足的，一个是 VLAN 的隔离，数目太少。前面我们学过，VLAN ID 只有 4096 个，明显不够用。另外一点是这个配置不够灵活。谁和谁通，谁和谁不通，流量的隔离也没有实现，还有大量改进的空间。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《趣谈网络协议》第14-23讲笔记]]></title>
    <url>%2F2019%2F10%2F25%2F%E3%80%8A%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E3%80%8B%E7%AC%AC14-23%E8%AE%B2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[HTTP 协议虽然很常用，也很复杂，重点记住 GET、POST、 PUT、DELETE 这几个方法，以及重要的首部字段； HTTP2.0HTTP 2.0 通过头压缩、分帧、二进制编码、多路复用等技术提升性能； 相比HTTP1.1的优点HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value 在两端建立一个索引表，对相同的头只发送索引表中的索引 HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的 HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header 帧，用于传输 Header 内容，并且会开启一个新的流。再就是Data 帧，用来传输正文实体。多个 Data 帧属于同一个流。 通过以上两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。 我们来举一个例子。假设我们的一个页面要发送三个独立的请求，一个获取 css，一个获取 js，一个获取图片 jpg。如果使用 HTTP 1.1 就是串行的，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。 HTTP 2.0 其实是将三个请求变成三个流，将数据分成帧，乱序发送到一个 TCP 连接中。 HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应，减少了 TCP 连接数对服务器性能的影响。同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。 不足HTTP 2.0 虽然大大增加了并发性，但还是有问题的。因为 HTTP 2.0 也是基于 TCP 协议的，TCP 协议在处理包时是有严格顺序的。当其中一个数据包遇到问题，TCP 连接需要等待这个包完成重传之后才能继续进行。虽然 HTTP 2.0 通过多个 stream，使得逻辑上一个 TCP 连接上的并行内容，进行多路数据的传输，并且这些数据没有关联。一前一后，前面 stream 2 的帧没有收到，后面 stream 1 的帧也会因此阻塞。 QUIC于是，就又到了从 TCP 切换到 UDP。这就是 Google 的 QUIC 协议。 QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。 HTTPS加密分对称加密和非对称加密。对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高。 非对称加密需要通过证书和权威机构来验证公钥的合法性。 HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证传输安全，也保证传输效率。 FTP下载FTP 采用两个 TCP 连接来传输一个文件。 控制连接：服务器以被动的方式，打开众所周知用于 FTP 的端口 21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。常用的命令有：list——获取文件目录；reter——取一个文件；store——存一个文件。 数据连接：每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。 FTP两种工作模式 主动模式(PORT) 主动模式是FTP客户端向FTP服务器发送数据传输需要的端口，FTP服务端去连接FTP客户端的端口。 被动模式(PASV) 被动模式是FTP服务器返回数据传输需要的端口，FTP客户端去连接FTP服务端。绝大部分的互联网应用(比如Web/Http)，都是客户端向服务端发起连接。换句话说，绝大部分互联网应用都是被动模式。 需要注意的是，被动模式和主动模式的登录过程，都是FTP客户端去连接FTP服务器。 为什么绝大部分互联网应用都是被动模式因为大部分客户端都是在路由器后面，没有独立的公网IP地址，服务器想要主动连接客户端，难度太大，在现在真实的互联网环境里面几乎是不可能完成的任务。 P2P种子文件(.torrent)由两部分组成，分别是：announce（tracker URL）和文件信息。 文件信息里面有这些内容。 info 区：这里指定的是该种子有几个文件、文件有多长、目录结构，以及目录和文件的名字。 Name 字段：指定顶层目录名字。 每个段的大小：BitTorrent（简称 BT）协议把一个文件分成很多个小段，然后分段下载。 段哈希值：将整个种子中，每个段的 SHA-1 哈希值拼在一起 下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 tracker 服务器。tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。 虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。所以，这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了。能不能彻底非中心化呢？请看DHT 去中心化网络(DHT)DHT(Distributed Hash Table) 有一种著名的 DHT 协议，叫 Kademlia 协议，接下来要介绍的就是这个协议。 任何一个BitTorrent启动后，都有两个角色 peer角色 监听TCP端口，用来上传下载文件。 DHT node 监听一个UDP端口，通过这个角色加入DHT网络 存储和定位一个DHT网络里，每一个DHT Node，都有一个id，每个DHT都保存有一些索引，哪些文件保存在哪个节点上。 算法规定，如果有文件的哈希值和DHT node的id一致，则这个DHT node知道从哪里下载，除了一模一样的DHT node知道，和哈希值接近的N个DHT node也知道。什么叫和哈希值接近呢？例如只修改了最后一位，就很接近；修改了倒数 2 位，也不远；修改了倒数 3 位，也可以接受。总之，凑齐了规定的 N 这个数就行。 如何找到对应的NODE呢分层 如果一个节点的 ID，前面所有位数相同，从倒数第 i 位开始不同，这样的节点只有 2^(i-1) 个，与基础节点的距离范围为 [2^(i-1), 2^i)；对于 01010 而言，这样的节点归为“k-bucket i”。 查找判断目标节点C与自己从倒数第i几位开始不同，然后从“k-bucket i”中去找，这一层所有NODE的第i位肯定和A的第i位不一样 如果有，那就找到了； 如果没有，在k-bucket i里随便找一个B节点（注意任意B节点，它的第i位肯定与C相同，即它与C的距离小于 2^(i-1)，距离缩短了一半，Kademlia 的这种查询机制，是通过折半查找的方式来收缩范围，对于总的节点数目为 N，最多只需要查询 log2(N) 次，就能够找到。） Kademlia 算法中，每个节点只有 4 个指令。 PING：测试一个节点是否在线，还活着没，相当于打个电话，看还能打通不。 STORE：要求一个节点存储一份数据，既然加入了组织，有义务保存一份数据。 FIND_NODE：根据节点 ID 查找一个节点，就是给一个 160 位的 ID，通过上面朋友圈的方式找到那个节点。 FIND_VALUE：根据 KEY 查找一个数据，实则上跟 FIND_NODE 非常类似。KEY 就是文件对应的 160 位的 ID，就是要找到保存了文件的节点。 k-bucket的维护及更新机制 每个bucket里的节点都按照最后一次接触的时间倒序排列(按最后一次接触时间从末尾往开头排序) 每次执行四个指令的任何一个都会触发更新 当一个节点与自己接触时，检查它是否在K-bucket中 –如果在，那么将它挪到k-bucket列表最底层（最新） –如果不在，PING一下列表最上面（最旧）的一个节点 –a）如果PING通，将旧节点挪到列表最底，并丢弃新节点 –b）如果PING不通，删除旧节点，并将新节点加入列表 该机制保证了任意节点加入和离开都不影响整体网络 易懂分布式 | Kademlia算法 DNS 传统的 DNS 有很多问题，例如解析慢、更新不及时。因为缓存、转发、NAT 问题导致客户端误会自己所在的位置和运营商，从而影响流量的调度。 HTTPDNS 通过客户端 SDK 和服务端，通过 HTTP 直接调用解析 DNS 的方式，绕过了传统 DNS 的这些缺点，实现了智能的调度 CDN CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，而数据缓存在离用户最近的位置。 CDN 最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。它也支持动态数据的缓存，一种是边缘计算的生鲜超市模式，另一种是链路优化的冷链运输模式。 VPN连接多个数据中心的方式： 走公网，最简单但不安全 专线连接，成本高昂，效率高 VPN 连接，简单便宜，保证私密性，性能稍差 IPSec VPN「Virtual Private Network」工作原理：将要发送的 IP 包「乘客协议」加密后加上 IPSec 包头「隧道协议」后再放入另一个 IP 包「承载协议」中发送 IPSec VPN 是基于 IP 协议的安全隧道协议，采用一些机制保证安全性 私密性：加密数据 完整性：对数据进行 hash 运算产生数据摘要 真实性：通过身份认证保证对端身份的真实性 IPSec VPN 协议簇包括： 两种协议： AH「Authentication Header」：只能进行数据摘要，不能实现数据加密 ESP「Encapsulating Security Payload」：能够进行数据加密和数据摘要 两种算法： 加密算法 摘要算法 两大组件： IKE「Internet Key Exchange Key Management」：用于交换对称秘钥 SA「Security Association」：进行连接维护 IPsec VPN 的建立过程： 建立 IKE 自己的 SA，算出对称秘钥 K 使用对称秘钥 K 建立 IPSec SA，在 SA 中生成随机对称秘钥 M，使用 M 进行双方接下来的通信 扩展IP 协议：不是面向连接的，是尽力而为的协议，每个 IP 包自由选择路径，依赖于上一层 TCP 的重发来保证可靠性 优点：一条道路崩溃时，可以自动换其他路 缺点：不断的路由查找，效率低下 IPSec VPN 的缺点：由于 IPSec VPN 是基于 IP 协议的，所以速度慢 ATM 协议：这种协议是面向连接的，并且和 IP 是同一个层次，ATM 是在传输之前先建立一个连接，形成一个虚拟的通路 优点：速度快，因为按照指定路径传输 缺点：当某个节点故障，连接就会中断，无法传输数据 多协议标签交换「MPLS，Multi-Protocol Label Switching」结合了 IP 和 ATM 协议的优点 需要标签交换路由器「LSR，Label Switching Router」的支持 如何动态生成标签 LDP「Label Distribution Protocol」 将 MPLS 和 VPN 结合起来可以提高 VPN 的效率需要解决的问题有： BGP 协议如何处理地址空间重叠的 VPN 的路由 路由表怎么区分重复的网段 移动网络手机是通过收发无线信号来通信的，专业名称是 Mobile Station，简称 MS，需要嵌入 SIM。手机是客户端，而无线信号的服务端，就是基站子系统（BSS，Base Station SubsystemBSS） 2G2G 时代，上网使用的不是 IP 网络，而是电话网络，走模拟信号，专业名称为公共交换电话网（PSTN，Public Switched Telephone Network）。 基站子系统分两部分，一部分对外提供无线通信，叫作基站收发信台（BTS，Base Transceiver Station），另一部分对内连接有线网络，叫作基站控制器（BSC，Base Station Controller）。基站收发信台通过无线收到数据后，转发给基站控制器。这部分属于无线的部分，统称为无线接入网（RAN，Radio Access Network）。 基站控制器通过有线网络，连接到提供手机业务的运营商的数据中心，这部分称为核心网（CN，Core Network）。核心网还没有真的进入互联网，这部分还是主要提供手机业务，是手机业务的有线部分。 首先接待基站来的数据的是移动业务交换中心（MSC，Mobile Service Switching Center），它是进入核心网的入口。 鉴权中心（AUC，Authentication Center）和设备识别寄存器（EIR，Equipment Identity Register）主要是负责安全性的 另外，需要看你是本地的号，还是外地的号，这个牵扯到计费的问题，异地收费还是很贵的。访问位置寄存器（VLR，Visit Location Register）是看你目前在的地方，归属位置寄存器（HLR，Home Location Register）是看你的号码归属地。 网关移动交换中心（GMSC ，Gateway Mobile Switching Center）是一个网关，连接核心网和真正的互联网。 数据中心里面的这些模块统称为网络子系统（NSS，Network and Switching Subsystem） 因而 2G 时代的上网如图所示，我们总结一下，有这几个核心点： 手机通过无线信号连接基站； 基站一面朝前接无线，一面朝后接核心网； 核心网一面朝前接到基站请求，一是判断你是否合法，二是判断你是不是本地号，还有没有钱，一面通过网关连接电话网络。 2.5G 相对2G网络的变化： 原来电路交换的基础上，加入了分组交换业务，支持 Packet 的转发，从而支持 IP 网络。** 在上述网络的基础上，基站一面朝前接无线，一面朝后接核心网。在朝后的组件中，多了一个分组控制单元（PCU，Packet Control Unit），用以提供分组交换通道。 在核心网里面，有个朝前的接待员（SGSN，Service GPRS Supported Node）和朝后连接 IP 网络的网关型 GPRS 支持节点（GGSN，Gateway GPRS Supported Node）。 3G 到了 3G 时代，主要是无线通信技术有了改进，大大增加了无线的带宽。以 W-CDMA 为例，理论最高 2M 的下行速度。 改变： 基站改变了，一面朝外的是 Node B，一面朝内连接核心网的是无线网络控制器（RNC，Radio Network Controller）。 核心网以及连接的 IP 网络没有什么变化。 4G 4G 网络，基站为 eNodeB，包含了原来 Node B 和 RNC 的功能，下行速度向百兆级别迈进。另外，核心网实现了控制面和数据面的分离。 在前面的核心网里面，有接待员 MSC 或者 SGSN，你会发现检查是否合法是它负责，转发数据也是它负责，也即控制面和数据面是合二为一的，这样灵活性比较差，因为控制面主要是指令，多是小包，往往需要高的及时性；数据面主要是流量，多是大包，往往需要吞吐量。 HSS 用于存储用户签约信息的数据库，其实就是你这个号码归属地是哪里的，以及一些认证信息。MME 是核心控制网元，是控制面的核心，当手机通过 eNodeB 连上的时候，MME 会根据 HSS 的信息，判断你是否合法。如果允许连上来，MME 不负责具体的数据的流量，而是 MME 会选择数据面的SGW 和 PGW，然后告诉 eNodeB，我允许你连上来了，你连接它们吧。于是手机直接通过 eNodeB 连接 SGW，连上核心网，SGW 相当于数据面的接待员，并通过 PGW 连到 IP 网络。PGW 就是出口网关。在出口网关，有一个组件 PCRF，称为策略和计费控制单元，用来控制上网策略和流量的计费。 4G网络协议解析 控制面协议 eNodeB 还是两面派，朝前对接无线网络，朝后对接核心网络，在控制面对接的是 MME。 eNodeB 和 MME 之间的连接就是很正常的 IP 网络，但是这里面在 IP 层之上，却既不是 TCP，也不是 UDP，而是 SCTP。这也是传输层的协议，也是面向连接的，但是更加适合移动网络。 它继承了 TCP 较为完善的拥塞控制并改进 TCP 的一些不足之处。 SCTP优势： 多宿主（Multi-homing） 多流（Multi-streaming） 初始化保护（Initiation protection） 消息分帧（Message framing） 可配置的无序发送（Configurable unordered delivery） 平滑关闭（Graceful shutdown） 参考链接使用 SCTP 优化网络 当 MME 通过认证鉴权，同意这个手机上网的时候，需要建立一个数据面的数据通路。建立通路的过程还是控制面的事情，因而使用的是控制面的协议 GTP-C。GTP-C是基于UDP的，GTP有序列号，所以不用 TCP，GTP-C 自己就可以实现可靠性，为每个输出信令消息分配一个依次递增的序列号，以确保信令消息的按序传递，并便于检测重复包。对于每个输出信令消息启动定时器，在定时器超时前未接收到响应消息则进行重发。 建设的数据通路分两段路，其实是两个隧道。 一段是从 eNodeB 到 SGW，这个数据通路由 MME 通过 S1-MME 协议告诉 eNodeB，它是隧道的一端，通过 S11 告诉 SGW，它是隧道的另一端。 第二端是从 SGW 到 PGW，SGW 通过 S11 协议知道自己是其中一端，并主动通过 S5 协议，告诉 PGW 它是隧道的另一端。 数据面协议当两个隧道都打通，接在一起的时候，PGW 会给手机分配一个 IP 地址，这个 IP 地址是隧道内部的 IP 地址，可以类比为 IPsec 协议里面的 IP 地址。这个 IP 地址是归手机运营商管理的。然后，手机可以使用这个 IP 地址，连接 eNodeB，从 eNodeB 经过 S1-U 协议，通过第一段隧道到达 SGW，再从 SGW 经过 S8 协议，通过第二段隧道到达 PGW，然后通过 PGW 连接到互联网。数据面的协议都是通过 GTP-U，如图所示。 手机每发出的一个包，都由 GTP-U 隧道协议封装起来，格式如下。 手机上网流程 手机开机以后，在附近寻找基站 eNodeB，找到后给 eNodeB 发送 Attach Request，说“我来啦，我要上网”。 eNodeB 将请求发给 MME，说“有个手机要上网”。 MME 去请求手机，一是认证，二是鉴权，还会请求 HSS 看看有没有钱，看看是在哪里上网。 当 MME 通过了手机的认证之后，开始分配隧道，先告诉 SGW，说要创建一个会话（Create Session）。在这里面，会给 SGW 分配一个隧道 ID t1，并且请求 SGW 给自己（MME）也分配一个隧道 ID。 SGW 转头向 PGW 请求建立一个会话，为 PGW 的控制面分配一个隧道 ID t2，也给 PGW 的数据面分配一个隧道 ID t3，并且请求 PGW 给自己（SGW）的控制面和数据面分配隧道 ID。 PGW 回复 SGW 说“创建会话成功”，使用自己的控制面隧道 ID t2，回复里面携带着给 SGW 控制面分配的隧道 ID t4 和控制面的隧道 ID t5，至此 SGW 和 PGW 直接的隧道建设完成。双方请求对方，都要带着对方给自己分配的隧道 ID，从而标志是这个手机的请求。 接下来 SGW 回复 MME 说“创建会话成功”，使用自己的隧道 ID t1 访问 MME，回复里面有给 MME 分配隧道 ID t6，也有 SGW 给 eNodeB 分配的隧道 ID t7。 当 MME 发现后面的隧道都建设成功之后，就告诉 eNodeB，“后面的隧道已经建设完毕，SGW 给你分配的隧道 ID 是 t7，你可以开始连上来了，但是你也要给 SGW 分配一个隧道 ID”。 eNodeB 告诉 MME 自己给 SGW 分配一个隧道，ID 为 t8。 MME 将 eNodeB 给 SGW 分配的隧道 ID t8 告知 SGW，从而前面的隧道也建设完毕 这样，手机就可以通过建立的隧道成功上网了。 为什么你的手机在国外上不了facebook为什么要分 SGW 和 PGW 呢，一个 GW 不可以吗？SGW 是你本地的运营商的设备，而 PGW 是你所属的运营商的设备。 如果你在巴塞罗那，一下飞机，手机开机，周围搜寻到的肯定是巴塞罗那的 eNodeB。通过 MME 去查寻国内运营商的 HSS，看你是否合法，是否还有钱。如果允许上网，你的手机和巴塞罗那的 SGW 会建立一个隧道，然后巴塞罗那的 SGW 和国内运营商的 PGW 建立一个隧道，然后通过国内运营商的 PGW 上网。 这样判断你是否能上网的在国内运营商的 HSS，控制你上网策略的是国内运营商的 PCRF，给手机分配的 IP 地址也是国内运营商的 PGW 负责的，给手机分配的 IP 地址也是国内运营商里统计的。运营商由于是在 PGW 里面统计的，这样你的上网流量全部通过国内运营商即可，只不过巴塞罗那运营商也要和国内运营商进行流量结算。由于你的上网策略是由国内运营商在 PCRF 中控制的，因而你还是上不了脸书。]]></content>
  </entry>
  <entry>
    <title><![CDATA[《图解TCP/IP》笔记]]></title>
    <url>%2F2019%2F09%2F19%2F%E3%80%8A%E5%9B%BE%E8%A7%A3TCP-IP%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[中继器到底能否完成不同媒介之间的转接工作？《图解TCP/IP》中说道“一般，中继器两端连接的是相同的通信媒介，但有的中继器也可以完成不同媒介之间的转接工作。如，可以在同轴电缆与光缆之间调整信号。然而，这种情况下，中继器也只是单纯负责信号在0和1比特流之间的替换，并不负责判断数据是否有错误。同时，它只负责将电信号转换为光信号，因此不能在传输速度不同的媒介之间转发” 请问是否前后矛盾，不能理解 这句话有问题，所以不正确也正确。 比如光网络可以跑万兆以上 但是你的光猫转换器是1000M的电口，符合你这个说法，因为光和电 2个媒介是传输速度不同的媒介。 但是 如果你的光口进来的数据的速率是100M的 那么这时候你的电口是可以满足的 这时候你这句话就是错误的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[知识盲点]]></title>
    <url>%2F2019%2F09%2F11%2F%E7%9F%A5%E8%AF%86%E7%9B%B2%E7%82%B9%2F</url>
    <content type="text"><![CDATA[git pull&amp;git pull rebase 字符编码笔记：ASCII，Unicode 和 UTF-8 长连接相关TCP Keepalive机制与应用层心跳Heartbeat 如何使用 Linux 中的 TCP keepalive? 随手记之TCP Keepalive笔记 高效保活长连接：手把手教你实现 自适应的心跳保活机制 nginx的so_keepalive和timeout相关小计 NATNAT大致分为两大类：圆锥形和对称型 圆锥形又分为三种 Full Cone：计算机A链接公网计算机M后，NAT打开一个端口，以后公网上任何发送到这个端口的数据（不限于M）都可以访问到A，这个时候任何从公网上发过来的数据都可以通过该端口到达内网计算机A，不限制M、端口和IP Address Restricted Cone：内网计算机A通过路由器链接了外网计算机M，NAT打开一个端口，这个时候外网计算机M（只限于M）可以通过任何端口和内网计算A进行通信。限制了ip地址，没有限制端口。 Port Restricted Cone：内网计算机A通过路由器链接了外网计算机M，NAT打开一个端口，M可以通过这个端口跟A进行通信，这种即限制了ip地址又限制了端口。 Symmetric NAT（对称形） 对称型NAT和圆锥形不同的地方在于： 圆锥形NAT对于同一台内网计算机，无论与那一台的外网服务器通信，NAT所分配的端口不变。 对称型NAT对于同一台内网计算机与不同的外网计算机通讯会分配不同的端口号，对称型NAT一般不能用于p2p软件。 NAT穿透介绍 SNAT DNAT linux命令netstat ss 网络相关HTTP/2: the difference between HTTP/1.1, benefits and how to use it 正向代理和反向代理 你真的掌握lvs工作原理吗？ consul 架构 阻塞IO和非阻塞IO Java NIO浅析 原码 反码 补码计算机中的有符号数有三种表示方法，即原码、反码和补码。三种表示方法均有符号位和数值位两部分，符号位都是用0表示“正”，用1表示“负”，而数值位，三种表示方法各不相同。 “反码”表示方式是用来处理负数的，符号位置不变，其余位置相反，当“原码”变成“反码”时，完美的解决了“正负相加等于0”的问题 正数补码和原码一样 负整数的补码，将其原码除符号位外的所有位取反（0变1，1变0，符号位为1不变）后加1 已知原码，求补码。 例：已知某数X的原码为10110100，试求X的补码和反码。 解：由[X]原=10110100知，X为负数。求其反码时，符号位不变，数值部分按位求反；求其补码时，再在其反码的末位加1。 1 0 1 1 0 1 0 0 原码 1 1 0 0 1 0 1 1 反码，符号位不变，数值位取反 1 +1 1 1 0 0 1 1 00 补码 故：[X]补=11001100，[X]反=11001101。 已知补码，求原码。 分析：按照求负数补码的逆过程，数值部分应是最低位减1，然后取反。但是对二进制数来说，先减1后取反和先取反后加1得到的结果是一样的，故仍可采用取反加1 有方法。 例：已知某数X的补码11101110，试求其原码。 解：由[X]补=11101110知，X为负数。 采用逆推法 1 1 1 0 1 1 1 0 补码 1 1 1 0 1 1 0 1 反码（末位减1） 1 0 0 1 0 0 1 0 原码（符号位不变，数值位取反）]]></content>
  </entry>
  <entry>
    <title><![CDATA[gc案例]]></title>
    <url>%2F2019%2F09%2F11%2Fgc%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[2019-09-11 频繁cms gc jvm参数 1-Xmx6g -Xms6g -XX:SurvivorRatio=8 -XX:NewRatio=2 -XX:PermSize=128m -XX:MaxPermSize=512m -XX:+DisableExplicitGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintCommandLineFlags -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:ParallelCMSThreads=4 -XX:+CMSClassUnloadingEnabled -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=1 -XX:CMSInitiatingOccupancyFraction=50 现象：老年代远远没有达到配置的50%阀值就开始进行了频繁cms gc 解决办法：增加jvm参数 -XX:+UseCMSInitiatingOccupancyOnly，加上后效果明显 如果不配置 -XX:+UseCMSInitiatingOccupancyOnly cms会动态决定什么时候执行cms gc，详情观看下文 参考链接 https://mp.weixin.qq.com/s/Mu-Xz4CLgdxJhcMJ7aKAHg]]></content>
  </entry>
  <entry>
    <title><![CDATA[《网络是怎么连接的》第二章笔记]]></title>
    <url>%2F2019%2F09%2F10%2F%E3%80%8A%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[用电信号传输TCP/IP数据—–探索协议栈和网卡创建套接字 浏览器、邮件等应用程序收发数据时一般使用TCP;DNS查询等收发较短的控制数据时使用UDP; 套接字是什么？协议栈内部有一块用于存放控制信息的内存空间，这里记录了用于控制通信操作的控制信息，例如通信对象的IP地址、端口号、通信操作的进行状态等。本来套接字只是一个概念而已，并不存在实体，如果一定要赋予它一个实体，我们可以说这些控制信息就是套接字的实体，或者说存放控制信息的内存空间就是套接字的实体。协议栈在执行操作时需要参阅这些控制信息。例如发送数据时需要看一看套接字中的通信对象的IP地址和端口号。发送数据后 套接字中必须要记录是否已经收到响应，以及发送数据后经过多长时间，才能根据这些信息按照需要进行重发操作。 协议栈是根据套接字中记录的控制信息来工作的。 可以在操作系统里输入netstat命令来显示套接字内容。每一行相当于一个套接字，当创建套接字时，就会在这里增加一行新的控制信息。 调用socket时的操作看过套接字的样子后，我们看一看当浏览器调用socket、connect等Socket库中的程序组件时，协议栈内部时如何工作的。 创建套接字的阶段 如图2.3(1)所示，应用程序调用socket申请创建套接字，协议栈根据应用程序的申请执行创建套接字的操作。在这个过程中协议栈首先会分配用于存放一个套接字所需的内存空间，相当于为控制信息准备一个容器。但是光有容器并没有什么用，还需要往里边存入控制信息。套接字刚刚创建时，数据收发操作还没有开始，因此需要在套接字的内存空间写入表示这一初始状态的控制信息。 接下来，需要将这个套接字的描述符告知应用程序。描述符相当于用来区分协议栈中的多个套接字的号码牌。 收到描述符之后，应用程序在向协议栈进行收发数据委托时就需要提供这个描述符。由于套接字中记录了通信双方的信息以及通信处于怎样的状态，所以只要通过描述符确定了相应的套接字，协议栈就能获取所有相关信息，这样一来，应用程序就不需要每次都告诉协议栈应该和谁进行通信了。 连接服务器连接实际上是通信双方交换控制信息 2.3(1)步骤套接字刚刚创建完成的时候，套接字里写的只是初始数据，并不知道通信的对方是谁，在这个状态下，即便是应用程序要求发送数据，协议栈也不知道数据该发给谁。因为调用socket来创建套接字时，这些信息并没有传递给协议栈。因此我们在connect时需要把服务器的IP地址和端口号等信息告诉协议帧，这是连接操作的目的之一。 服务器那边又是怎样的情况呢？服务器上也会创建套接字，服务器上的协议栈和客户端上的一样，只创建套接字是不知道和谁进行通信的。而且和客户端不同的是，在服务器上连应用程序也不知道通信的对象是谁，于是需要客户端告知服务器必要的信息，这也是连接操作的目的之一。 双方交换的的控制信息，除了IP和端口，还有其他。 此外，当执行数据收发操作的时候，我们还需要一块用于临时存放要收发的数据的内存空间，这块内存空间称为缓冲区，它也是在连接操作的过程中分配的。 通信操作中使用的控制信息分为两类。 （1）头部中记录的信息 （2）套接字（协议栈中的内存空间）中记录的信息 连接操作的实际过程这个过程是从应用程序调用Socket库的connect开始的(图2.3(2))。 connect(&lt;描述符&gt;,&lt;服务器IP地址和端口号&gt;) 上面的提供的服务器IP地址和端口号，会传递给协议栈中的TCP模块。然后TCP模块会与该IP地址对应的对象(服务器TCP模块)交换控制信息，这一交互过程包括下面几个步骤。 客户端先创建一个包含表示开始数据收发操作的控制信息的头部。重点关注的是发送方和接收方的端口号，可以通过端口号准确的找到服务器的套接字。然后将头部控制位的SYN比特值设置为1 当TCP头创建好了后，TCP模块把信息传递给IP模块并委托他进行发送。IP模块执行发送网络包操作，网络包到达服务器，服务器IP模块会把收到的数据传递给TCP模块，服务器根据头部的端口号找到对应的套接字，找到后写入相应的信息，并将状态改为正在连接。返回响应，SYN、ACK比特位设置为1 然后网络包到达客户端，通过IP模块到达TCP模块，并通过TCP头部的信息确认连接服务器的操作是否成功。如果SYN为1表示连接成功，这时会向套接字中写入服务器的IP地址、端口号等信息，同时将状态改为连接完毕。客户端返回ACK，ACK比特设置为1 收发数据协议栈并不关心应用程序传来的数据是什么内容。应用程序在调用write时会指定发送数据的长度，在协议栈看来，要发送的数据就是一定长度的二进制字节码而已。 协议栈并不是一收到数据就会马上发出去，而是将数据放在内部的发送缓冲区中，并等待应用程序的下一段数据，因此需要在数据累计到一定的量在发出去，这样做是为了防止网络效率下降 关于协议栈发送数据的时机有两个要素决定 第一个判断要素是每个网络包能容纳的数据长度，协议栈会根据一个叫做MTU的参数来进行判断。MTU表示一个网络包的最大长度，在以太网中一般是1500字节。MTU是包含头部的总长度，因此需要减去头部，TCP和IP头部加起来一共40字节，所以MTU减去这个长度就是一个网络包中能容纳的最大数据长度，这一长度叫做MSS。当协议栈收到的数据长度超过或者接近MSS时再发出去，就可以避免发送大量小包的问题了。 另一个判断要素是时间。当应用程序发送数据频率不高的时候，如果每次都等到接近MSS时在发送，可能会因为等待时间太长而造成发送延迟，这种情况下即便缓冲区中的数据长度没有达到MSS，也应该果断发送出去。为此协议栈内部有一个计时器，当经过一定时间后，就把网络包发送出去。 这两个要素其实是相互矛盾的。长度优先，效率会提高，但是会产生延迟；想反时间优先，延迟降低，网络效率降低。TCP协议规格中并没有告诉我们怎么才能平衡，因此如果判断是由协议栈的开发者来决定的，正是这个原因，不同种类和版本的操作系统在相关操作上也就存在差异。仅靠协议栈来判断发送时机也会带来问题，因此协议栈给应用程序保留了控制发送时机的余地，应用程序可以指定一些选项。 对较大的数据进行拆分：当HTTP消息长度超过一个网络包所能容纳的数据量时，就需要进行拆分了，如图所示。 使用ACK号确认网络包已收到：TCP模块在拆分数据时，会先算好每一块数据相当于从头开始的第几个字节，这个值就是“序号”，然后长度也需要告知接收方，不过这个不是放在TCP头部中，而是用数据包长度减去头部的长度就可以得到数据的长度。接收方回复的ACK号代表，到第XX字节前的数据我都已经收到了，所以已收到多少字节加1作为ACK号。实际通信中序号并不是从1开始的，而是需要随机计算出一个初始值，防止能预测序号发动攻击，如果序号是随机的，为了让对方清楚初始值，所以在建立连接的过程中，需要把序号告诉对方。 通过“序号”和“ACK号”可以确认接收方是否收到了网络包。TCP采用这样的方式确认对方是否收到数据，在得到对方确认之前，发送过的包都会保存在发送缓冲区，如果没有返回某些包对应的ACK号，那么就重新发送这些包。这一机制非常强大，有了这一机制，我们就不需要在其他地方对错误进行补救了。因此网卡、集线器、路由器都没有错误补偿机制，一旦检测到错误就直接丢弃相应的包。应用程序和IP模块也一样只管自顾自的发送数据就好了。 根据网络包平均往返时间调整ACK号等待的时间，等待时间需要设置一个合适的值，不能太长也不能太短，太长会延迟，太短会增加重传对于拥堵的网络无疑是雪上加霜，因此，TCP采用了动态调整等待时间的做法，这个等待时间是根据ACK号返回所需要的时间来判断的。具体来说，TCP会在发送数据的过程中持续测量ACK号的返回时间，如果ACK号返回变慢，则相应延长等待时间；相对地，如果ACK号马上就能返回，则相应缩短等待时间。 每发送一个包就等待一个ACK号的方式是最简单的也是最容易理解的，但是在等ACK号的这段时间内，如果什么也不做就太浪费了。为了减少这样的浪费，TCP采用滑动窗口方式来管理数据发送和ACK号的操作。所谓滑动窗口，就是在发送完一个包之后，不等ACK号返回，而是直接发送后续一系列的包。如图所示 但是滑动窗口的方式发送的数据接收方处理不过来怎么办呢？ 接收方的TCP模块收到包后，会先将数据存放到接收缓存区中。接收方需要计算ACK号，将数据块组装起来还原成原本的数据并传递给应用程序，如果数据到达的速率比处理这些数据并传递给应用程序的速率还快，那么缓存区中的数据就会越堆越多，最后就会溢出。 怎么解决呢？ 首先接收方要告诉发送方自己最多能接收多少数据，然后发送方根据这个值对数据发送操作进行控制，这就是滑动窗口方式的基本思路。 ACK与窗口的合并 要想提高发送数据的效率，还要考虑另一个问题，就是返回ACK号和更新窗口时机。 当收到的数据刚刚填入缓冲区时，其实没必要每次都像发送方更新窗口大小，发送方可以自己算出来。 更新窗口的时机是，接收方从缓冲区中取出数据传递给应用程序的时候。这时缓冲区容量增加，发送方是不知道的，所以需要告诉发送方。 ACK号的发送时机是，接收方收到数据时，确认内容没有问题，就会向发送方返回ACK号，因此我们可以认为收到数据之后马上就进行这一操作。 如果将前面两个因素结合起来看，每收到一个包接收方需要发送两个包，数据到达接收方发ACK包，数据传递给应用程序需要通知发送方更新窗口大小。这样一来，导致网络效率下降。 因此，接收方发送ACK号和窗口更新时，并不会立马发送，而是等待一段时间，这个过程可能会出现其他通知操作，这样就可以把多个通知合并在一个包里发送了。 举个大例子，在等待ACK号的时候正好需要更新窗口，这样就可以把ACK和窗口更新放在一个包里发送了。 当需要连续发送多个ACK号时，也可以减少包的数量，这是因为ACK号表示的是已经收到的数据量，也就是说，它是告诉发送方目前已接收的数据的最后的位置在哪里，因此当需要发送多个ACK号时，只要发送最后一个ACK就行了，中间的可以省略。 同样当需要连续发送多个窗口更新时也可以减少包的数量，这种情况和ACK号一样，可以省略中间过程，只要发送最终结果就可以了。 协议栈接收数据的操作过程 首先，协议栈会检查收到的数据块和TCP头部的内容，判断数据是否有丢失，如果没有问题返回ACK号。 然后，协议栈将数据块暂存到接收缓冲区中，并将数据块按顺序连接起来还原出原始数据 最后，将数据交给应用程序，具体来说，协议栈会将接收到的数据复制到应用程序指定的内存地址中，然后将控制流程交给应用程序。将数据交给应用程序后，协议栈还需要找到合适的时机向发送方发送窗口更新。 从服务器断开并删除套接字客户端和服务器都可以发起断开过程，这里我们以服务器一方发起断开过程为例进行讲解。 断开过程 首先服务器一方的应用程序会调用Socket库的close程序。然后，服务器的协议栈生成包含断开信息的TCP头部，就是将控制位中FIN比特设置为1。接下来协议栈委托IP模块向客户端发送数据。同时服务器套接字中也会记录下断开操作的相关信息。 当客户端收到服务器发来的FIN为1的TCP头部时，客户端的协议栈会将自己的套接字标记进入断开操作状态。然后告知服务器已经收到FIN为1的包，客户端会向服务器返回一个ACK号。这些操作完成后，协议栈就等着应用程序来取数据了。过了一会儿，应用程序就会调用read来读取数据。这时，协议栈不会向应用程序传递数据，而是告知应用程序来自服务器的数据已经全部收到了。 根据规则，服务器返回请求之后，web通信操作就全部结束了，因此只要收到服务器返回的所有数据，客户端的操作也就随之结束了。因此客户端应用程序会调用close来结束数据收发操作，这时客户端的协议栈也会和服务器一样，生成一个FIN比特为1的TCP包，然后委托IP模块发送给服务器。 一段时间后服务器就会返回ACK号，到这里，客户端和服务器的通信就全部结束了。 删除套接字 通信结束后，按理说用来通信的套接字不会再用了，这时我们就可以删除这个套接字了。不过实际上不会立马删除，而是等待一段时间然后删除。 等待这段时间是为了防止误操作，引发误操作的原因有好多，这里举一个最容易理解的例子。 假设客户端先发起断开，则断开的操作顺序如下。 （1）客户端发送FIN （2）服务器返回ACK号 （3）服务器发送FIN （4）客户端返回ACK号 假设最后客户端返回的ACK号丢了，这时服务器没有收到ACK号，可能会重发一次FIN。如果这时客户端的套接字被删了，那套接字保存的控制信息也就跟着消失了，套接字对应的端口就会被释放出来。这时如果别的应用程序要创建套接字，新套接字碰巧又被分配给了同一个接口，而服务器重发的FIN刚好到达，于是这个FIN就会错误的跑到新套接字里面，新套接字就开始执行断开操作了。之所以不马上删除套接字，就是为了防止这样的误操作。 那么应该等待多长时间呢，这和包重传的操作方式有关。网络包丢失之后会进行重传，这个操作通常要持续几分钟。如果重传了几分钟之后依然无效，则停止重传。但在这段时间内，网络中可能存在重传的包，因此需要等待到重传完全结束。协议中对于这个等待时间没有明确规定，一般来说会等待几分钟之后在删除套接字。 数据收发操作小结 IP与以太网的包收发操作包的基本结构 发送方的网路设备会负责创建包，接下来，包会被发往最近的网络转发设备。当到达最近的网络转发设备之后，转发设备会根据头部中的信息判断接下来应该发往哪里。这个过程需要一张表，这张表里记录了每一个地址对应的发送方向，也就是按照头部里记录的目的地址在表里进行查询，并根据查到的信息判断接下来发往哪个方向。接下来，包在向目的地移动的过程中，又会到达下一个转发设备。这样经过多个转发设备的接力以后，包就到达最终的设备。 （1）路由器根据目标地址判断下一个路由器的位置。 （2）集线器在子网中将网络包传输到下一个路由。 实际上，集线器是按照以太网规则传输包的设备，而路由器是按照IP规则传输包的设备，因此我们可以作如下理解。 （1）IP协议根据目标地址判断下一个IP转发设备的位置。 （2）子网中的以太网协议将包传输到下一个转发设备 TCP/IP包包含如下两个头部。 （a）MAC头部（用于以太网协议） （b）IP头部（用于IP协议） 传输过程中ip头目标ip地址不变，mac头目标地址不断变化位下一个路由器的mac地址，更准确的说，收到包的时候MAC头会被舍弃，而当再次发送的时候又会加上包含新MAC地址的新MAC头部。如图所示 包收发概览包收发操作的起点是TCP模块委托IP模块发送包的操作（如下图所示）。这个委托的过程就是TCP模块在数据块的前面加上TCP头部，然后整个传递给IP模块，这部分就是网络包的内容。收到委托后IP模块负责添加MAC头部和IP头部，接下来，封装好的包会被交给网卡。传递给网卡的网络包是由一连串0和1组成的数字信息，网卡将这些数字信息转换为电信号或光信号，并通过网线发送出去，然后这些信号就会到达集线器、路由器等转发设备，再由转发设备一步一步地送达接收方。 生成IP头部IP模块接收TCP模块的委托负责包的收发操作，它会生成IP头部并附加在TCP头部前。最重要的是接收方IP地址，这个地址是TCP模块告知的，而TCP又是在执行连接操作时从应用程序那里获得的。发送方IP地址需要判断发送所使用的网卡，并填写该网卡的IP地址。 生成以太网用的MAC头部IP头部中的接收方IP地址表示网络包的目的地，通过这个地址我们就可以判断将包发送到哪里，但在以太网的世界里，TCP/IP这个思路是行不通的。以太网判断网络包的目的地时和TCP/IP的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而MAC头部就是干这个用的。 IP模块根据路由表Gateway栏的内容判断应该把包发给谁，解释看书内章节2.5.3 通过ARP查询目标路由器的MAC地址在以太网中，有一种叫作广播的方法，可以把包发给连接在同一以太网的所有设备。ARP就是利用了广播。 为了防止每次发送包都用ARP查询一次，网络中就会增加很多ARP包，因此我们会将查询结果放到一块叫做ARP缓存的内存空间中留着以后用。在发送包时，先查下缓存，虽然能减少ARP包的数量，但是如果IP地址发生变化时，ARP缓存的内容就会和现实产生差异。为了防止这种问题的发生，ARP缓存中的值过一段时间就会被删除。 UDP 以太网基本知识（建议看原文2.5.6-2.5.11）]]></content>
  </entry>
  <entry>
    <title><![CDATA[《网络是怎么连接的》第一章笔记]]></title>
    <url>%2F2019%2F08%2F30%2F%E3%80%8A%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[浏览器生成消息生成HTTP请求 一条请求消息中只能写一个URI。如果需要获取多个文件，必须对每个文件单独发送1条请求。向DNS服务器查询Web服务器的IP地址域名和IP地址并用的理由问：为啥不直接使用IP地址，而是要用域名 答：这样其实也是能正常工作的，想想日常上网，你查某个网站肯定是输入域名比如baidu,tianmao之类的，你肯定记不住一长串的IP地址 问：那干脆不用IP地址，用域名来确定通信对象不好吗 答：应该也能实现，但是从运行效率上来看，这并不能算是一个好主意。互联网中存在无数的路由器，他们之间相互配合，根据IP地址来判断应该把数据传送到什么地方。IP地址的长度为32bit，也就是4个字节，相对的域名最短也要几十个字节，增加了路由器的负担。 DNS解析器查询DNS其实是想DNS服务器发送根据域名查询IP的请求，对于DNS服务器我们计算机上的有DNS客户端，相当于DNS客户端的部分我们称为DNS解析器 解析器其实就是一段程序，它包含在操作系统的Socket库中，Socket库是用于调用网络功能的程序组件集合。 根据域名查询IP地址时，浏览器会使用Socket库中的解析器。 解析器内部原理图 向DNS服务器发送消息时，我们当然需要知道DNS服务器的IP地址。这个是事先设置好的。如图window系统 全世界DNS服务器的大接力DNS查询消息包含3种消息 域名：服务器、邮件服务器 Class：最早设计DNS方案时，DNS在互联网以外的其他网络中的应用也被考虑到了，而Class就是用来识别网络的信息。不过如今除了互联网没有其他网络了，因此Class的值永远代表互联网的IN 记录类型：表示域名对应何种类型的记录。例如当类型为A时，表示域名对应的是IP地址;当类型为MX时，表示域名对应的是邮件服务器。不同的记录类型，服务器返回给客户端的信息也会不同。 DNS服务器会从域名与IP地址的对照表中查找相应的记录，并返回IP地址 域名的层次结构问题1： 互联网中存在不计其数的IP地址，将这些IP地址保存到一台DNS服务器是不可能的，因此肯定会存在在DNS服务器中找不到查询信息的情况。 解决方案1： DNS服务器按照域名以分层次的结构来保存到多个DNS服务器上。 比如域名www.lab.glasscom.com,这里的点号代表了不同层级之间的界限。在域名中**越靠右的位置表示层级越高**，其中，每一层级的部分称为域。因此com域的下一层是glasscom域,在下一层是lab域,在下面才是www这个名字。 负责下级域的DNS服务器的IP地址注册到他们上级DNS服务器中，然后上级在注册到更上级的DNS服务器中，以此类推。 根域：似乎com、net这些域就是最顶层了，他们各自负责保存下级DNS服务器的信息，但实际上他们上层还有一级域，称为根域，可以认为www.lab.glasscom.com. 最后那个.代表根域但是一般不写最后的点，因此根域往往被忽略，根域的DNS服务器保存着com、net等DNS服务器的信息。所以我们从根域开始一路顺藤摸瓜找到任意域的DNS服务器，除此之外还需要完成另一项工作，那就是将根域的DNS服务器信息保存在互联网中所有的DNS服务器中。这样一来客户端找到任意一台DNS服务器，就可以通过他找到根域DNS服务器，然后在顺藤摸瓜找到位于下层的目标服务器。 委托协议栈发送消息收发数据操作之前双方需要建立管道。建立管道的关键在于管道两端的数据入口，这些入口称为套接字。 我们需要先创建套接字，然后将套接字连接起来形成管道。 创建套接字阶段 &lt;描述符&gt; = socket(&lt;使用IPV4&gt;,&lt;流模式&gt;, ….); 创建套接字调用Socket库中的socket程序组件就可以了，套接字创建完成后，协议栈会返回一个描述符，应用程序会将收到的描述符放在内存中。描述符是用来识别不同的套接字的。应用程序是通过“描述符”这一类号码牌的东西来识别套接字的 连接阶段:把管道接上去 connect(&lt;描述符&gt;,&lt;服务器的IP地址和端口号&gt;,…); 关于端口号 可能大家还有疑问，既然确定连接对象的套接字需要使用端口号，那么服务器也得知道客户端套接字的端口号才行吧？这个问题怎么解决的呢？首先客户端在创建套接字时，协议栈会为这个套接字随便分配一个端口号。接下来协议栈执行连接操作时，会将这个随便分配的端口号通知给服务器。总之当连接成功后，协议栈会将对方的IP地址和端口号等信息保存在套接字中，这样我们可以开始收发数据了 描述符：应用程序用来识别套接字的机制 IP地址和端口号：客户端和服务器之间用来识别对方套接字的机制 通信阶段：传递消息 断开连接：收发数据结束 本笔记中出现Socket、socket、套接字(英文也是socket)等看起来非常容易混淆的词，其中小写的socket表示程序组件的名称，大写字母开头的Socket表示库，而汉字“套接字”则表示管道两端的接口。]]></content>
      <tags>
        <tag>网络是怎么连接的</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《趣谈网络协议》第10-13讲笔记]]></title>
    <url>%2F2019%2F08%2F19%2F%E3%80%8A%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E3%80%8B%E7%AC%AC10-13%E8%AE%B2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[TCP和UDP的区别TCP面向连接，UDP无连接，所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。 TCP提供可靠交付，通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。UDP不保证不丢失，不保证顺序 TCP 是面向字节流的。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的 IP 包。之所以变成了流，这也是 TCP 自己的状态维护做的事情。而UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收。 TCP是有拥塞控制的。当它意识到包丢弃了或者网络不好，就会根据情况调整自己的行为，决定是不是要发慢点。 UDP就不会，应用让我发我就发。 TCP是一个有状态的服务，里面精确的精确的记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点就不行。而UDP是无状态的服务。 我们可以这样比喻，如果 MAC 层定义了本地局域网的传输行为，IP 层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子 UDP 完全继承了这些特性，几乎没有自己的思想。 UDP包头发送的时候，我知道我发的是一个 UDP 的包，收到的那台机器咋知道的呢？所以在 IP 头里面有个 8 位协议，这里会存放，数据里面到底是 TCP 还是 UDP，当然这里是 UDP。 当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。因为是两端通信嘛，这很好理解。但是你还会发现，UDP 除了端口号，再没有其他的了。和下两节要讲的 TCP 头比起来，这个简直简单得一塌糊涂啊！ UDP三大适用场景 需要资源少，网络情况比较好的内网，或者丢包不敏感的应用。 不需要一对一沟通，建立连接，而是可以广播的应用。 需要处理速度快，时延低，可以容忍少量丢包，但是要求即使网络拥塞也毫不退缩，一往无前的时候。 TCP包头 序号是解决乱序的问题，哪个包先发哪个包后发 确认序号是解决不丢包的问题，发出去的包得有确认，没有确认得重新发送直到送达。 状态位SYN表示发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接。 窗口大小TCP要做流量控制，通信双方各声明一个窗口，标示当前自己能处理的能力，别发送的太快，也别发送的太慢 总结下TCP 顺序问题，稳重不乱 丢包问题，承诺靠谱 连接维护，有始有终 流量控制，把握分寸 拥塞控制，知进知退 TCP三次握手 只要保证双方的包有去有回就行 三次握手除了建立连接外，主要还是为了沟通一件事，就是TCP包的序号的问题。 TCP序号的问题序号不能都从1开始，因为A发1/2/3，三个包给B，中途B丢了，这时A掉线了重新连上B，如果序号又从1开始，发送1/2，这时之前丢的3绕回来了，B就认为这个3是下一个包，于是发生了错误。 因此每个连接都有不同的序号这个起始序号是随着时间变化的可以看成一个32位的计数器 TCP四次挥手为什么建立连接是三次握手，关闭连接确是四次挥手呢？ 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。 TCP的三次握手与四次挥手（详解+动图） TCP状态机 在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端 A 的状态变迁，加粗的虚线是服务端 B 的状态变迁。 TCP缓存发送端的缓存第一部分：发送并已经确认的 第二部分：发送还并且尚未确认 第三部分：没有发送，但是已经等待发送 第四部分：没有发送，并且暂时不会发送 TCP里接收端会给发送端报一个窗口大小，叫做AdvertisedWindow,窗口大小=第二部分+第三部分 接收端的缓存第一部分：接收已确认,之后是已经接收了，但是还没被应用层读取的 第二部分：等待接收，也就是能承受的最大工作量。也就是AdvertisedWindow 第三部分：还没接收，无法接受，因为超过了最大承受量 其中第二部分里面，由于收到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。 顺序与丢包问题分析刚才接受端和发送端的图 状态如下： 1、2、3没有问题达成一致 4、5接收方说ACK了，但是发送方还没有收到，有可能丢了，有可能在路上 6、7、8、9肯定都发了，但是8、9已经到了，但是6、7没到出现乱序，没办法ACK 根据这个例子，知道丢包和顺序问题都可能发生。 假设4的ACK收到了，5的ACK丢了，6、7的数据包丢了，咋办呢 超时重试，那超时时间如何控制呢。需要自适应重传算法（Adaptive+Retransmission+Algorithm）[^1]，如果过一段时间5、6、7都超时了，发送端会重发5、6、7的包，接收端发现5收到过就会丢弃5,不回ACK[^2]，6收到回ACK，不幸的是7又丢了，当再次超时的时候，TCP的策略是超时间隔加倍，每当遇到一次超时重传的时候，都会将下一次超时时间设置为先前两倍。两次超时说明网络环境差，不宜频繁反复发送,超时重传的问题是超时周期可能相对较长，是不是有更快的方式，有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。例如，接收方发现 6、8、9 都已经接收了，就是 7 没来，那肯定是丢了，于是发送三个 6 的 ACK，要求下一个是 7。客户端收到 3 个，就会发现 7 的确又丢了，不等超时，马上重发。 Selective Acknowledgment(SAK) 这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。 流量控制对于包的确认中，同时会携带一个窗口大小。我们假设窗口不变，始终为9，4的ACK来的时候会右移一个，这个时候第13个包也可以发送了 这个时候如果发送端发送过猛，会将10、11、12、13都发送了，之后停止发送，因为未发送可发送部分为0。 这时候又收到了5的ACK，窗口又会往右滑动一格，这时才可以有更多包可以发送 如果接收方处理的太慢，导致缓存中没有空间，可以通过确认信息修改窗口大小，甚至可以设置为0，让发送方定制发送。 我们假设一个极端情况，接收端的应用一直不读取缓存里的数据，当数据包6确认后，窗口大小不能在是9了，就要缩小一个变成8。 这个新窗口8通过6的确认消息，到达发送端的时候，你会发现发送端窗口没有右移，而只是左边的移动了，窗口大小由9变成8 如果接收端的应用还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，甚至变为0 当窗口大小通过14包的ACK到达发送端时，发送端的窗口也变为0。 如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。 拥塞控制解决什么问题最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满。 这里有一个公式 LastByteSent - LastByteAcked &lt;= min {cwnd, rwnd} ，是拥塞窗口和滑动窗口共同控制发送的速度。 那发送方怎么判断网络是不是满呢？这其实是个挺难的事情，因为对于 TCP 协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。 假设tcp发送的速度超过了带宽，中间设备处理不了的包就会被丢弃， 为了解决这个问题中间经过的设备会会加上缓存，处理不过来的在队列里排着，虽然避免了丢包，但是造成了超时重传 于是TCP的拥塞控制住要来解决这两种现象，包丢失和超时重传，一旦出现了这些现象就说明太快了，要慢一点。TCP 的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽 如何解决如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢的倒，然后发现总能够倒进去，就可以越倒越快。这叫作慢启动。 一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是指数增长，增长到啥时候是个头呢。 涨到什么时候是个头呢？有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。 每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。 但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。 拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 sshresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。 前面讲过快速重传算法。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。 有什么问题第一个问题是是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。 第二个问题是 TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。 为了优化这两个问题出来了TCP拥塞 BBR算法。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。 基于TCP协议Socket函数调用过程 服务端调用accept函数，拿出一个已经完成的连接进行处理。如果没有完成就需要等待，在服务器等待的时候，客户端可以通过connect函数发起连接。先在参数中指明要连接的IP地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时端口。一旦握手成功，服务端的accept就会返回另一个Socket。 这是经常考的知识点，就是监听的Socket和真正用来传数据的Socket是两个，一个叫做监听Socket，一个叫做已连接Socket。 基于UDP协议Socket函数调用过程 对于 UDP 来讲，过程有些不一样。UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。 [^1]:估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为[^2]:不会有问题。接收方的 ACK 应答，不是和发送方的数据包一一对应的，也不是一个个回复。当某个包做了 ACK 应答，表示它之前的所有包都收到了。所以这里的例子里，5 虽然没有 ACK 应答，但是之后收到的 6、7、8，只需要 ACK 应答 8 就表示之前的包都收到并确认了。]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《趣谈网络协议》第3-7讲笔记]]></title>
    <url>%2F2019%2F08%2F14%2F%E3%80%8A%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E3%80%8B%E7%AC%AC3-7%E8%AE%B2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ifconfig 和 ip addr的区别这是有关net-tools 和 iproute2的故事，后续回答这个问题 IP是什么ip地址是一个网卡在网络世界的通信地址，相当于我们现实世界的地址。 IPv6出现原因这个地址被分为四个部分，每个部分8个bit，所以一共32位，所以IP地址的数量很快就不够用了。当时设计IP地址时，哪里知道会有这么多计算机，因为不够用所以，就有了IPv6，这个有128位。 IP分类本来 32 位的 IP 地址就不够，还被分成了 5 类。现在想想，当时分配地址的时候，真是太奢侈了。 A/B/C类分网络号和主机号两部分 IP A/B/C 类包含的主机数量 类别 IP地址范围 最大主机数 私有IP地址范围 A 0.0.0.0-127.255.255.255 16,777,214 10.0.0.0-10.255.255.255 B 128.0.0.0-191.255.255.255 65534 172.16.0.0-172.31.255.255 C 192.0.0.0-223.255.255.255 254 192.168.0.0-192.168.255.255 C类主机数太少了只有254个，一般大网吧都满足不了。B类又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。为了解决C类主机数太少，B类主机数太多的窘状，出现了CIDR 无类型域间选路（CIDR）这种方式打破了原来设计的分类方案，将原来的ip地址一分为二，前边是网络号，后边是主机号 从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个 IP 地址中有一个斜杠，斜杠后面有个数字 24。这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号。 CIDR里有几个概念 广播地址: 10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到 子网掩码: 255.255.255.0 子网掩码&amp;IP地址=网络号: 10.100.122.2&amp;255.255.255.0=10.100.122.0 CIDR 可以用来判断是不是本地人，网络号一样就是本地人 公有IP和私有IP平时我们看到的数据中心里，办公室、家里或学校的 IP 地址，一般都是私有 IP 地址段。因为这些地址允许组织内部的 IT 人员自己管理、自己分配，而且可以重复。因此，你学校的某个私有 IP 地址段和我学校的可以是一样的。 公有 IP 地址有个组织统一分配，你需要去买。如果你搭建一个网站，给你学校的人使用，让你们学校的 IT 人员给你一个 IP 地址就行。但是假如你要做一个类似网易 163 这样的网站，就需要有公有 IP 地址，这样全世界的人才能访问。 表格中的 192.168.0.x 是最常用的私有 IP 地址。你家里有 Wi-Fi，对应就会有一个 IP 地址。一般你家里地上网设备不会超过 256 个，所以 /24 基本就够了。有时候我们也能见到 /16 的 CIDR，这两种是最常见的，也是最容易理解的。 不需要将十进制转换为二进制 32 位，就能明显看出 192.168.0 是网络号，后面是主机号。而整个网络里面的第一个地址 192.168.0.1，往往就是你这个私有网络的出口地址。例如，你家里的电脑连接 Wi-Fi，Wi-Fi 路由器的地址就是 192.168.0.1，而 192.168.0.255 就是广播地址。一旦发送这个地址，整个 192.168.0 网络里面的所有机器都能收到。 但是也不总都是这样的情况。因此，其他情况往往就会很难理解，还容易出错。 ip addr 和ifconfig 查ip信息内容分析12345678910111213root@test:~# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::f816:3eff:fec7:7975/64 scope link valid_lft forever preferred_lft forever scope在 IP 地址的后面有个 scope，对于 eth0 这张网卡来讲，是 global，说明这张网卡是可以对外的，可以接收来自各个地方的包。对于 lo 来讲，是 host，说明这张网卡仅仅可以供本机相互通信。 lo 全称是loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。 MAC地址在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。 MAC 地址是一个很容易让人“误解”的地址。因为 MAC 地址号称全局唯一，不会有两个网卡有相同的 MAC 地址，而且网卡自生产出来，就带着这个地址。 很多人看到这里就会想，既然这样，整个互联网的通信，全部用 MAC 地址好了，只要知道了对方的 MAC 地址，就可以把信息传过去。 这样当然是不行的。 一个网络包要从一个地方传到另一个地方，除了要有确定的地址，还需要有定位功能。 而有门牌号码属性的 IP 地址，才是有远程定位功能的。 例如，你去杭州市网商路 599 号 B 楼 6 层找刘超，你在路上问路，可能被问的人不知道 B 楼是哪个，但是可以给你指网商路怎么去。但是如果你问一个人，你知道这个身份证号的人在哪里吗？可想而知，没有人知道。 MAC 地址是有一定定位功能的，只不过范围非常有限。你可以根据 IP 地址，找到杭州市网商路 599 号 B 楼 6 层，但是依然找不到我，你就可以靠吼了，大声喊身份证 XXXX 的是哪位？我听到了，我就会站起来说，是我啊。但是如果你在上海，到处喊身份证 XXXX 的是哪位，我不在现场，当然不会回答，因为我在杭州不在上海。 所以，MAC 地址的通信范围比较小，局限在一个子网里面。例如，从 192.168.0.2/24 访问 192.168.0.3/24 是可以用 MAC 地址的。一旦跨子网，即从 192.168.0.2/24 到 192.168.1.2/24，MAC 地址就不行了，需要 IP 地址起作用了。 MAC 地址更像是身份证，是一个唯一的标识。它的唯一性设计是为了组网的时候，不同的网卡放在一个网络里面的时候，可以不用担心冲突。从硬件角度，保证不同的网卡有不同的标识。 网络设备的状态标识解析完了 MAC 地址，我们再来看 &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; 是干什么的？这个叫作net_device flags，网络设备的状态标识。 UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。 mtuMTU1500 是指什么意思呢？是哪一层的概念呢？最大传输单元 MTU 为 1500，这是以太网的默认值。网络包是层层封装的。MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定连 MAC 头带正文合起来，不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。 qdiscqdisc pfifo_fast 是什么意思呢？qdisc 全称是queueing discipline，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。 最简单的 qdisc 是 pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。 pfifo_fast 稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。 三个波段（band）的优先级也不相同。band 0 的优先级最高，band 2 的最低。如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包，band 1 和 band 2 之间也是一样。 数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。 队列是个好东西，后面我们讲云计算中的网络的时候，会有很多用户共享一个网络出口的情况，这个时候如何排队，每个队列有多粗，队列处理速度应该怎么提升，我都会详细为你讲解。 如何手动设计IP地址使用net-tools: 12$ sudo ifconfig eth1 10.0.0.1/24$ sudo ifconfig eth1 up 使用iproute2: 12$ sudo ip addr add 10.0.0.1/24 dev eth1$ sudo ip link set up eth1 如果身边的人的IP都是192.68.1.x，我设置成 172.10.168.2会怎么样包发不出去，因为linux会首先判断这个ip和本机是一个网段的吗？只有是一个网段才会发送ARP协议获取MAC地址。如果判断不是同一网段，Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。所以如果你要配置ip一定要问好你的网络管理员，人少还行，如果每个人都去问那管理员会疯的，所以有了DHCP 动态主机配置协议（DHCP）Dynamic Host Configuration Protocol 有了这个协议，网络管理员就轻松多了。他只需要配置一段共享的 IP 地址。每一台新接入的机器都通过 DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。 DHCP工作模式第一步（DHCP Discover）新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。广播包封装了 UDP，UDP 封装了 BOOTP。其实 DHCP 是 BOOTP 的增强版，但是如果你去抓包的话，很可能看到的名称还是 BOOTP 协议。 在这个广播包里面，新人大声喊：我是新来的（Boot request），我的 MAC 地址是这个，我还没有 IP，谁能给租给我个 IP 地址！ 第二步（DHCP Offer）如果配置了DHCP server，他会立马知道来了个新人，是通过MAC地址判断的，所以唯一的MAC地址是多么重要。他会立马回DHCP Offer，DHCP Server 仍然使用广播地址作为目的地址，因为，此时请求分配 IP 的新人还没有自己的 IP。DHCP Server 回复说，我分配了一个可用的 IP 给你，你看如何？除此之外，服务器还发送了子网掩码、网关和 IP 地址租用期等信息。 第三步（选一个Offer）新来的机器很开心，它的广播得到了回复，并且有人愿意租给它一个 IP 地址了，这意味着它可以在网络上立足了。 当然更令人开心的是，如果有多个 DHCP Server，这台新机器会收到多个 IP 地址，简直受宠若惊。 它会选择其中一个 DHCP Offer，一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者。 此时，由于还没有得到 DHCP Server 的最后确认，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。在 BOOTP 里面，接受某个 DHCP Server 的分配的 IP。 第四步（DHCP Server Ack）当 DHCP Server 接收到客户机的 DHCP request 之后，会广播返回给客户机一个 DHCP ACK 消息包，表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。 最终租约达成的时候，还是需要广播一下，让大家都知道一下。 IP地址的收回与续租既然是租房子，就是有租期的。租期到了，管理员就要将 IP 收回。 如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP 也是这样。 客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。 HUB有一个叫作Hub的东西，也就是集线器。这种设备有多个口，可以将宿舍里的多台电脑连接起来。但是，和交换机不同，集线器没有大脑，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。这是第一层物理层联通的方案。 你可能已经发现问题了。Hub 采取的是广播的模式，如果每一台电脑发出的包，宿舍的每个电脑都能收到，那就麻烦了。这就需要解决几个问题：包是发给谁的，顺序，包是否完整，这几个问题都是MAC层需要解决的 MAC层如何解决上述问题根据ip如何获取MAC地址根据IP地址获取MAC地址 ####第一个问题，发给谁，谁接收？ 这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC 地址。 解决第一个问题就牵扯到第二层的网络包格式。对于以太网，第二层的最开始，就是目标的 MAC 地址和源的 MAC 地址。 第二个问题，顺序问题MAC的全称是Medium Access Control，即媒体访问控制。控制什么呢？其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。这解决的是第二个问题。这个问题中的规则，学名叫多路访问。有很多算法可以解决这个问题。就像车管所管束马路上跑的车，能想的办法都想过了。 方式一：分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作信道划分； 方式二：今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作轮流协议； 方式三：不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作随机接入协议。著名的以太网，用的就是这个方式。 第三个问题，如何校验包是否完整对于以太网，第二层的最后面是CRC，也就是循环冗余检测。通过 XOR 异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。 交换机一旦机器数目增多，问题就出现了。因为 Hub 是广播的，不管某个接口是否需要，所有的 Bit 都会被发送出去，然后让主机来判断是不是需要。这种方式路上的车少就没问题，车一多，产生冲突的概率就提高了。而且把不需要的包转发过去，纯属浪费。看来 Hub 这种不管三七二十一都转发的设备是不行了，需要点儿智能的。因为每个口都只连接一台电脑，这台电脑又不怎么换 IP 和 MAC 地址，只要记住这台电脑的 MAC 地址，如果目标 MAC 地址不是这台电脑的，这个口就不用转发了。 谁能知道目标 MAC 地址是否就是连接某个口的电脑的 MAC 地址呢？这就需要一个能把 MAC 头拿下来，检查一下目标 MAC 地址，然后根据策略转发的设备，这个设备是个二层设备，我们称为交换机。 交换机是有 MAC 地址学习能力的，学完了它就知道谁在哪儿了，不用广播了。 拓扑结构怎么形成的当机器变得很多的时候，一个交换机肯定不够用，需要多台交换机，交换机之间连接起来，就形成一个稍微复杂的拓扑结构。 如何解决拓扑结构中的环路问题 需要STP协议来解决 STP协议在数据结构中，有一个方法叫作最小生成树。有环的我们常称为图。将图中的环破了，就生成了树。在计算机网络中，生成树的算法叫作STP，全称Spanning Tree Protocol。 如何解决广播问题和安全问题？毕竟机器多了，交换机也多了，就算交换机比 Hub 智能一些，但是还是难免有广播的问题，一大波机器，相关的部门、不相关的部门，广播一大堆，性能就下来了。就像一家公司，创业的时候，一二十个人，坐在一个会议室，有事情大家讨论一下，非常方便。但是如果变成了 50 个人，全在一个会议室里面吵吵，就会乱的不得了。有两种解决方法，物理隔离、虚拟隔离 物理隔离每个部门设一个单独的会议室，对应到网络方面，就是每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了。路由器咱们还没讲到，以后再说。这样的问题在于，有的部门人多，有的部门人少。人少的部门慢慢人会变多，人多的部门也可能人越变越少。如果每个部门有单独的交换机，口多了浪费，少了又不够用。 虚拟隔离就是用我们常说的VLAN，或者叫虚拟局域网。使用 VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？ 我们只需要在原来的二层的头上加一个 TAG，里面有一个 VLAN ID，一共 12 位。为什么是 12 位呢？因为 12 位可以划分 4096 个 VLAN。这样是不是还不够啊。 现在的情况证明，目前云计算厂商里面绝对不止 4096 个用户。当然每个用户需要一个 VLAN 了啊，怎么办呢，这个我们在后面的章节再说。 如果我们买的交换机是支持 VLAN 的，当这个交换机把二层的头取下来的时候，就能够识别这个 VLAN ID。这样只有相同 VLAN 的包，才会互相转发，不同 VLAN 的包，是看不到的。这样广播问题和安全问题就都能够解决了。 有人会问交换机之间怎么连接呢？将两个交换机连接起来的口应该设置成什么 VLAN 呢？对于支持 VLAN 的交换机，有一种口叫作Trunk 口。它可以转发属于任何 VLAN 的口。交换机之间可以通过这种口相互连接。 ICMP协议ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，那具体是怎么控制的呢。 ICMP 报文是封装在 IP 包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。 ICMP 报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为 8,主动请求的应答为0 查询报文类型常用的ping 就是查询报文，是一种主动请求，并且获得主动应答的 ICMP 协议。所以，ping 发的包也是符合 ICMP 协议格式的，只不过它在后面增加了自己的格式。 差错报文类型Traceroute 使用差错报文,详细请看专栏 路由器网关往往是一个路由器，是一个三层转发的设备。啥叫三层设备？前面也说过了，就是把 MAC 头和 IP 头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程下hashmap死循环]]></title>
    <url>%2F2019%2F02%2F16%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8Bhashmap%E6%AD%BB%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[问题由于HashMap并非是线程安全的，所以在高并发的情况下必然会出现问题，可能发生死循环，导致cpu100%，服务重启之后，问题消失，过段时间可能又复现了。这是为什么 原因分析在了解来龙去脉之前，我们先看看HashMap的数据结构。在内部，HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，算法很简单，根据key的hash值，对数组的大小取模 hash &amp; (length-1)，并把结果插入数组该位置，如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。 实现HashMap的put方法实现： 判断key是否已经存在123456789101112131415161718192021public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); // 如果key已经存在，则替换value，并返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // key不存在，则插入新的元素 addEntry(hash, key, value, i); return null;&#125; 检查容量是否达到阈值threshold123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 复制代码如果元素个数已经达到阈值，则扩容，并把原来的元素移动过去。 扩容实现1234567891011void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; ... Entry[] newTable = new Entry[newCapacity]; ... transfer(newTable, rehash); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 这里会新建一个更大的数组，并通过transfer方法，移动元素。123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 移动的逻辑也很清晰，遍历原来table中每个位置的链表，并对每个元素进行重新hash，在新的newTable找到归宿，并插入。 案例分析假设HashMap初始化大小为4，插入个3节点，不巧的是，这3个节点都hash到同一个位置，如果按照默认的负载因子的话，插入第3个节点就会扩容，为了验证效果，假设负载因子是1.123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 以上是节点移动的相关逻辑。 两个线程同时rehash插入第4个节点时，发生rehash，假设现在有两个线程同时进行，线程1和线程2，两个线程都会新建新的数组。 线程2Block线程1继续执行假设 线程2 在执行到Entry&lt;K,V&gt; next = e.next;之后，cpu时间片用完了，这时变量e指向节点a，变量next指向节点b。线程1继续执行，很不巧，a、b、c节点rehash之后又是在同一个位置7，开始移动节点第一步，移动节点a 第二步，移动节点b 注意，这里的顺序是反过来的，继续移动节点c 线程1Block线程2开始执行这个时候 线程1 的时间片用完，内部的table还没有设置成新的newTable， 线程2 开始执行，这时内部的引用关系如下： 线程2继续循环剩余逻辑这时，在 线程2 中，变量e指向节点a，变量next指向节点b，开始执行循环体的剩余逻辑。12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行之后的引用关系如下图执行后，变量e指向节点b，因为e不是null，则继续执行循环体 线程2第二次循环12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行后的引用关系 变量e又重新指回节点a，只能继续执行循环体 线程2第三次循环(出现环)12345678// 目前节点a没有next，所以变量next指向null；Entry&lt;K,V&gt; next = e.next;// 其中 newTable[i] 指向节点b，那就是把a的next指向了节点b，这样a和b就相互引用了，形成了一个环e.next = newTable[i]; // 把节点a放到了数组i位置；newTable[i] = e // 把变量e赋值为null，因为第一步中变量next就是指向null；e = next; 所以最终的引用关系是这样的： 节点a和b互相引用，形成了一个环，当在数组该位置get寻找对应的key时，就发生了死循环。另外，如果线程2把newTable设置成到内部的table，节点c的数据就丢了，看来还有数据遗失的问题。 总结所以在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。 文章参考 占小狼和coolshell的博客]]></content>
      <tags>
        <tag>java基础</tag>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2019%2F02%2F13%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal是什么jdk文档介绍1234567891011121314/** * This class provides thread-local variables. These variables differ from * their normal counterparts in that each thread that accesses one (via its * &#123;@code get&#125; or &#123;@code set&#125; method) has its own, independently initialized * copy of the variable. &#123;@code ThreadLocal&#125; instances are typically private * static fields in classes that wish to associate state with a thread (e.g., * a user ID or Transaction ID). * * &lt;p&gt;For example, the class below generates unique identifiers local to each * thread. * A thread's id is assigned the first time it invokes &#123;@code ThreadId.get()&#125; * and remains unchanged on subsequent calls. */ 结合我的总结可以这样理解：ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离～。简要言之：往ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是隔离的。 作用是什么从上面可以得出：ThreadLocal可以让我们拥有当前线程的变量，那这个作用有什么用呢？？？最常见的ThreadLocal使用场景为用来解决 数据库连接、Session管理、避免一些参数传递等例如12345678910private static ThreadLocal&lt;Connection&gt; connectionHolder= new ThreadLocal&lt;Connection&gt;() &#123;public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL);&#125;&#125;; public static Connection getConnection() &#123;return connectionHolder.get();&#125; 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 实现原理Thread、ThreadLocal、ThreadLocalMap、Entry之间的关系 ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。 也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 ThreadLocalMap由一个个Entry对象构成，Entry的代码如下：12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;，一个Entry由ThreadLocal对象和Object构成。由此可见，Entry的key是ThreadLocal对象，并且是一个弱引用。当没指向key的强引用后，该key就会被垃圾收集器回收。 那么，ThreadLocal是如何工作的呢？下面来看set和get方法。1234567891011121314151617181920212223242526public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; ThreadLocal为什么会内存泄漏ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话(比如线程池线程循环利用)，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal有外部强引用，延长了ThreadLocal的生命周期，可能导致的内存泄漏 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。(虽然ThreadLocal回收了但是value没有被回收) 为什么使用弱引用从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.为了应对非常大和长时间的用途，哈希表使用弱引用的 key。 下面我们分两种情况讨论： key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 避免内存泄漏综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，thread的生命周期很长的情况下，没有及时清理ThreadLocal，导致内存泄漏随着应用运行的时间越来越长会导致内存溢出。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表]]></title>
    <url>%2F2019%2F01%2F29%2F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[相比数组，链表是一种稍微复杂一点的数据结构。对于初学者来说，掌握起来也要比数组稍难一些。这两个非常基础、非常常用的数据结构，我们常常将会放到一块儿来比较。所以我们先来看，这两者有什么区别。 链表和数组的区别为了直观地对比，我画了一张图。从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。 单链表我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作“后继指针” 从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址NULL，表示这是链表上最后一个结点。 与数组一样，链表也支持数据的查找、插入和删除操作。 我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 为了方便你理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。 循环链表循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。和单链表相比，循环列表的优点是是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。 双向链表单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。 从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。 你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。我再来带你分析一下链表的两个操作。 删除操作在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中“值等于某个给定值”的结点；这种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。 删除给定指针指向的结点。对于这种种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。你可以参照我刚刚讲过的删除操作自己分析一下。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。 双向循环链表 数组vs链表性能比拼通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。 开发中如何选择不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 我举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？ 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。 链表实现LRU缓存我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果次数据不在链表里 链表满了，删除尾结点，该数据插入头结点 链表还有空间，插入头结点 代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。 实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。 问题数组实现LRU缓存除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？我把这个问题留给你思考。我的思路是这样：维护一个数组，越靠近尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从数组第一个元素开始遍历 如果此数据已经被缓存，我们遍历得到这个数据的下标，并将前面的所有数据都往右移动一位，然后在把该元素放到数据下标0的位置 如果数组不在数组里 数组满了，把最后一个元素之前的元素向右平移一位，最后一个元素自然也就丢弃了，然后把该数据放到下标为0的位置 数组还有空间，把数组里所有元素向右平移一位，然后把该数据放到下标为0的位置代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍数组，所以这种基于数组的实现思路，缓存访问的时间复杂度为 O(n)。 如何判断一个字符串是回文串如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的思题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？我的思路是：使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。最后比较中点两侧的链表是否相等。代码地址 常见单链表编程题 单链表反转 链表中环的检测 两个有序链表合并 删除倒数第n个代码 求链表中间结点代码地址]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[如何实现随机访问什么是数组？数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 这个定义里有几个关键词 线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。 而与他对立的是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。 连续的内存空间和相同类型的数据正是有了这个特性，他才有了随机访问这个“杀手锏”。但是有利就有弊，比如删除添加为了保证连续性，必须要做数据搬移工作。说到数据的访问，那你知道数组是如何实现根据下标随机访问数组元素的吗？我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址。1a[i]_address = base_address + i * data_type_size 其中data_type_size表示每个元素的大小。我们这个例子数组中存储的是int类型数组，所以date_type_size就为4个字节。这里特别纠正一个“错误”。面试中经常会问到数组和链表的区别，很多人都会回答，“链表适合插入、删除、时间复杂度O(1);数组适合查找，查找时间复杂度为O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但查找时间复杂度不是O(1)。即便是排序好的数组，你用二分查找时间复杂度才是O(logn)。所以正确的表述是数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。 低效的插入和删除前面提到，数组为了保证内存数组连续性，会导致插入、删除两个操作会比较低效。 插入操作假设数组长度为n，现在，需要把一个数据插入到数组第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要把k～n这部分元素都顺序往后挪一下，那时间复杂度是多少呢？如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。如果数组中的数据是有序的，我们在某个位置插入一个新元素，就必须按照刚才的方法搬移k之后的数组。但是如果数组中的数据没有任何规律，数组只是存储集合。在这种情况下，如果把数据插入第k个位置，为了避免大规模搬移，直接将第k个位置的数据插入到数组最后，把新的元素放在第k个位置。如下图所示 利用这个技巧，在特定场景下，在第k个位置插入元素的复杂度就降到了O(1) 删除操作跟插入操作类似，如果删除第k个位置的数据，为了内存连续性，也需要搬移数据，不然会出现空洞，内存就不连续了。和插入类似，如果删除末尾的数据，时间复杂度O(1);如果删除开头的数据，则最坏情况时间复杂度为O(n);平均情况时间复杂度也为O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。 为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。 容器能否代替数组？针对数组类型，很多语言提供了容器类，比如java中的ArrayList。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？因为我是java开发，几乎每天都在用ArrayList。个人觉得ArrayList的最大优势就是可以把很多数组操作的细节封装起来。比如插入、删除、动态扩容。 数组本身在定义时需要预先指定大小，因为需要分配连续的内存空间。乳沟我们申请了大小为10的数组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后在插入新的数据。 如果使用ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList已经帮我们实现好了。每次空间不够时，他都会自动扩容为1.5倍大小。 不过，这里需要注意一点，因为扩容需要内存申请和数据搬移，比较耗时。所以，如果事先能去定需要存储数据的大小，最后在创建ArrayList的时候事先指定数据大小。 作为高级语言编程者，是不是数组就无用武之地了？当然不是，一下情况可以用数组。 Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList array。 我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 为什么大多数编程语言数组下标要从0开始而不是1从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：1a[k]_address = base_address + k * type_size 但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：1a[k]_address = base_address + (k-1)*type_size 对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。 数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。 不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非 0 开始不可。所以我觉得最主要的原因可能是历史原因。 C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2019%2F01%2F26%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[第一版鸭子游戏我们设计了一个鸭子游戏项目，游戏中会出现各种鸭子，为此Joe实现了一个超类Duck，让鸭子子类都继承这个类，如下图所示。 加鸭子会飞的需求使用继承过了几天主管找到Joe说希望有的鸭子能飞，Joe说so easy，只需在超类里增加一个fly()方法就ok了。但是过了几天主管对外演示时发现，橡皮鸭子在屏幕上飞来飞去，非常尴尬。主管打电话开始喷Joe:你可以去看看boss直聘了。Joe忽略了一件事，并非所有鸭子都会飞，他在超类里加上新的行为，会使得不该拥有这个行为的子类也拥有了这个行为。他体会了一件事：当涉及维护时为了复用目的使用继承结局并不完美。 Joe：那么橡皮鸭子类可以重写这个fly方法里边什么也不做，不就可以了吗？主管：那么所有不能飞的子类都得重写一遍fly，然后如果加入木鸭(不会飞不会叫)，也得把quack()方法重写。Joe意思到继承可能无法解决这个问题： 使用接口Joe：那么可以把fly()和quack()方法从超类里拆出来，只有能飞/能叫的鸭子子类实现这个接口主管：这真是个超级糟糕的设计，如果你认为重写几个方法很差劲，但是48个子类都稍微修改下飞行的行为呢？Joe：我去还真是，虽然Flayable和Quackable能解决一部分问题（不再有会飞的橡皮鸭），但是却造成代码无法复用啊，每个会飞的鸭子子类都得实现一个fly()方法哪怕他们的飞的行为是一样的，如果每个fly方法里增加打印日志得需要改48个子类。那咋办呀？ 设计原则一主管：把问题归零把，下面给你介绍一个设计原则：找出应用中可能需要变化的地方，把他们独立出来，不要在和哪些不变的代码混在一起了，把会变化的代码封装起来，好让其他部分不受影响，代码变化引起的bug变少，系统更加有弹性 下面是这个设计原则的另一种思考方式：“把会变化的部分取出并封装起来，以便以后可以轻易的改动或者扩展此部分，而不影响不需要变化的部分“主管：Joe是时候把鸭子的行为从Duck里行为拆出来了！Joe：ok，那么Duck里的行为除了fly和quack有问题外，其他行为一切还算正常，现在要分开变化部分和不变部分了，我打算建立两组类看图 设计原则二那么如何设计那组实现飞行和呱呱叫的的行为的类呢？我们希望一切能有弹性，毕竟，正是一开始鸭子行为没有弹性，才让我们走上现在这条路。我们还想能够“指定”行为到鸭子的实例。比方说，我们想要产生一个新的绿头鸭的实例，并指定特定的“类型”的飞行行为给它。干脆让鸭子的行为可以动态地改变好了。换句话说，我们应该在鸭子类中包含设定行为的方法，这样就可以在“运行时”动态地“改变”绿头鸭的飞行行为。有了这些目标要实现，接着看看第二个设计原则： 我们利用接口代表每个行为，比方说，FlyBehavior和QuackBehavior接口。所以这次鸭子类不回负责实现Fly与Quack接口，反而是由我们制造一组其他类专门实现FlyBehavior与QuackBehavior,这些就称为“行为”类。 这样的设计，可以让飞行和呱呱叫的动作被其他的对象复用，因为这些行为已经与鸭子类无关了。而我们可以新增一些行为，不会影响到既有的行为类，也不会影响“使用”到飞行行为的鸭子类。这么一来，有了继承的“复用”的好处，却没有继承所带来的包袱。 整合鸭子的行为关键在于，鸭子现在会将飞行和呱呱叫“委托”(delegate)别人处理，而不是定义在Duck类(或子类)内的呱呱叫和飞行方法。 1234567891011public class Duck &#123; //每只鸭子都会引用实现QuackBehavior接口的对象。 QuackBehavior quackBehavior; // 还有更多 ....... //鸭子对象不亲自处理呱呱叫的行为，而是委托给quackBehavior引用的对象 public void performQuack()&#123; quckBehavior.quack(); &#125;&#125; UML图 设计原则三“有一个”可能比“是一个”更好。“有一个”关系相当有趣：每一鸭子都有一个FlyBehavior和一个QuackBehavior，好将飞行和呱呱叫委托给它们代为处理。当你将两个类结合起来使用，如同本例一般，这就是组合(composition)。这种做法和“继承”不同的地方在于，鸭子的行为不是继承来的，而是和适当的行为对像“组合来的”。这是一个很重要的技巧。其实是使用了我们的第三个设计原则：]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2015%2F01%2F31%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[java静态代理和动态代理 代理的优点 职责清晰 真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后期的代理完成一件完成事务，附带的结果就是编程简洁清晰。 代理对象可以在客户端和目标对象之间起到中介的作用，这样起到了中介的作用和保护了目标对象的作用。 高扩展性，可以在代理方法前后增加额外的处理逻辑。 被代理的对象一个接口123public interface Subject &#123; void doSomething();&#125; 它的实现类1234567public class SubjectImpl implements Subject &#123; @Override public void doSomething() &#123; System.out.println( "call doSomething()" ); &#125;&#125; 静态代理静态代理是由程序员创建或工具生成代理类的源码，再编译代理类。也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。缺点是被代理对象和代理紧耦合在一起。而且代理类都是针对被代理类创建的。12345678910public class SubjectProxy implements Subject &#123; Subject subject = new SubjectImpl(); @Override public void doSomething() &#123; System.out.println("before"); //调用目标对象之前可以做相关操作 subject.doSomething(); System.out.println("after");//调用目标对象之后可以做相关操作 &#125;&#125; 动态代理动态代理在运行阶段才指定被代理的对象，通过实现InvocationHandler接口，调用具体的方法。123456789101112131415161718public class ProxyHandler implements InvocationHandler &#123; private Object tar; public Object bind(Object tar) &#123; this.tar = tar; return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; System.out.println("before"); //调用目标对象之前可以做相关操作 result = method.invoke(tar, args); System.out.println("after");//调用目标对象之后可以做相关操作 return result; &#125;&#125; 运行12345678public class Test &#123; public static void main(String[] args) &#123; ProxyHandler proxy = new ProxyHandler(); //绑定该类实现的所有接口 Subject sub = (Subject) proxy.bind(new SubjectImpl()); sub.doSomething(); &#125;&#125;]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
</search>
