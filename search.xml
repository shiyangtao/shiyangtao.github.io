<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程下hashmap死循环]]></title>
    <url>%2F2019%2F02%2F16%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8Bhashmap%E6%AD%BB%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[问题由于HashMap并非是线程安全的，所以在高并发的情况下必然会出现问题，可能发生死循环，导致cpu100%，服务重启之后，问题消失，过段时间可能又复现了。这是为什么 原因分析在了解来龙去脉之前，我们先看看HashMap的数据结构。在内部，HashMap使用一个Entry数组保存key、value数据，当一对key、value被加入时，会通过一个hash算法得到数组的下标index，算法很简单，根据key的hash值，对数组的大小取模 hash &amp; (length-1)，并把结果插入数组该位置，如果该位置上已经有元素了，就说明存在hash冲突，这样会在index位置生成链表。如果存在hash冲突，最惨的情况，就是所有元素都定位到同一个位置，形成一个长长的链表，这样get一个值时，最坏情况需要遍历所有节点，性能变成了O(n)，所以元素的hash值算法和HashMap的初始化大小很重要。当插入一个新的节点时，如果不存在相同的key，则会判断当前内部元素是否已经达到阈值（默认是数组大小的0.75），如果已经达到阈值，会对数组进行扩容，也会对链表中的元素进行rehash。 实现HashMap的put方法实现：1、判断key是否已经存在123456789101112131415161718192021public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); // 如果key已经存在，则替换value，并返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // key不存在，则插入新的元素 addEntry(hash, key, value, i); return null;&#125; 2、检查容量是否达到阈值threshold123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 复制代码如果元素个数已经达到阈值，则扩容，并把原来的元素移动过去。3、扩容实现12345678910111213141516171819202122232425262728void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; ... Entry[] newTable = new Entry[newCapacity]; ... transfer(newTable, rehash); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;这里会新建一个更大的数组，并通过transfer方法，移动元素。``` javavoid transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 移动的逻辑也很清晰，遍历原来table中每个位置的链表，并对每个元素进行重新hash，在新的newTable找到归宿，并插入。 案例分析假设HashMap初始化大小为4，插入个3节点，不巧的是，这3个节点都hash到同一个位置，如果按照默认的负载因子的话，插入第3个节点就会扩容，为了验证效果，假设负载因子是1.123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 以上是节点移动的相关逻辑。 插入第4个节点时，发生rehash，假设现在有两个线程同时进行，线程1和线程2，两个线程都会新建新的数组。 假设 线程2 在执行到Entry&lt;K,V&gt; next = e.next;之后，cpu时间片用完了，这时变量e指向节点a，变量next指向节点b。线程1继续执行，很不巧，a、b、c节点rehash之后又是在同一个位置7，开始移动节点第一步，移动节点a 第二步，移动节点b 注意，这里的顺序是反过来的，继续移动节点c 这个时候 线程1 的时间片用完，内部的table还没有设置成新的newTable， 线程2 开始执行，这时内部的引用关系如下： 继续循环剩余逻辑这时，在 线程2 中，变量e指向节点a，变量next指向节点b，开始执行循环体的剩余逻辑。12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行之后的引用关系如下图执行后，变量e指向节点b，因为e不是null，则继续执行循环体 第二次循环12345Entry&lt;K,V&gt; next = e.next;int i = indexFor(e.hash, newCapacity);e.next = newTable[i];newTable[i] = e;e = next; 执行后的引用关系 变量e又重新指回节点a，只能继续执行循环体 第三次循环12345678// 目前节点a没有next，所以变量next指向null；Entry&lt;K,V&gt; next = e.next;// 其中 newTable[i] 指向节点b，那就是把a的next指向了节点b，这样a和b就相互引用了，形成了一个环e.next = newTable[i]; // 把节点a放到了数组i位置；newTable[i] = e // 把变量e赋值为null，因为第一步中变量next就是指向null；e = next; 所以最终的引用关系是这样的： 节点a和b互相引用，形成了一个环，当在数组该位置get寻找对应的key时，就发生了死循环。另外，如果线程2把newTable设置成到内部的table，节点c的数据就丢了，看来还有数据遗失的问题。 总结所以在并发的情况，发生扩容时，可能会产生循环链表，在执行get的时候，会触发死循环，引起CPU的100%问题，所以一定要避免在并发环境下使用HashMap。曾经有人把这个问题报给了Sun，不过Sun不认为这是一个bug，因为在HashMap本来就不支持多线程使用，要并发就用ConcurrentHashmap。 文章参考 占小狼和coolshell的博客]]></content>
      <tags>
        <tag>java基础</tag>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2019%2F02%2F13%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal是什么jdk文档介绍1234567891011121314/** * This class provides thread-local variables. These variables differ from * their normal counterparts in that each thread that accesses one (via its * &#123;@code get&#125; or &#123;@code set&#125; method) has its own, independently initialized * copy of the variable. &#123;@code ThreadLocal&#125; instances are typically private * static fields in classes that wish to associate state with a thread (e.g., * a user ID or Transaction ID). * * &lt;p&gt;For example, the class below generates unique identifiers local to each * thread. * A thread's id is assigned the first time it invokes &#123;@code ThreadId.get()&#125; * and remains unchanged on subsequent calls. */ 结合我的总结可以这样理解：ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离～。简要言之：往ThreadLocal中填充的变量属于当前线程，该变量对其他线程而言是隔离的。 作用是什么从上面可以得出：ThreadLocal可以让我们拥有当前线程的变量，那这个作用有什么用呢？？？最常见的ThreadLocal使用场景为用来解决 数据库连接、Session管理、避免一些参数传递等例如12345678910private static ThreadLocal&lt;Connection&gt; connectionHolder= new ThreadLocal&lt;Connection&gt;() &#123;public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL);&#125;&#125;; public static Connection getConnection() &#123;return connectionHolder.get();&#125; 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 实现原理Thread、ThreadLocal、ThreadLocalMap、Entry之间的关系 ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。 也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。 ThreadLocalMap由一个个Entry对象构成，Entry的代码如下：12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;，一个Entry由ThreadLocal对象和Object构成。由此可见，Entry的key是ThreadLocal对象，并且是一个弱引用。当没指向key的强引用后，该key就会被垃圾收集器回收。 那么，ThreadLocal是如何工作的呢？下面来看set和get方法。1234567891011121314151617181920212223242526public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; ThreadLocal为什么会内存泄漏ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话(比如线程池线程循环利用)，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄漏。 其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。 但是这些被动的预防措施并不能保证不会内存泄漏： 使用static的ThreadLocal有外部强引用，延长了ThreadLocal的生命周期，可能导致的内存泄漏 分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。(虽然ThreadLocal回收了但是value没有被回收) 为什么使用弱引用从表面上看内存泄漏的根源在于使用了弱引用。网上的文章大多着重分析ThreadLocal使用了弱引用会导致内存泄漏，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？ 我们先来看看官方文档的说法： To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.为了应对非常大和长时间的用途，哈希表使用弱引用的 key。 下面我们分两种情况讨论： key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。 key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。 避免内存泄漏综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？ 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。在使用线程池的情况下，thread的生命周期很长的情况下，没有及时清理ThreadLocal，导致内存泄漏随着应用运行的时间越来越长会导致内存溢出。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表]]></title>
    <url>%2F2019%2F01%2F29%2F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[相比数组，链表是一种稍微复杂一点的数据结构。对于初学者来说，掌握起来也要比数组稍难一些。这两个非常基础、非常常用的数据结构，我们常常将会放到一块儿来比较。所以我们先来看，这两者有什么区别。 链表和数组的区别为了直观地对比，我画了一张图。从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。 单链表我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作“后继指针” 从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址NULL，表示这是链表上最后一个结点。 与数组一样，链表也支持数据的查找、插入和删除操作。 我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 为了方便你理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。 循环链表循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。和单链表相比，循环列表的优点是是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。 双向链表单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。 从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。 你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。我再来带你分析一下链表的两个操作。 删除操作在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中“值等于某个给定值”的结点；这种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。 删除给定指针指向的结点。对于这种种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next=q，说明 p 是 q 的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。你可以参照我刚刚讲过的删除操作自己分析一下。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。 双向循环链表 数组vs链表性能比拼通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。 开发中如何选择不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 我举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？ 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。 链表实现LRU缓存我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果次数据不在链表里 链表满了，删除尾结点，该数据插入头结点 链表还有空间，插入头结点 代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。 实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。 问题数组实现LRU缓存除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？我把这个问题留给你思考。我的思路是这样：维护一个数组，越靠近尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从数组第一个元素开始遍历 如果此数据已经被缓存，我们遍历得到这个数据的下标，并将前面的所有数据都往右移动一位，然后在把该元素放到数据下标0的位置 如果数组不在数组里 数组满了，把最后一个元素之前的元素向右平移一位，最后一个元素自然也就丢弃了，然后把该数据放到下标为0的位置 数组还有空间，把数组里所有元素向右平移一位，然后把该数据放到下标为0的位置代码地址现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍数组，所以这种基于数组的实现思路，缓存访问的时间复杂度为 O(n)。 如何判断一个字符串是回文串如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的思题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？我的思路是：使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。最后比较中点两侧的链表是否相等。代码地址 常见单链表编程题 单链表反转 链表中环的检测 两个有序链表合并 删除倒数第n个代码 求链表中间结点代码地址]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[如何实现随机访问什么是数组？数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。 这个定义里有几个关键词 线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。 而与他对立的是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。 连续的内存空间和相同类型的数据正是有了这个特性，他才有了随机访问这个“杀手锏”。但是有利就有弊，比如删除添加为了保证连续性，必须要做数据搬移工作。说到数据的访问，那你知道数组是如何实现根据下标随机访问数组元素的吗？我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址。1a[i]_address = base_address + i * data_type_size 其中data_type_size表示每个元素的大小。我们这个例子数组中存储的是int类型数组，所以date_type_size就为4个字节。这里特别纠正一个“错误”。面试中经常会问到数组和链表的区别，很多人都会回答，“链表适合插入、删除、时间复杂度O(1);数组适合查找，查找时间复杂度为O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但查找时间复杂度不是O(1)。即便是排序好的数组，你用二分查找时间复杂度才是O(logn)。所以正确的表述是数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。 低效的插入和删除前面提到，数组为了保证内存数组连续性，会导致插入、删除两个操作会比较低效。 插入操作假设数组长度为n，现在，需要把一个数据插入到数组第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要把k～n这部分元素都顺序往后挪一下，那时间复杂度是多少呢？如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。如果数组中的数据是有序的，我们在某个位置插入一个新元素，就必须按照刚才的方法搬移k之后的数组。但是如果数组中的数据没有任何规律，数组只是存储集合。在这种情况下，如果把数据插入第k个位置，为了避免大规模搬移，直接将第k个位置的数据插入到数组最后，把新的元素放在第k个位置。如下图所示 利用这个技巧，在特定场景下，在第k个位置插入元素的复杂度就降到了O(1) 删除操作跟插入操作类似，如果删除第k个位置的数据，为了内存连续性，也需要搬移数据，不然会出现空洞，内存就不连续了。和插入类似，如果删除末尾的数据，时间复杂度O(1);如果删除开头的数据，则最坏情况时间复杂度为O(n);平均情况时间复杂度也为O(n)。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。 为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。 容器能否代替数组？针对数组类型，很多语言提供了容器类，比如java中的ArrayList。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？因为我是java开发，几乎每天都在用ArrayList。个人觉得ArrayList的最大优势就是可以把很多数组操作的细节封装起来。比如插入、删除、动态扩容。 数组本身在定义时需要预先指定大小，因为需要分配连续的内存空间。乳沟我们申请了大小为10的数组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后在插入新的数据。 如果使用ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList已经帮我们实现好了。每次空间不够时，他都会自动扩容为1.5倍大小。 不过，这里需要注意一点，因为扩容需要内存申请和数据搬移，比较耗时。所以，如果事先能去定需要存储数据的大小，最后在创建ArrayList的时候事先指定数据大小。 作为高级语言编程者，是不是数组就无用武之地了？当然不是，一下情况可以用数组。 Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList array。 我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 为什么大多数编程语言数组下标要从0开始而不是1从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：1a[k]_address = base_address + k * type_size 但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：1a[k]_address = base_address + (k-1)*type_size 对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。 数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。 不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非 0 开始不可。所以我觉得最主要的原因可能是历史原因。 C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。]]></content>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2019%2F01%2F26%2F2019-01-28-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[第一版鸭子游戏我们设计了一个鸭子游戏项目，游戏中会出现各种鸭子，为此Joe实现了一个超类Duck，让鸭子子类都继承这个类，如下图所示。 加鸭子会飞的需求使用继承过了几天主管找到Joe说希望有的鸭子能飞，Joe说so easy，只需在超类里增加一个fly()方法就ok了。但是过了几天主管对外演示时发现，橡皮鸭子在屏幕上飞来飞去，非常尴尬。主管打电话开始喷Joe:你可以去看看boss直聘了。Joe忽略了一件事，并非所有鸭子都会飞，他在超类里加上新的行为，会使得不该拥有这个行为的子类也拥有了这个行为。他体会了一件事：当涉及维护时为了复用目的使用继承结局并不完美。 Joe：那么橡皮鸭子类可以重写这个fly方法里边什么也不做，不就可以了吗？主管：那么所有不能飞的子类都得重写一遍fly，然后如果加入木鸭(不会飞不会叫)，也得把quack()方法重写。Joe意思到继承可能无法解决这个问题： 使用接口Joe：那么可以把fly()和quack()方法从超类里拆出来，只有能飞/能叫的鸭子子类实现这个接口主管：这真是个超级糟糕的设计，如果你认为重写几个方法很差劲，但是48个子类都稍微修改下飞行的行为呢？Joe：我去还真是，虽然Flayable和Quackable能解决一部分问题（不再有会飞的橡皮鸭），但是却造成代码无法复用啊，每个会飞的鸭子子类都得实现一个fly()方法哪怕他们的飞的行为是一样的，如果每个fly方法里增加打印日志得需要改48个子类。那咋办呀？ 设计原则一主管：把问题归零把，下面给你介绍一个设计原则：找出应用中可能需要变化的地方，把他们独立出来，不要在和哪些不变的代码混在一起了，把会变化的代码封装起来，好让其他部分不受影响，代码变化引起的bug变少，系统更加有弹性 下面是这个设计原则的另一种思考方式：“把会变化的部分取出并封装起来，以便以后可以轻易的改动或者扩展此部分，而不影响不需要变化的部分“主管：Joe是时候把鸭子的行为从Duck里行为拆出来了！Joe：ok，那么Duck里的行为除了fly和quack有问题外，其他行为一切还算正常，现在要分开变化部分和不变部分了，我打算建立两组类看图 设计原则二那么如何设计那组实现飞行和呱呱叫的的行为的类呢？我们希望一切能有弹性，毕竟，正是一开始鸭子行为没有弹性，才让我们走上现在这条路。我们还想能够“指定”行为到鸭子的实例。比方说，我们想要产生一个新的绿头鸭的实例，并指定特定的“类型”的飞行行为给它。干脆让鸭子的行为可以动态地改变好了。换句话说，我们应该在鸭子类中包含设定行为的方法，这样就可以在“运行时”动态地“改变”绿头鸭的飞行行为。有了这些目标要实现，接着看看第二个设计原则： 我们利用接口代表每个行为，比方说，FlyBehavior和QuackBehavior接口。所以这次鸭子类不回负责实现Fly与Quack接口，反而是由我们制造一组其他类专门实现FlyBehavior与QuackBehavior,这些就称为“行为”类。 这样的设计，可以让飞行和呱呱叫的动作被其他的对象复用，因为这些行为已经与鸭子类无关了。而我们可以新增一些行为，不会影响到既有的行为类，也不会影响“使用”到飞行行为的鸭子类。这么一来，有了继承的“复用”的好处，却没有继承所带来的包袱。 整合鸭子的行为关键在于，鸭子现在会将飞行和呱呱叫“委托”(delegate)别人处理，而不是定义在Duck类(或子类)内的呱呱叫和飞行方法。 1234567891011public class Duck &#123; //每只鸭子都会引用实现QuackBehavior接口的对象。 QuackBehavior quackBehavior; // 还有更多 ....... //鸭子对象不亲自处理呱呱叫的行为，而是委托给quackBehavior引用的对象 public void performQuack()&#123; quckBehavior.quack(); &#125;&#125; UML图 设计原则三“有一个”可能比“是一个”更好。“有一个”关系相当有趣：每一鸭子都有一个FlyBehavior和一个QuackBehavior，好将飞行和呱呱叫委托给它们代为处理。当你将两个类结合起来使用，如同本例一般，这就是组合(composition)。这种做法和“继承”不同的地方在于，鸭子的行为不是继承来的，而是和适当的行为对像“组合来的”。这是一个很重要的技巧。其实是使用了我们的第三个设计原则：]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试题]]></title>
    <url>%2F2019%2F01%2F10%2F%E9%9D%A2%E8%AF%95%2F2019-01-10%2F</url>
    <content type="text"><![CDATA[算法1.对链表进行归并排序，链表可能有环2.b+树b树的区别，优缺点 java基础1.线程池有哪些参数，有哪些作用，如果任务超过核心线程数，会发生什么？https://www.jianshu.com/p/432554383c552.hashset 底层实现维护了一个hashMap3.hashmap，hashtable，concurrentHashMap区别和底层原理hashMap线程不安全，hashtable线程安全set/get都加了synchronized，concurrentHashMap线程安全采用锁分段来实现线程安全 copyOnWriteListhttp://www.importnew.com/25034.html4.String/StringBuffer/StringBuilderString不可变，每次拼接都会新创建一个String对象StringBuffer线程安全，维护一个数组(默认16)，append超过大小会出发Array copyStringBuilder线程非安全，维护一个数组(默认16)，append超过大小会出发Array copy4.公平锁和非公平锁怎么实现的公平锁代码非公平锁代码 总结：公平锁和非公平锁只有两处不同： 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。非公平锁在 CAS 失败后，和公平锁一样都会进入到 tryAcquire 方法，在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。公平锁和非公平锁就这两点区别，如果这两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。 相对来说，非公平锁会有更好的性能，因为它的吞吐量比较大。当然，非公平锁让获取锁的时间变得更加不确定，可能会导致在阻塞队列中的线程长期处于饥饿状态。 5.说说java AQS 原理详细介绍下看看java并发编程实战 关于AQS的章节6.实现一个线程安全的计数器AtomicInteger.incrementAndGet7.synchronized和lock的区别 8.介绍happen-before9.三个线程保证执行顺序https://www.cnblogs.com/kaleidoscope/p/9877174.html jvm1.java 内存模式 #数据库1.连接池底层说下 redis 解决缓存雪崩和缓存穿透的方案https://mp.weixin.qq.com/s/TBCEwLVAXdsTszRVpXhVug?]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql读写分离]]></title>
    <url>%2F2019%2F01%2F05%2Fmysql%2Fmysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[解决问题，读压力，解决不了存储压力读表利用索引提升查询速度，主表可以不建很多索引提升写入速度。 带来问题 主从复制延迟例如：注册完账号后，登陆显示无该用户解决方法 写操作后的读操作指定发给主服务器例如：注册完后，登陆读主库，这种方式和业务强绑定，如果新来的人不知道这样写代码，就会导致一个bug 读从机失败在去读主机（二次读取）对业务无绑定，只需要对底层数据库访问api进行封装即可，实现代价较小，不足之处在于如果有很多二次读取，将大大增加主机读的压力。 关键业务读写全部指向主机，非关键业务采用读写分离例如：注册登陆业务读写全部访问主机，用户介绍、爱好可以采用读写分离。 分配机制1.程序代码封装优点实现简单。缺点每个编程语言都要实现一次，如果主从发生切换，则需要所有系统都修改配置并重启目前开源的 淘宝的TDDL2.中间件封装优点支持多种编程语言，主从切换无感知（中间件可探测主从状态，比如发一个写语句，成功的是主）缺点，实现复杂，所有读写请求经过中间件对性能要求高目前开源的 奇虎360 atlas]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次线上死锁]]></title>
    <url>%2F2018%2F12%2F24%2Fmysql%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[项目做了什么这个项目是为了处理一些任务，实现是启动定时任务去处理这些数据，因为项目上线后是集群的，所以为了避免多个节点处理到相同的数据，我们使用select … where state =0 for update limit 500 来锁住数据，然后update state =2值。这样其他节点就不会重复处理数据了 同事定时任务的代码大概是这样的，我这里用伪代码表示1234567@Transaction //注意使用for update一定要在事务里边processData()&#123;bikeIds = findForUpdate();//select * from test_rawdata where state=0 for update limit 500;//取出数据，然后先状态改成2updateData(bikeIds);//update test_rawdata set state = 2 where bikeId in(bikeIds);&#125; 除了这个地方操作db外，其他地方也有insert delete，所以for update的where条件里必须要有索引，因为如果where 里的字段没有索引的话，for update就不是行锁了，就升级成表锁了。那当处理定时任务时，insert和delete都将会被阻塞，这样并发性太弱了。 12345678910111213CREATE TABLE `test_rawdata` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &apos;主键ID&apos;, `bikeId` varchar(15) NOT NULL COMMENT &apos;车id&apos;, `lat` decimal(11,8) NOT NULL DEFAULT &apos;0.00000000&apos; COMMENT &apos;纬度&apos;, `lng` decimal(11,8) NOT NULL DEFAULT &apos;0.00000000&apos; COMMENT &apos;经度&apos;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建更新时间，默认当前时间&apos;, `state` int(8) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;0表示未处理 1处理中&apos;, `accuracy` smallint(6) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;位置精确度&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uniq_bikeid` (`bikeId`), KEY `idx_time` (`update_time`) USING BTREE, KEY `idx_state` (`state`)) ENGINE=InnoDB AUTO_INCREMENT=8897633 DEFAULT CHARSET=utf8 COMMENT=&apos;车辆原始位置&apos;; trx1123456set autocommit = 0;begin;select * from test_rawdata where state=0 for update;select sleep(8);update test_rawdata set state = 2 where bikeId = &quot;7fd9gSBkZ1&quot;;commit; trx1234set autocommit = 0;begin;delete from test_rawdata where bikeId = &apos;7fd9gSBkZ1&apos;; //在trx sleep时间点执行commit; 发生死锁死锁日志 参考链接innodb的锁 https://zhuanlan.zhihu.com/p/31875702索引和锁 https://zhuanlan.zhihu.com/p/40396971https://www.jianshu.com/p/1dc4250c6f6f]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql事务隔离级别]]></title>
    <url>%2F2018%2F12%2F08%2Fmysql%2Fmysql%E7%9A%84%E5%9B%9B%E7%A7%8D%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/huanongying/p/7021555.html]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql分库分表]]></title>
    <url>%2F2018%2F12%2F05%2Fmysql%2Fmysql%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[业务分库按照业务分库，比如用户、商品、订单分库带来的问题 join 问题不在同一数据库无法join，只能先查一个数据库拿到id列表，在去另外一个库查询 事务问题原本在同一个数据库的不同表的操作可以在同一个事务里边，分散到不同数据库后无法通过事务统一修改。 成本问题 分表 垂直分表把不常用且占用了大量空间的列拆分出去。带了的问题是原来只要查询一次就能获取所有所有列，现在需要查询多次 水平分表 路由 范围路由按照userId的范围分表，特点可能分配不均（例如按照1000万分表，可能一个表有1000万另一个表只有1000），随着数据的增加平滑的扩充新表，原数据不动 hash路由按照hash取模分表，特点分配均匀，但是新增表所有数据需要重新分布，但是使用一致性hash算法可以优化 配置路由增加一个配置表比如 user_router表 包含 user_id,table_id两列,优点灵活，缺点多查询一次表太大了性能也会不好 join需要多次join然后合并 count()多个表count()相加，实现简单去诶单性能较低。增加一个记录数表，性能优化了，但是复杂度增加了，必须要同步记录，但是又不能放在同一事务里处理，因为记录表插入失败不应该回滚业务逻辑 order by数据分散多个字表中，排序无法在数据库中完成，只能由业务或者中间件去分表查询每个子表中的数据然后汇总。]]></content>
      <tags>
        <tag>mysql</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell启动socket]]></title>
    <url>%2F2018%2F12%2F03%2Flinux%E5%91%BD%E4%BB%A4%2Fshell%E5%90%AF%E5%8A%A8socket%2F</url>
    <content type="text"><![CDATA[nc -l localhost 3000 servernc localhost 3000 client]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep]]></title>
    <url>%2F2018%2F11%2F03%2Flinux%E5%91%BD%E4%BB%A4%2Fgrep%2F</url>
    <content type="text"><![CDATA[grep 后面带上-A -B -C 参数可以多显示几行内容 grep -A 5 可以显示匹配内容以及后面的5行内容grep -B 5 可以显示匹配内容以及前面的5行内容grep -C 5 可以显示匹配内容以及前后面的5行内容 grep “” logfile|wc -l 显示匹配的行数]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池构造方法]]></title>
    <url>%2F2018%2F10%2F03%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[Java中的ThreadPoolExecutor类提供了四个构造方法123456789101112131415public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125; 参数解读 corePoolSize: 核心线程大小 maximumPoolSize: 最大线程数 workQueue: 一个阻塞队列，用来存储等待执行的任务，由如下选择ArrayBlockingQueue 有界队列;LinkedBlockingQueue 无界队列;SynchronousQueue同步移交，不是一个真正的队列，而是一种在线程中移交的机制。将一个元素放入到队列中必须有一个线程等待接受这个任务，如果没有线程正在等待，且线程池当前大小小于最大值，那么创建一个新的线程去执行，否则根据饱和机制这个任务将被拒绝 keepAliveTime: 表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； threadFactory：线程工厂，主要用来创建线程；可以自己写个线程工厂来个性化自己的线程比如名字，或者计数 rejectedExecutionHandler:ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务线程创建逻辑ThreadPoolExecutor里execute方法12345678910111213141516171819202122232425262728293031323334353637383940public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); // “线程数” 的整数 int c = ctl.get(); // 如果当前线程数少于核心线程数，那么直接添加一个 worker 来执行任务， // 创建一个新的线程，并把当前任务 command 作为这个线程的第一个任务(firstTask) if (workerCountOf(c) &lt; corePoolSize) &#123; // 添加任务成功，那么就结束了。提交任务嘛，线程池已经接受了这个任务，这个方法也就可以返回了 // 至于执行的结果，到时候会包装到 FutureTask 中。 // 返回 false 代表线程池不允许提交任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 到这里说明，要么当前线程数大于等于核心线程数，要么刚刚 addWorker 失败了 // 如果线程池处于 RUNNING 状态，把这个任务添加到任务队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; /* 这里面说的是，如果任务进入了 workQueue，我们是否需要开启新的线程 * 因为线程数在 [0, corePoolSize) 是无条件开启新的线程 * 如果线程数已经大于等于 corePoolSize，那么将任务添加到队列中，然后进到这里 */ int recheck = ctl.get(); // 如果线程池已不处于 RUNNING 状态，那么移除已经入队的这个任务，并且执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程 // 到这里，我们知道了，这块代码的真正意图是：担心任务提交到队列中了，但是线程都关闭了 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 如果 workQueue 队列满了，那么进入到这个分支 // 以 maximumPoolSize 为界创建新的 worker， // 如果失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125; 1.如果当前线程数少于 corePoolSize，那么提交任务的时候创建一个新的线程，并由这个线程执行这个任务；2.如果当前线程数已经达到 corePoolSize，那么将提交的任务添加到队列中，等待线程池中的线程去队列中取任务；3.如果队列已满，那么创建新的线程来执行任务，需要保证池中的线程数不会超过 maximumPoolSize，如果此时线程数超过了 maximumPoolSize，那么执行拒绝策略 Executors里的三个静态方法 生成固定大小线程池12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 最大线程数设置为与核心线程数相等，此时 keepAliveTime 设置为 0（因为这里它是没用的，即使不为 0，线程池默认也不会回收 corePoolSize 内的线程），任务队列采用 LinkedBlockingQueue，无界队列。 过程分析：刚开始，每提交一个任务都创建一个 worker，当 worker 的数量达到 nThreads 后，不再创建新的线程，而是把任务提交到 LinkedBlockingQueue 中，而且之后线程数始终为 nThreads。 生成只有一个线程的固定线程池，这个更简单，和上面的一样，只要设置线程数为 1 就可以了： 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 生成一个需要的时候就创建新的线程，同时可以复用之前创建的线程（如果这个线程当前没有任务）的线程池： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 核心线程数为 0，最大线程数为 Integer.MAX_VALUE，keepAliveTime 为 60 秒，任务队列采用 SynchronousQueue。这种线程池对于任务可以比较快速地完成的情况有比较好的性能。如果线程空闲了 60 秒都没有任务，那么将关闭此线程并从线程池中移除。所以如果线程池空闲了很长时间也不会有问题，因为随着所有的线程都会被关闭，整个线程池不会占用任何的系统资源。 过程分析：我把 execute 方法的主体黏贴过来，让大家看得明白些。鉴于 corePoolSize 是 0，那么提交任务的时候，直接将任务提交到队列中，由于采用了 SynchronousQueue，所以如果是第一个任务提交的时候，offer 方法肯定会返回 false，因为此时没有任何 worker 对这个任务进行接收，那么将进入到最后一个分支来创建第一个 worker。之后再提交任务的话，取决于是否有空闲下来的线程对任务进行接收，如果有，会进入到第二个 if 语句块中，否则就是和第一个任务一样，进到最后的 else if 分支。1234567891011121314151617int c = ctl.get();// corePoolSize 为 0，所以不会进到这个 if 分支if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get();&#125;// offer 如果有空闲线程刚好可以接收此任务，那么返回 true，否则返回 falseif (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false);&#125;else if (!addWorker(command, false)) reject(command); 参考链接：https://javadoop.com/post/java-thread-pool#%E6%80%BB%E7%BB%93]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式技术栈]]></title>
    <url>%2F2018%2F09%2F21%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88%2F</url>
    <content type="text"><![CDATA[构建分布式系统的目的是增加系统容量，提高系统的可用性，转换成技术方面，也就是完成下面两件事。 大流量处理。通过集群技术把大规模并发请求的负载分散到不同的机器上。 关键业务保护。提高后台服务的可用性，把故障隔离起来阻止多米诺骨牌效应（雪崩效应）。如果流量过大，需要对业务降级，以保护关键业务流转。 说白了就是干两件事。一是提高整体架构的吞吐量，服务更多的并发和流量，二是为了提高系统的稳定性，让系统的可用性更高。 ##提高架构的性能咱们先来看看，提高系统性能的常用技术。 缓存系统。加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、硬盘和 CPU，全都有缓存，这是提高快速访问能力最有效的手段。对于分布式系统下的缓存系统，需要的是一个缓存集群。这其中需要一个 Proxy 来做缓存的分片和路由。 负载均衡系统，是做水平扩展的关键技术。其可以用多台机器来共同分担一部分流量请求。 异步调用。异步系统主要通过消息队列来对请求做排队处理，这样可以把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。这样可以增加系统的吞吐量，但是实时性就差很多了。同时，还会引入消息丢失的问题，所以要对消息做持久化，这会造成“有状态”的结点，从而增加了服务调度的难度。 数据分区和数据镜像。数据分区是把数据按一定的方式分成多个区（比如通过地理位置），不同的数据区来分担不同区的流量。这需要一个数据路由的中间件，会导致跨库的 Join 和跨库的事务非常复杂。而数据镜像是把一个数据库镜像成多份一样的数据，这样就不需要数据路由的中间件了。你可以在任意结点上进行读写，内部会自行同步数据。然而，数据镜像中最大的问题就是数据的一致性问题。 对于一般公司来说，在初期，会使用读写分离的数据镜像方式，而后期会采用分库分表的方式。 #提高架构的稳定性接下来，咱们来看看提高系统系统稳定性的一些常用技术。 服务拆分，主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题。 服务冗余，是为了去除单点故障，并可以支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，冗余这些有状态的服务带来了更高的复杂性。其中一个是弹性伸缩时，需要考虑数据的复制或是重新分片，迁移的时候还要迁移数据到其它机器上。 限流降级。当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，以确保整个架构不会挂掉。这些技术属于保护措施。 高可用架构，通常来说是从冗余架构的角度来保障可用性。比如，多租户隔离，灾备多活，或是数据可以在其中复制保持一致性的集群。总之，就是为了不出单点故障。 高可用运维，指的是 DevOps 中的 CI（持续集成）/CD（持续部署）。一个良好的运维应该是一条很流畅的软件发布管线，其中做了足够的自动化测试，还可以做相应的灰度发布，以及对线上系统的自动化控制。这样，可以做到“计划内”或是“非计划内”的宕机事件的时长最短。 上述这些技术非常有技术含量，而且需要投入大量的时间和精力。 ##分布式系统的关键技术而通过上面的分析，我们可以看到，引入分布式系统，会引入一堆技术问题，需要从以下几个方面来解决。 服务治理。服务拆分、服务调用、服务发现，服务依赖，服务的关键度定义……服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，并对这些服务进行性能和可用性方面的管理。 架构软件管理。服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，以及对服务的编排、聚合、事务处理等服务调度功能。 DevOps。分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要 DevOps 的全流程，其中包括环境构建、持续集成、持续部署等。 自动化运维。有了 DevOps 后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。 资源调度管理。应用层的自动化运维需要基础层的调度支持，也就是云计算 IaaS 层的计算、存储、网络等资源调度、隔离和管理。 整体架构监控。如果没有一个好的监控系统，那么自动化运维和资源调度管理只可能成为一个泡影，因为监控系统是你的眼睛。没有眼睛，没有数据，就无法进行高效的运维。所以说，监控是非常重要的部分。这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控。 流量控制。最后是我们的流量控制，负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里。 此时，你会发现，要做好这么多的技术，或是要具备这么多的能力，简直就是一个门槛，是一个成本巨高无比的技术栈，看着就都头晕。要实现出来得投入多少人力、物力和时间啊。是的，这就是分布式系统中最大的坑。 不过，我们应该庆幸自己生活在了一个非常不错的年代。今天有一个技术叫——Docker，通过 Docker 以及其衍生出来的 Kubernetes 之类的软件或解决方案，大大地降低了做上面很多事情的门槛。Docker 把软件和其运行的环境打成一个包，然后比较轻量级地启动和运行。在运行过程中，因为软件变成了服务可能会改变现有的环境。但是没关系，当你重新启动一个 Docker 的时候，环境又会变成初始化状态。 这样一来，我们就可以利用 Docker 的这个特性来把软件在不同的机器上进行部署、调度和管理。如果没有 Docker 或是 Kubernetes，那么你可以认为我们还活在“原始时代”。现在你知道为什么 Docker 这样的容器化虚拟化技术是未来了吧。因为分布式系统已经是完全不可逆转的技术趋势了。 但是，上面还有很多的技术是 Docker 及其周边技术没有解决的，所以，依然还有很多事情要做。那么，如果是一个一个地去做这些技术的话，就像是我们在撑开一张网里面一个一个的网眼，本质上这是使蛮力的做法。我们希望可以找到系统的“纲”，一把就能张开整张网。那么，这个纲在哪里呢？ ##分布式系统的“纲”总结一下上面讲述的内容，你不难发现，分布式系统有五个关键技术，它们是： 全栈系统监控； 服务 / 资源调度； 流量调度； 状态 / 数据调度； 开发和运维的自动化。 而最后一项——开发和运维的自动化，是需要把前四项都做到了，才有可能实现的。所以，最为关键是下面这四项技术，即应用整体监控、资源和服务调度、状态和数据调度及流量调度，它们是构建分布式系统最最核心的东西。后面的文章中，我会一项一项地解析这些关键技术。 小结回顾一下今天的要点内容。首先，我总结了分布式系统需要干的两件事：一是提高整体架构的吞吐量，服务更多的并发和流量，二是为了提高系统的稳定性，让系统的可用性更高。然后分别从这两个方面阐释，需要通过哪些技术来实现，并梳理出其中的技术难点及可能会带来的问题。最后，欢迎你分享一下你在解决系统的性能和可用性方面使用到的方法和技巧。 虽然 Docker 及其衍生出来的 Kubernetes 等软件或解决方案，能极大地降低很多事儿的门槛。但它们没有解决的问题还有很多，需要掌握分布式系统的五大关键技术，从根本上解决问题。后面我将陆续撰写几篇文章一一阐述这几大关键技术，详见文末给出的《分布式系统架构的本质》系列文章的目录。 分布式系统架构的冰与火 从亚马逊的实践，谈分布式系统的难点 分布式系统的技术栈 分布式系统关键技术：全栈监控 分布式系统关键技术：服务调度 分布式系统关键技术：流量与数据调度 洞悉 PaaS 平台的本质 推荐阅读：分布式系统架构经典资料 推荐阅读：分布式数据调度相关论文]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简历]]></title>
    <url>%2F2018%2F09%2F21%2F%E9%9D%A2%E8%AF%95%2Fjianli%2F</url>
    <content type="text"><![CDATA[个人简介 史洋涛/男/1990 工作年限：4年 手机（微信）：13621204061 邮箱：yangtao.shi@gmail.com 博客：http://shiyangtao.github.io 自我描述 4年＋java开发经验 极客，热爱编程，喜欢专研 渴求自我提升、实现价值 工作认真，积极性高，思路清晰，善于思考，能独立分析和解决问题 责任心强，具有较强的沟通能力及团队合作精神和承受压力能力。 教育背景 2010.9-2014.7 石家庄学院 软件工程 本科（统招） 工作经历北京安信创富科技有限公司 （ 2015.09 - 至今 ） 后端团队leader负责把产品的需求转化为规范的开发计划，并对产品需求进行合理化建议，按计划确保开发工作顺利进行。带三至四人后端团队开发、任务分配，并且主导系统全局分析设计和实施，包括接口的设计，数据库设计，第三方服务接入，根据业务来选择实施落地的技术，最后按质按量的完成项目需求。后期根据业务增长针对性的做优化，比如缓存系统，负载均衡，服务拆分，异步调用削峰，数据分区等，来提高架构的性能和稳定性 客慧来-收银系统（2016.05-至今）基于python-libcef开发的windows桌面收银和云端java结合的智能收银系统, 主要为商家提供除基础收银功能外的智能买单，灵活的营销体系、强大的会员系统、营业手机监控等功能，截止目前有1000+商家把传统收银软件替换成我们的收银系统，更加智能和易用 负责：收银本地和云端产品的接口和数据库的设计，主要模块支付体系、会员体系、营销体系、第三方对接等的开发和功能点的任务分配，根据后期数据增长，需求变化对系统实现功能扩展，服务拆分、性能优化、日志监控、安全性升级等，使系统高性能、高稳定性、安全性。 解决的问题： 客户端数据库：选用sqlite数据库，并使用sqlcipher加密，使用SQLAlchemy作为orm框架来提高开发速度，实现数据库版本控制，数据备份 支付系统：微信支付／支付宝支付／第三方支付（beecloud）的对接，支持多种支付场景（刷卡，扫码，混合），根据商户的各种情况一键切换 小程序工具开发：小程序和公众号用户关联，合并用户，历史数据刷新 会员系统优化：按业务拆分数据库，消息队列(SQS)削峰提高性能，实现用户行为收集高并发 爬取第三方数据：随着对接商家的增多，有会员迁移的需求，有些商家之前使用的平台不支持导出数据，Python Scrapy爬取会员数据 集群化：服务拆分、RPC调用、容器化（Docker Swarm）、日志收集与监控(Amazon CloudWatch)口碑isv（2017.02-至今）该项目是一个基于支付宝平台，为商家提供便捷支付和营销功能，打通商家收银系统，提供更加支付体验，相比口碑同期ISV，我们终端设备插件可实时配置与打通，并且打通速度快，支持设备广，目前仍有2000+家在使用，曾被口碑平台推荐 负责模块：对接口碑功能、商户收银的打通、后期业务增长系统优化、服务拆分、服务冗余 解决的问题： 口碑券状态不同步的问题：采取定时通过口碑提供的接口去同步状态，还有给用户发券失败的错误信息异步分析，如果是因为发送已下架的券，就会主动去把状态修改掉 并发发券提升用户体验：启用多线程去发券，前后端协调一起优化用户体验 结账前优惠计算问题：团队通过多种测试用例来推算口碑券核销的优先级互斥性，并且记录着给用户发放的券，来实现这个需求。虽然这种方式是有误差的，但是灰度上线经运行一段时间后根据log分析准确率很高，用户体验得到了提升，得到了商户的认可 收银软件打通：采用数据库打通机制解决，破解商户收银的数据库，云端和本地client通过websocket通信，本地插件把云端指令集翻译成sql语句通过odbc 去查询商家收银数据库，来获得菜品／桌台／订单数据，保证稳定性和准确性 秒付性能问题：根据后期业务增长，和口碑对isv的高性能和稳定性要求，都使用redis缓存起来常用的查询数据，并且实现服务拆分（重用服务模块），服务冗余（避免单点故障），消息队列削峰（SQS）使用docker 技术实现服务的弹性伸缩，最后通过口碑压测，峰值能达到1000+qps###准成品电商平台 （2015.09-2016.08 ）该项目是一个基于微信平台的一个电商项目，主要向用户出售半成品，项目主要包括：用户登录、用户储值、下单、客服系统、订单消息系统(对商家、对用户)、快递配送系统、后台库存系统、邮件系统，项目截止前，北京有数家半成品供应商，个人消费者10000+，合作小商户等多达1000+，配送基本覆盖了北京全范围 负责模块：用户登陆，微信授权、下单、订单超时、订单配送、拆单、跳单逻辑、库存管理、报表数据等主要模块 遇到的问题： 库存管理：供应商有后台来编辑某个菜品的库存量，库存不足时菜品不能下单，为了避免多人同时下单操作单个菜品的时，引起的并发问题，采用redis的transaction机制，避免高并发引起的库存数量错误问题 订单数量多后数据库压力：分库分表（Sharding-JDBC） 北京源讯信息技术中国有限公司（2014.10 - 2015.09 ） java开发工程师负责公司主要项目维护和个性化开发，性能优化，针对客户反馈出来的问题进行有效的沟通，并解决问题 北京东方飞扬科技有限公司（2013.12 - 2014.09 ） java开发工程师负责公司定制化项目的敏捷开发，参与总体需求分析与架构设计、领域模型设计、数据库设计、SSH架构搭建及JBPM 技能清单 java基础扎实，熟悉Jvm，有jvm调优经验 能够熟练的应用各种框架spring struts hibernate spring Ibatis jpa 熟悉mysql等关系型数据库，以及数据库调优、sql优化，熟练掌握sql语言 熟悉redis，mogodb，dynamodb等非关系型数据库 熟悉Linux操作系统，会使用常用的linux命令，有linux服务器的部署经验 熟悉docker容器技术，docker编排工具 熟悉python语言，用于日常脚本和爬虫 熟悉消息队列 掌握rabbitmq、sqs等消息队列 熟悉分布式、缓存、消息、异步等机制 熟悉aws云平台，dynamodb，s3，sqs模块发]]></content>
      <categories>
        <category>blog</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面试计数器相关]]></title>
    <url>%2F2018%2F05%2F20%2F%E9%9D%A2%E8%AF%95%2F%E9%9D%A2%E8%AF%95-%E8%AE%A1%E6%95%B0%E5%99%A8%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[面试官问：文件里有m个身份证号，统计每个身份证号出现的次数 回答：使用hashMap实现，key作为身份证号ContainsKey12345Map&lt;String, Integer&gt; freq = new HashMap&lt;String, Integer&gt;();public void incr (String word)&#123; int count = freq.containsKey(word) ? freq.get(word) : 0; freq.put(word, count + 1);&#125; 面试官问：还能优化吗 回答：TestForNull12345678910Map&lt;String, Integer&gt; freq = new HashMap&lt;String, Integer&gt;();public void incr (String word)&#123; Integer count = freq.get(word); if (count == null) &#123; freq.put(word, 1); &#125; else &#123; freq.put(word, count + 1); &#125;&#125; 减少调用containsKey方法的开销 面试官问：如果是高并发情况呢 回答：采用ConcurrentHashMap去做，线程安全的 面试官问：高并发下HashMap有什么问题吗 回答：并发情况下使用HashMap造成Race Condition，从而导致死循环，CPU占用率会达到100%博文链接hashMap死循环 面试官问：ok 用ConcurrentHashMap 实现下 回答：12345678910ConcurrentMap &lt;String, Integer&gt; freq = new ConcurrentHashMap &lt;String, Integer&gt;();public void incr (String word)&#123; Integer count = freq.get(word); if (count == null) &#123; freq.put(word, 1); &#125; else &#123; freq.put(word, count + 1); &#125;&#125; 面试官问：确定能实现？ 回答：实现不了 put操作会覆盖，比如两个线程同时进来读到了都是4，那么都会put 5进去，可以给方法加上synchronized锁12345678910ConcurrentMap &lt;String, Integer&gt; freq = new ConcurrentHashMap &lt;String, Integer&gt;();public synchronized void incr (String word)&#123; Integer count = freq.get(word); if (count == null) &#123; freq.put(word, 1); &#125; else &#123; freq.put(word, count + 1); &#125;&#125; 面试官问：嗯嗯 加锁确实能实现，但是性能差点，能优化下吗 回答(当时回答的不好)：能,采用cas方式12345ConcurrentMap&lt;String, AtomicLong&gt; map = new ConcurrentHashMap&lt;String, AtomicLong&gt;();public void incr (String word)&#123; map.putIfAbsent(word, new AtomicLong(0)); map.get(word).incrementAndGet();&#125; 也可以采用 AtomicLongMap，AtomicLongMap是Google Guava项目的一个类，它是线程安全、支持并发访问的，通过CAS方式实现1234AtomicLongMap&lt;String&gt; map = AtomicLongMap.create();public void incr (String word)&#123; map.getAndIncrement(word);&#125; 延伸：AtomicLong – 这组类使用CAS（比较并交换）处理器指令来更新计数器的值。听起来不错，真的是这样吗？是也不是。好的一面是它通过一个直接机器码指令设置值时，能够最小程度地影响其他线程的执行。坏的一面是如果它在与其他线程竞争设置值时失败了，它不得不再次尝试。在高竞争下，这将转化为一个自旋锁，线程不得不持续尝试设置值，无限循环直到成功。这可不是我们想要的方法。让我们进入Java 8的LongAdders]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[必要商城面试]]></title>
    <url>%2F2018%2F05%2F13%2F%E9%9D%A2%E8%AF%95%2F%E5%BF%85%E8%A6%81%E5%95%86%E5%9F%8E%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[无笔试第一轮 你看过哪些java源码 或者框架的源码 项目里用了多线程的地方 线程池相关 数据库隔离 spring 原理 ioc aop 自己设计一个券系统，并画出er图 根据用户的优惠券，快速算出最佳优惠的策略 第二轮 业务数据量大，如何优化 订单超时过期实现（回答延迟mq、redis过期key订阅、Linux定时任务，面试官感觉mq会出现死信，redis或linux会down 有没有更好的方案，没有get到他想考察的点 第三轮 依赖第三方服务，比如支付结果的轮询，如果第三方down掉，支付服务会down或者重启后又down是什么原因（考察http 链接的开销，设置过期时间）]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[boss直聘面试15分钟gg]]></title>
    <url>%2F2018%2F05%2F03%2F%E9%9D%A2%E8%AF%95%2Fboss%E7%9B%B4%E8%81%98%E9%9D%A2%E8%AF%9515%E5%88%86gg%2F</url>
    <content type="text"><![CDATA[#笔试题 hashmap遍历 linux log 查处访问前十的IP地址 三个远程方法a b c 返回类型一样 有一个方法执行完就返回面试讲讲hashmap hashmap的几种构造方法讲讲一致性hash算法]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行时栈帧结构]]></title>
    <url>%2F2018%2F03%2F24%2Fjvm%2F2018-03-24-%E8%BF%90%E8%A1%8C%E6%97%B6%E6%A0%88%E5%B8%A7%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中，因此一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。一个线程中的方法调用链可能会很长，很多方法都同时处于执行状态。对于执行引擎来说，在活动线程中，只有位于栈顶的栈帧才是有效的，称为当前栈帧（CurrentStackFrame），与这个栈帧相关联的方法称为当前方法（CurrentMethod）。执行引擎运行的所有字节码指令都只针对当前栈帧进行操作，在概念模型上，典型的栈帧结构如上图所示。 局部变量表局部变量表用于存放方法参数和方法内定义的局部变量，在java程序编译为Class文件时，就在方法的Code属性的max_locals数据项中明确了该方法所需要分配的局部变量表的最大容量。 局部变量表的容量以变量槽（VariableSlot，下称Slot）为最小单位，一个Slot可以存放一个32位以内的数据类型，Java中占用32位以内的数据类型有boolean、byte、char、short、int、float、reference和returnAddress8种类型。前面6种不需要多加解释，读者可以按照Java语言中对应数据类型的概念去理解它们，而第7种reference类型表示对一个对象实例的引用，虚拟机规范既没有说明它的长度，也没有明确指出这种引用应有怎样的结构。但一般来说，虚拟机实现至少都应当能通过这个引用做到两点，一是从此引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引，二是此引用中直接或间接地查找到对象所属数据类型在方法区中的存储的类型信息，否则无法实现Java语言规范中定义的语法约束。 在方法执行时，虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程的，如果执行的是实例方法（非static的方法），那局部变量表中第0位索引的Slot默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字”this”来访问到这个隐含的参数。其余参数则按照参数表顺序排列，占用从1开始的局部变量Slot，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的Slot。 为了尽可能节省栈帧空间，局部变量表中的Slot是可以重用的，方法体中定义的变量，其作用域并不一定会覆盖整个方法体，如果当前字节码PC计数器的值已经超出了某个变量的作用域，那这个变量对应的Slot就可以交给其他变量使用。不过，这样的设计除了节省栈帧空间以外，还会伴随一些额外的副作用，例如，在某些情况下，Slot的复用会直接影响到系统的垃圾收集行为，请看代码演示。123456789public static void main(String[] args) throws Exception &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; System.gc();&#125;//执行java -verbose:gc SlotTest//结果[GC (System.gc()) 66867K-&gt;66040K(125952K), 0.0164932 secs][Full GC (System.gc()) 66040K-&gt;65813K(125952K), 0.0103833 secs] 代码很简单，即向内存填充了64MB的数据，然后通知虚拟机进行垃圾收集。我们在虚拟机运行参数中加上”-verbose:gc”来看看垃圾收集的过程，发现在System.gc()运行后并没有回收这64MB的内存，没有回收placeholder所占的内存能说得过去，因为在执行System.gc()时，变量placeholder还处于作用域之内，虚拟机自然不敢回收placeholder的内存。那我们把代码修改一下。1234567891011public static void main(String[] args) throws Exception &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; System.gc();&#125;//执行结果[GC (System.gc()) 66867K-&gt;65992K(125952K), 0.0054315 secs][Full GC (System.gc()) 65992K-&gt;65813K(125952K), 0.0111123 secs] 加入了花括号之后，placeholder的作用域被限制在花括号之内，从代码逻辑上讲，在执行System.gc()的时候，placeholder已经不可能再被访问了，但执行一下这段程序，会发现运行结果如下，还是有64MB的内存没有被回收，这又是为什么呢？在解释为什么之前，我们先对这段代码进行第二次修改，在调用System.gc()之前加入一行”int a=0；”1234567891011public static void main(String[] args) throws Exception &#123; &#123; byte[] placeholder = new byte[64 * 1024 * 1024]; &#125; int a = 1; System.gc();&#125;//执行结果[GC (System.gc()) 66867K-&gt;66008K(125952K), 0.0024539 secs][Full GC (System.gc()) 66008K-&gt;277K(125952K), 0.0105643 secs] 这个修改看起来很莫名其妙，但运行一下程序，却发现这次内存真的被正确回收了。placeholder能否被回收的根本原因是：局部变量表中的Slot是否还存有关于placeholder数组对象的引用。第一次修改中，代码虽然已经离开了placeholder的作用域，但在此之后，没有任何对局部变量表的读写操作，placeholder原本所占用的Slot还没有被其他变量所复用，所以作为GCRoots一部分的局部变量表仍然保持着对它的关联。这种关联没有被及时打断，在绝大部分情况下影响都很轻微。但如果遇到一个方法，其后面的代码有一些耗时很长的操作，而前面又定义了占用了大量内存、实际上已经不会再使用的变量，手动将其设置为null值（用来代替那句int a=0，把变量对应的局部变量表Slot清空）便不见得是一个绝对无意义的操作，这种操作可以作为一种在极特殊情形（对象占用内存大、此方法的栈帧长时间不能被回收、方法调用次数达不到JIT的编译条件）下的“奇技”来使用。 代码示例说明了赋null值的操作在某些情况下确实是有用的，但笔者的观点是不应当对赋null值的操作有过多的依赖，更没有必要把它当做一个普遍的编码规则来推广。原因有两点，从编码角度讲，以恰当的变量作用域来控制变量回收时间才是最优雅的解决方法，更关键的是，从执行角度讲，使用赋null值的操作来优化内存回收是建立在对字节码执行概念模型的理解之上的。在虚拟机使用解释器执行时，通常与概念模型还比较接近，但经过JIT编译器后，才是虚拟机执行代码的主要方式，赋null值的操作在经过JIT编译优化后就会被消除掉，这时候将变量设置为null就是没有意义的。字节码被编译为本地代码后，对GCRoots的枚举也与解释执行时期有巨大差别，以前面例子来看，第二个块代码清单在经过JIT编译后，System.gc()执行时就可以正确地回收掉内存，无须加一句”int a = 0;” 关于局部变量表，还有一点可能会对实际开发产生影响，就是局部变量不像前面介绍的类变量（static修饰）那样存在“准备阶段”。通过前面类加载的讲解，我们已经知道类变量有两次赋初始值的过程，一次在准备阶段，赋予系统初始值；另外一次在初始化阶段，赋予程序员定义的初始值。因此，即使在初始化阶段程序员没有为类变量赋值也没有关系，类变量仍然具有一个确定的初始值。但局部变量就不一样，如果一个局部变量定义了但没有赋初始值是不能使用的，不要认为Java中任何情况下都存在诸如整型变量默认为0，布尔型变量默认为false等这样的默认值。如下面代码所示，这段代码其实并不能运行，还好编译器能在编译期间就检查到并提示这一点，即便编译能通过或者手动生成字节码的方式制造出下面代码的效果，字节码校验的时候也会被虚拟机发现而导致类加载失败。 操作数栈操作数栈（OperandStack）也常称为操作栈，它是一个后入先出（LastInFirstOut,LIFO）栈。同局部变量表一样，操作数栈的最大深度也在编译的时候写入到Code属性的max_stacks数据项中。操作数栈的每一个元素可以是任意的Java数据类型，包括long和double。32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。在方法执行的任何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值。 当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。例如，在做算术运算的时候是通过操作数栈来进行的，又或者在调用其他方法的时候是通过操作数栈来进行参数传递的。 举个例子，整数加法的字节码指令iadd^1在运行的时候操作数栈中最接近栈顶的两个元素已经存入了两个int型的数值，当执行这个指令时，会将这两个int值出栈并相加，然后将相加的结果入栈。操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，在编译程序代码的时候，编译器要严格保证这一点，在类校验阶段的数据流分析中还要再次验证这一点。再以上面的iadd指令为例，这个指令用于整型数加法，它在执行时，最接近栈顶的两个元素的数据类型必须为int型，不能出现一个long和一个float使用iadd命令相加的情况。 另外，在概念模型中，两个栈帧作为虚拟机栈的元素，是完全相互独立的。但在大多虚拟机的实现里都会做一些优化处理，令两个栈帧出现一部分重叠。让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样在进行方法调用时就可以共用一部分数据，无须进行额外的参数复制传递，重叠的过程如图所示。 动态链接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接（Dynamic Linking）。我们知道Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就转化为直接引用，这种转化称为静态解析。另外一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。 方法返回值当一个方法开始执行后，只有两种方式可以退出这个方法。 第一种方式是执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者（调用当前方法的方法称为调用者），是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为正常完成出口（Normal Method Invocation Completion）。 另外一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方法的方式称为异常完成出口（Abrupt Method Invocation Completion）。一个方法使用异常完成出口的方式退出，是不会给它的上层调用者产生任何返回值的。 无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。 方法退出的过程实际上就等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强-软-弱-虚引用]]></title>
    <url>%2F2017%2F09%2F21%2Fjvm%2F%E5%BC%BA-%E8%BD%AF-%E5%BC%B1-%E8%99%9A%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在Java语言中，除了基本数据类型外，其他的都是指向各类对象的对象引用；Java中根据其生命周期的长短，将引用分为4类。 1 强引用 特点：我们平常典型编码Object obj = new Object()中的obj就是强引用。通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出OutOfMemoryError运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。 2 软引用 特点：软引用通过SoftReference类实现。 软引用的生命周期比强引用短一些。只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 3 弱引用 弱引用通过WeakReference类实现。 弱引用的生命周期比软引用短。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。 4 虚引用 特点：虚引用也叫幻象引用，通过PhantomReference类来实现。无法通过虚引用访问对象的任何属性或函数。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue);程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。看下边两个例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115import java.lang.ref.*;import java.util.LinkedList;public class ReferenceTest &#123; private static ReferenceQueue&lt;VeryBig&gt; rq = new ReferenceQueue&lt;VeryBig&gt;(); public static void checkQueue() &#123; Reference&lt;? extends VeryBig&gt; ref = null; while ((ref = rq.poll()) != null) &#123; if (ref != null) &#123; System.out.println("In queue: " + ((VeryBigWeakReference) (ref)).id); &#125; &#125; &#125; public static void changeWeakToStrong() &#123; int size = 3; Object o = null; LinkedList&lt;WeakReference&lt;VeryBig&gt;&gt; weakList = new LinkedList&lt;WeakReference&lt;VeryBig&gt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; VeryBigWeakReference veryBigWeakReference = new VeryBigWeakReference(new VeryBig("Weak " + i), rq); weakList.add(veryBigWeakReference); System.out.println("Just created weak: " + weakList.getLast()+" Reference: "+veryBigWeakReference.get()); o = veryBigWeakReference.get();// 把weak 改成strong 最后这个没有被回收 &#125; System.gc(); try &#123; // 下面休息几分钟，让上面的垃圾回收线程运行完成 Thread.currentThread().sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; checkQueue(); System.out.println(o); &#125; public static void recycleWeakTest() &#123; int size = 3; LinkedList&lt;WeakReference&lt;VeryBig&gt;&gt; weakList = new LinkedList&lt;WeakReference&lt;VeryBig&gt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; VeryBigWeakReference veryBigWeakReference = new VeryBigWeakReference(new VeryBig("Weak " + i), rq); weakList.add(veryBigWeakReference); System.out.println("Just created weak: " + weakList.getLast()+" Reference: "+veryBigWeakReference.get()); &#125; System.gc(); try &#123; // 下面休息几分钟，让上面的垃圾回收线程运行完成 Thread.currentThread().sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; checkQueue(); &#125; public static void recycleSoftTest() &#123; int size = 3; LinkedList&lt;SoftReference&lt;VeryBig&gt;&gt; weakList = new LinkedList&lt;SoftReference&lt;VeryBig&gt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; VeryBigSoftReference veryBigSoftReference = new VeryBigSoftReference(new VeryBig("Weak " + i), rq); weakList.add(veryBigSoftReference); System.out.println("Just created weak: " + weakList.getLast()+" Reference: "+veryBigSoftReference.get()); &#125; System.gc(); try &#123; // 下面休息几分钟，让上面的垃圾回收线程运行完成 Thread.currentThread().sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; checkQueue(); &#125; public static void main(String[] args)&#123; changeWeakToStrong();// 弱引用转化成强引用躲过一劫 // recycleWeakTest(); //触发垃圾回收，被扫描到立马会被回收 // recycleSoftTest();// 只有堆内存不够时才会被回收 &#125;&#125; class VeryBig &#123; public String id; // 占用空间,让线程进行回收 byte[] b = new byte[2 * 1024]; public VeryBig(String id) &#123; this.id = id; &#125; protected void finalize() &#123; System.out.println("Finalizing VeryBig " + this); &#125;&#125; class VeryBigWeakReference extends WeakReference&lt;VeryBig&gt; &#123; public String id; public VeryBigWeakReference(VeryBig big, ReferenceQueue&lt;VeryBig&gt; rq) &#123; super(big, rq); this.id = big.id; &#125;&#125;class VeryBigSoftReference extends SoftReference&lt;VeryBig&gt; &#123; public String id; public VeryBigSoftReference(VeryBig big, ReferenceQueue&lt;VeryBig&gt; rq) &#123; super(big, rq); this.id = big.id; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import java.lang.ref.ReferenceQueue;import java.lang.ref.WeakReference;import java.lang.ref.SoftReference;import java.util.HashMap;import java.util.Map;public class RefTest&#123; private static ReferenceQueue&lt;byte[]&gt; rq = new ReferenceQueue&lt;byte[]&gt;(); private static int _1M = 1024 * 1024; public static void strongReferenceTest() &#123; Object value = new Object(); Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i &lt; 10000; i++) &#123; byte[] bytes = new byte[_1M]; map.put(new byte[_1M], value); &#125; System.out.println("map.size-&gt;" + map.size()); &#125; public static void weakReferenceTest() &#123; Object value = new Object(); Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); Thread thread = new Thread(() -&gt; &#123; try &#123; int cnt = 0; WeakReference&lt;byte[]&gt; k; while((k = (WeakReference) rq.remove()) != null) &#123; System.out.println((cnt++) + "回收了:" + k); &#125; &#125; catch(InterruptedException e) &#123; //结束循环 &#125; &#125;); thread.setDaemon(true); thread.start(); for(int i = 0; i &lt; 10000; i++) &#123; byte[] bytes = new byte[_1M]; WeakReference&lt;byte[]&gt; weakReference = new WeakReference&lt;byte[]&gt;(bytes, rq); map.put(weakReference, value); &#125; System.out.println("map.size-&gt;" + map.size()); &#125; public static void softReferenceTest() &#123; Object value = new Object(); Map&lt;Object, Object&gt; map = new HashMap&lt;&gt;(); Thread thread = new Thread(() -&gt; &#123; try &#123; int cnt = 0; SoftReference&lt;byte[]&gt; k; while((k = (SoftReference) rq.remove()) != null) &#123; System.out.println((cnt++) + "回收了:" + k); &#125; &#125; catch(InterruptedException e) &#123; //结束循环 &#125; &#125;); thread.setDaemon(true); thread.start(); for(int i = 0; i &lt; 10000; i++) &#123; byte[] bytes = new byte[_1M]; SoftReference&lt;byte[]&gt; softReference = new SoftReference&lt;byte[]&gt;(bytes, rq); map.put(softReference, value); &#125; System.out.println("map.size-&gt;" + map.size()); &#125; public static void main(String[] args)&#123; // strongReferenceTest(); //out of mermory // softReferenceTest(); // 堆内存不够时会回收 weakReferenceTest();// 垃圾回收扫描到立马会被回收 &#125;&#125;]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载器]]></title>
    <url>%2F2017%2F09%2F21%2Fjvm%2F2017-09-21-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块称为“类加载器”。比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判定等情况。 双亲委派模型从Java虚拟机的角度来讲，只存在两种不同的类加载器： 启动类加载器（BootstrapClassLoader），这个类加载器使用C++语言实现[1]，是虚拟机自身的一部分； 其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。 从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器： 启动类加载器（BootstrapClassLoader）：前面已经介绍过，这个类将器负责将存放在＜JAVA_HOME＞\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，那直接使用null代替即可，如代码清单7-9所示为java.lang.ClassLoader.getClassLoader()方法的代码片段。 1234567891011121314151617/** * Returns the class loader for the class. Some implementations may use * null to represent the bootstrap class loader. This method will return * null in such implementations if this class was loaded by the bootstrap * class loader. */@CallerSensitivepublic ClassLoader getClassLoader() &#123; ClassLoader cl = getClassLoader0(); if (cl == null) return null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader.checkClassLoaderPermission(cl, Reflection.getCallerClass()); &#125; return cl;&#125; 扩展类加载器（ExtensionClassLoader）：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载＜JAVA_HOME＞\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器（ApplicationClassLoader）：这个类加载器由sun.misc.Launcher$App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。这些类加载器之间的关系一般如图所示。双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系来复用父加载器的代码。 工作过程：如果一个类加载器收到一个类加载的请求，它首先不会自己去尝试加载这个类，而是先委派给它的父类加载器去加载，每一个层次的加载器都是如此。因此所有的类加载请求都会传到启动类加载器，只有当父类加载器反馈自己无法完成（它的搜索范围没有找到所需的类）时，子加载器才会自己去加载。 好处：有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。如果读者有兴趣的话，可以尝试去编写一个与rt.jar类库中已有类重名的Java类，将会发现可以正常编译，但永远无法被加载运行。 实现:双亲委派模型对于保证Java程序的稳定运作很重要，但它的实现却非常简单，实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass()方法之中。123456789101112131415161718192021222324252627282930313233343536373839protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded // 检查类是否已经被加载过了 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader // 如果父类抛出ClassNotFoundException //说明父类无法完成加载请求 &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. // 在父类无法加载的时候调用自身的findClass进行加载 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; 破坏双亲委派模型上文提到过双亲委派模型并不是一个强制性的约束模型，而是Java设计者推荐给开发者的类加载器实现方式。在Java的世界中大部分的类加载器都遵循这个模型，但也有例外，到目前为止，双亲委派模型主要出现过3较大规模的“被破坏”情况。 第一次破坏&emsp;&emsp;由于双亲委派模型在JDK1.2之后才被引入，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个新的protected方法findClass()，在JDK1.2之前，用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，因为虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法的唯一逻辑就是去调用自己的loadClass()。JDK1.2之后已不提倡用户再去覆盖loadClass()方法，而应当把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里如果父类加载失败，则会调用自己的findClass()方法来完成加载，这样就可以保证新写出来的类加载器是符合双亲委派规则的。 第二次破坏&emsp;&emsp;双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美，如果基础类又要调用回用户的代码，那该怎么办？这并非是不可能的事情，一个典型的例子便是JNDI服务，JNDI现在已经是Java的标准服务，它的代码由启动类加载器去加载（在JDK1.3时放进去的rt.jar），但JNDI的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者（SPI,ServiceProviderInterface）的代码，但启动类加载器不可能“认识”这些代码啊!那该怎么办？&emsp;&emsp;为了解决这个问题，Java设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（ThreadContextClassLoader）。这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。&emsp;&emsp;有了线程上下文类加载器，就可以做一些“舞弊”的事情了，JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java中所有涉及SPI的加载动作基本上都采用这种方式，例如JNDI、JDBC、JCE、JAXB和JBI等。 第三次破坏&emsp;&emsp;双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的，这里所说的“动态性”指的是当前一些非常“热门”的名词：代码热替换（HotSwap）、模块热部署（HotDeployment）等，说白了就是希望应用程序能像我们的计算机外设那样，接上鼠标、U盘，不用重启机器就能立即使用，鼠标有问题或要升级就换个鼠标，不用停机也不用重启。对于个人计算机来说，重启一次其实没有什么大不了的，但对于一些生产系统来说，关机重启一次可能就要被列为生产事故，这种情况下热部署就对软件开发者，尤其是企业级软件开发者具有很大的吸引力。&emsp;&emsp;Sun公司所提出的JSR-294[1]、JSR-277[2]规范在与JCP组织的模块化规范之争中落败给JSR-291（即OSGiR4.2），虽然Sun不甘失去Java模块化的主导权，独立在发展Jigsaw项目，但目前OSGi已经成为了业界“事实上”的Java模块化标准，而OSGi实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块（OSGi中称为Bundle）都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。&emsp;&emsp;这里“被破坏”并不带有贬义的感情色彩。只要有足够意义和理由，突破已有的原则就可认为是一种创新。正如OSGi中的类加载器并不符合传统的双亲委派的类加载器，并且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议，但在Java程序员中基本有一个共识：OSGi中对类加载器的使用是很值得学习的，弄懂了OSGi的实现，就可以算是掌握了类加载器的精髓。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载过程]]></title>
    <url>%2F2017%2F07%2F28%2Fjvm%2F2017-07-28-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[接下来我们详细讲解一下Java虚拟机中类加载的全过程，也就是加载、验证、准备、解析和初始化这5个阶段所执行的具体动作。 ##加载加载(loading) 是类加载(class loading)的一个过程,不要混淆。加载分三步: 通过一个类的全限定名来获取定义此类的二进制字节流并没有指明二进制字节流要从class文件里获取可以是其他方式 从ZIP包中读取，这很常见，最终成为日后JAR、EAR、WAR格式的基础。 从网络中获取，这种场景最典型的应用就是Applet。 运行时计算生成，这种场景使用得最多的就是动态代理技术，在java.lang.reflect.Proxy中，就是用了ProxyGenerator.generateProxyClass来为特定接口生成形式为”*$Proxy”的代理类的二进制字节流。 由其他文件生成，典型场景是JSP应用，即由JSP文件生成对应的Class类。从数据库中读取，这种场景相对少见些，例如有些中间件服务器（如SAPNetweaver）可以选择把程序安装到数据库中来完成程序代码在集群间的分发。……. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，方法区中的数据存储格式由虚拟机实现自行定义，虚拟机规范未规定此区域的具体数据结构。然后在内存中实例化一个java.lang.Class类的对象（并没有明确规定是在Java堆中，对于HotSpot虚拟机而言，Class对象比较特殊，它虽然是对象，但是存放在方法区里面），这个对象将作为程序访问方法区中的这些类型数据的外部接口。 加载阶段与连接阶段的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的内容，这两个阶段的开始时间仍然保持着固定的先后顺序。 ##验证 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 Java语言本身是相对安全的语言（依然是相对于C/C++来说），使用纯粹的Java代码无法做到诸如访问数组边界以外的数据、将一个对象转型为它并未实现的类型、跳转到不存在的代码行之类的事情，如果这样做了，编译器将拒绝编译。但前面已经说过，Class文件并不一定要求用Java源码编译而来，可以使用任何途径产生，甚至包括用十六进制编辑器直接编写来产生Class文件。在字节码语言层面上，上述Java代码无法做到的事情都是可以实现的，至少语义上是可以表达出来的。虚拟机如果不检查输入的字节流，对其完全信任的话，很可能会因为载入了有害的字节流而导致系统崩溃，所以验证是虚拟机对自身保护的一项重要工作。分为以下几步 文件格式验证第一阶段要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。这一阶段可能包括下面这些验证点： 是否以魔数0xCAFEBABE开头。 主、次版本号是否在当前虚拟机处理范围之内。 常量池的常量中是否有不被支持的常量类型（检查常量tag标志）。 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。 CONSTANT_Utf8_info型的常量中是否有不符合UTF8编码的数据。 Class文件中各个部分及文件本身是否有被删除的或附加的其他信息。…这阶段的验证是基于二进制字节流进行的，只有通过了这个阶段的验证后，字节流才会进入内存的方法区中进行存储，所以后面的3个验证阶段全部是基于方法区的存储结构进行的，不会再直接操作字节流。 元数据验证第二阶段是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求，这个阶段可能包括的验证点如下： 这个类是否有父类（除了java.lang.Object之外，所有的类都应当有父类）。 这个类的父类是否继承了不允许被继承的类（被final修饰的类）。 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法。 类中的字段、方法是否与父类产生矛盾（例如覆盖了父类的final字段，或者出现不符合规则的方法重载，例如方法参数都一致，但返回值类型却不同等）。……第二阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证第三阶段是整个验证过程中最复杂的一个阶段，主要目的是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。在第二阶段对元数据信息中的数据类型做完校验后，这个阶段将对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，例如： 在操作栈放置了一个int类型的数据，使用时却按long类型来加载入本地变量表中。 保证跳转指令不会跳转到方法体以外的字节码指令上。 保证方法体中的类型转换是有效的，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但是把父类对象赋值给子类数据类型，甚至把对象赋值给与它毫无继承关系、完全不相干的一个数据类型，则是危险和不合法的。……如果一个类方法体的字节码没有通过字节码验证，那肯定是有问题的；但如果一个方法体通过了字节码验证，也不能说明其一定就是安全的。即使字节码验证之中进行了大量的检查，也不能保证这一点。 符号引用验证最后一个阶段的校验发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段——解析阶段中发生。符号引用验证可以看做是对类自身以外（常量池中的各种符号引用）的信息进行匹配性校验，通常需要校验下列内容： 符号引用中通过字符串描述的全限定名是否能找到对应的类。 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。 符号引用中的类、字段、方法的访问性（private、protected、public、default）是否可被当前类访问。……符号引用验证的目的是确保解析动作能正常执行，如果无法通过符号引用验证，那么将会抛出一个java.lang.IncompatibleClassChangeError异常的子类，如java.lang.IllegalAccessError、java.lang.NoSuchFieldError、java.lang.NoSuchMethodError等。对于虚拟机的类加载机制来说，验证阶段是一个非常重要的、但不是一定必要（因为对程序运行期没有影响）的阶段。如果所运行的全部代码（包括自己编写的及第三方包中的代码）都已经被反复使用和验证过，那么在实施阶段就可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 ##准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值，假设一个类变量的定义为： 1public static int value=123； 那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞()方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。 上面提到，在“通常情况”下初始值是零值，那相对的会有一些“特殊情况”：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，假设上面类变量value的定义变为：1public static final int value=123； 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。 ##解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程 符号引用（SymbolicReferences）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。 直接引用（DirectReferences）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。 虚拟机规范之中并未规定解析阶段发生的具体时间，只要求了在执行anewarray(创建一个引用类型的数组)、checkcast(检验类型转换，校验未通过抛出ClassCastException)、getfield(获得指定类型的实例域)、getstatic(获得指定类型的静态域)、instanceof(检查对象是否是指定类的实例)、invokedynamic(调用动态链接方法)、invokeinterface(调用接口方法)、invokespecial(调用超类构造方法)、invokestatic(调用静态方法)、invokevirtual(调用实例方法)、ldc、ldc_w、multianewarray(创建指定类型的多维度数组)、new、putfield(为指定的类的实例域赋值)和putstatic(为指定的类的静态域赋值)这16个用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析。所以虚拟机实现可以根据需要来判断到底是在类被加载器加载时就对常量池中的符号引用进行解析，还是等到一个符号引用将要被使用前才去解析它。 对同一个符号引用进行多次解析请求是很常见的事情，除invokedynamic指令以外，虚拟机实现可以对第一次解析的结果进行缓存（在运行时常量池中记录直接引用，并把常量标识为已解析状态）从而避免解析动作重复进行。无论是否真正执行了多次解析动作，虚拟机需要保证的是在同一个实体中，如果一个符号引用之前已经被成功解析过，那么后续的引用解析请求就应当一直成功；同样的，如果第一次解析失败了，那么其他指令对这个符号的解析请求也应该收到相同的异常。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行，分别对应于常量池的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info和CONSTANT_InvokeDynamic_info7种常量类型，下面将讲解前4种类型的解析过程 类或接口的解析假设当前代码所处的类为D，如果要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用，那虚拟机完成整个解析的过程需要以下3个步骤：1）如果C不是一个数组类型，那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。在加载过程中，由于元数据验证、字节码验证的需要，又可能触发其他相关类的加载动作，例如加载这个类的父类或实现的接口。一旦这个加载过程出现了任何异常，解析过程就宣告失败。2）如果C是一个数组类型，并且数组的元素类型为对象，也就是N的描述符会是类似”[Ljava/lang/Integer”的形式，那将会按照第1点的规则加载数组元素类型。如果N的描述符如前面所假设的形式，需要加载的元素类型就是”java.lang.Integer”，接着由虚拟机生成一个代表此数组维度和元素的数组对象。3）如果上面的步骤没有出现任何异常，那么C在虚拟机中实际上已经成为一个有效的类或接口了，但在解析完成之前还要进行符号引用验证，确认D是否具备对C的访问权限。如果发现不具备访问权限，将抛出java.lang.IllegalAccessError异常。 字段解析要解析一个未被解析过的字段符号引用，首先将会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析，也就是字段所属的类或接口的符号引用。如果在解析这个类或接口符号引用的过程中出现了任何异常，都会导致字段符号引用解析的失败。如果解析成功完成，那将这个字段所属的类或接口用C表示，虚拟机规范要求按照如下步骤对C进行后续字段的搜索。1）如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束。2）否则，如果在C中实现了接口，将会按照继承关系从下往上递归搜索各个接口和它的父接口，如果接口中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束。3）否则，如果C不是java.lang.Object的话，将会按照继承关系从下往上递归搜索其父类，如果在父类中包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束。4）否则，查找失败，抛出java.lang.NoSuchFieldError异常。如果查找过程成功返回了引用，将会对这个字段进行权限验证，如果发现不具备对字段的访问权限，将抛出java.lang.IllegalAccessError异常。 类方法解析类方法解析的第一个步骤与字段解析一样，也需要先解析出类方法表的class_index项中索引的方法所属的类或接口的符号引用，如果解析成功，我们依然用C表示这个类，接下来虚拟机将会按照如下步骤进行后续的类方法搜索。1）类方法和接口方法符号引用的常量类型定义是分开的，如果在类方法表中发现class_index中索引的C是个接口，那就直接抛出java.lang.IncompatibleClassChangeError异常。2）如果通过了第1步，在类C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。3）否则，在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。4）否则，在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法，如果存在匹配的方法，说明类C是一个抽象类，这时查找结束，抛出java.lang.AbstractMethodError异常。5）否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError。最后，如果查找过程成功返回了直接引用，将会对这个方法进行权限验证，如果发现不具备对此方法的访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用，如果解析成功，依然用C表示这个接口，接下来虚拟机将会按照如下步骤进行后续的接口方法搜索。1）与类方法解析不同，如果在接口方法表中发现class_index中的索引C是个类而不是接口，那就直接抛出java.lang.IncompatibleClassChangeError异常。2）否则，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。3）否则，在接口C的父接口中递归查找，直到java.lang.Object类（查找范围会包括Object类）为止，看是否有简单名称和描述符都与目标相匹配的方法，如果有则返回这个方法的直接引用，查找结束。4）否则，宣告方法查找失败，抛出java.lang.NoSuchMethodError异常。由于接口中的所有方法默认都是public的，所以不存在访问权限的问题，因此接口方法的符号解析应当不会抛出java.lang.IllegalAccessError异常。 ##初始化类初始化阶段是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码（或者说是字节码）。对于初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”参考 在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器＜clinit＞()方法的过程。我们在下文会讲解＜clinit＞()方法是怎么生成的，在这里，我们先看一下＜clinit＞()方法执行过程中一些可能会影响程序运行行为的特点和细节，这部分相对更贴近于普通的程序开发人员。 ＜clinit＞()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问，如代码清单中的例子所示。12345static &#123; i = 0;//给变量赋值可以编译通过 System.out.println(i);//编译器提示非法的向前引用 &#125;static int i = 1; ＜clinit＞()方法与类的构造函数（或者说实例构造器＜init＞()方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的＜clinit＞()方法执行之前，父类的＜clinit＞()方法已经执行完毕。因此在虚拟机中第一个被执行的＜clinit＞()方法的类肯定是java.lang.Object。 由于父类的＜clinit＞()方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作，如在代码清单中，字段B的值将会是2而不是1。1234567891011121314class Parent &#123; public static int A = 1; static &#123; A = 2; &#125;&#125;class Sub extends Parent &#123; public static int B = A;&#125; public static void main(String[] args) &#123; System.out.println(Sub.B);&#125; ＜clinit＞()方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成＜clinit＞()方法。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载时机]]></title>
    <url>%2F2017%2F05%2F04%2Fjvm%2F2017-05-04-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%97%B6%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定）。加载什么情况下需要开始类加载过程的第一个阶段：加载？Java虚拟机规范中并没有进行强制约束，这点可以交给虚拟机的具体实现来自由把握。 对于初始化阶段，虚拟机规范则是严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 1）遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外（看实例三））的时候，以及调用一个类的静态方法的时候。 2）使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 3）当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 4）当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 5）当使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 除此之外，所有引用类的方式都不会触发初始化，称为被动引用。上述代码运行之后，只会输出”SuperClassinit！”，而不会输出”SubClassinit！”。对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 运行之后发现没有输出”SuperClassinit！”，说明并没有触发类org.fenixsoft.classloading.SuperClass的初始化阶段。但是这段代码里面触发了另外一个名为”[Lorg.fenixsoft.classloading.SuperClass”的类的初始化阶段，对于用户代码来说，这并不是一个合法的类名称，它是一个由虚拟机自动生成的、直接继承于java.lang.Object的子类，创建动作由字节码指令newarray触发。这个类代表了一个元素类型为org.fenixsoft.classloading.SuperClass的一维数组，数组中应有的属性和方法（用户可直接使用的只有被修饰为public的length属性和clone()方法）都实现在这个类里。上述代码运行之后，也没有输出”ConstClassinit！”，这是因为虽然在Java源码中引用了ConstClass类中的常量HELLOWORLD，但被final修饰在编译阶段通过常量传播优化，已经将此常量的值”helloworld”存储到了NotInitialization类的常量池中，以后NotInitialization对常量ConstClass.HELLOWORLD的引用实际都被转化为NotInitialization类对自身常量池的引用了。 接口与类真正有所区别的是前面讲述的5种“有且仅有”需要开始初始化场景中的第3种：当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存分配与回收策略]]></title>
    <url>%2F2017%2F04%2F03%2Fjvm%2F2017-04-03-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[Java技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存以及回收分配给对象的内存。对象主要分配在堆上的Eden，如果启用的TLAB，那优先在TLAB上分配，少数情况会直接分配到老年代中，分配的规则不会100%确定的，取决于使用什么垃圾收集器，还有虚拟机相关参数设置接下来我们在Serial／Serial Old收集器下验证几种规则 1. 对象优先在Eden中分配 执行javac Test.javajava -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC Test结果 #####解析:-Xms20M、-Xmx20M、-Xmn10M这3个参数限制了Java堆大小为20MB，不可扩展，其中10MB分配给新生代，剩下的10MB分配给老年代。-XX:SurvivorRatio=8决定了新生代中Eden区与一个Survivor区的空间比例是8:1，从输出的结果也可以清晰地看到”edenspace8192K、fromspace1024K、tospace1024K”的信息，新生代总可用空间为9216KB（Eden区+1个Survivor区的总容量），-XX:UseSerialGC 指定使用Serial收集器。 执行testAllocation()中分配allocation4对象的语句时会发生一次MinorGC，这次GC的结果是新生代6816KB变为279KB，而总内存占用量则几乎没有减少（因为allocation1、allocation2、allocation3三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。这次GC发生的原因是给allocation4分配内存的时候，发现Eden已经被占用了6MB，剩余空间已不足以分配allocation4所需的4MB内存，因此发生MinorGC。GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间（Survivor空间只有1MB大小），所以只好通过分配担保机制提前转移到老年代去。 这次GC结束后，4MB的allocation4对象顺利分配在Eden中，因此程序执行完的结果是Eden占用4MB（被allocation4占用），Survivor空闲，老年代被占用6MB（被allocation1、allocation2、allocation3占用）。通过GC日志可以证实这一点 2. 大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组（笔者列出的例子中的byte[]数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息（替Java虚拟机抱怨一句，比遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制javac Test.javajava -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC Testjava -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC -XX:PretenureSizeThreshold=3145728 Test第一次直接分配在了eden空间，第二次指定-XX:PretenureSizeThreshold参数为3MB（就是3145728，这个参数不能像-Xmx之类的参数一样直接写3MB），因此超过3MB的对象都会直接在老年代进行分配，所以第二次老年代内存占比40%。注意PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效，ParallelScavenge收集器不认识这个参数，ParallelScavenge收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑ParNew加CMS的收集器组合。 3. 长期存活的对象进入老年代既然虚拟机采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中。为了做到这点，虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次MinorGC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次MinorGC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置。读者可以试试分别以-XX:MaxTenuringThreshold=1和-XX:MaxTenuringThreshold=15两种设置来执行代码 javac Test.javajava -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC -XX:MaxTenuringThreshold=1 Testjava -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:+UseSerialGC -XX:MaxTenuringThreshold=15 Test此方法中的allocation1对象需要(1024/5)KB内存，Survivor空间可以容纳。当MaxTenuringThreshold=1时，allocation1对象在第二次GC发生时进入老年代，新生代已使用的内存GC后非常干净地变成0KB。而MaxTenuringThreshold=15时，第二次GC发生后，allocation1对象则还留在新生代Survivor空间，这时新生代仍然有482KB被占用。 4. 动态年龄判定为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 5. 空间分配担保 JDK6Update24之前：下面解释一下“冒险”是冒了什么风险，前面提到过，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行FullGC来让老年代腾出更多空间。取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次MinorGC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（HandlePromotionFailure）。如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次FullGC。虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免FullGC过于频繁。 在JDK6Update24之后： HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。JDK6Update24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行MinorGC，否则将进行FullGC。 6. 小节内存回收与垃圾收集器在很多时候都是影响系统性能、并发能力的主要因素之一，虚拟机之所以提供多种不同的收集器以及提供大量的调节参数，是因为只有根据实际应用需求、实现方式选择最优的收集方式才能获取最高的性能。没有固定收集器、参数组合，也没有最优的调优方法，虚拟机也就没有什么必然的内存回收行为。 日志里GC和FullGC概念：GC日志开头的”[GC”和”[FullGC”说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC的。如果有”Full”，说明这次GC是发生了Stop-The-World的，新生代收集器ParNew的日志也会出现”[FullGC”（这一般是因为出现了分配担保失败之类的问题，所以才导致STW）。如果是调用System.gc()方法所触发的收集，那么在这里将显示”[FullGC（System）”。 多次提到的MinorGC和FullGC有什么不一样吗？： 新生代GC（MinorGC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以MinorGC非常频繁，一般回收速度也比较快。 老年代GC（MajorGC/FullGC）：指发生在老年代的GC，出现了MajorGC，经常会伴随至少一次的MinorGC（但非绝对的，在ParallelScavenge收集器的收集策略里就有直接进行MajorGC的策略选择过程）。MajorGC的速度一般会比MinorGC慢10倍以上。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书方法]]></title>
    <url>%2F2017%2F02%2F03%2F%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F%E8%AF%BB%E4%B9%A6%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.构思出知识地图 2.系统的学习 读完一本书需要了解到的六个问题1.出现的背景，初衷，为了解决什么问题2.适用的场景3.用法4.底层原理5.优缺点6.对比其他]]></content>
      <tags>
        <tag>学习心得</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现阶段学习路线]]></title>
    <url>%2F2017%2F02%2F03%2F%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F%E8%A1%A5%E5%BC%BA%E8%B7%AF%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[Java Jvm 书籍《深入理解java虚拟机》 极客专栏《Java36讲》 并发编程 书籍《Java 并发编程实战》线程安全、锁机制看并发工具的源代码ReentrantLock和Condition、ReentrantReadWriteLock、CountDownLatch、CyclicBarrier、Semphore、线程池 Spring《spring 实战》《spring boot实战》《精通spring4.x》清楚AOP IOC Java NIO IBM&lt;nio入门&gt; 《netty实战》清楚PPC TPC Reactor模型数据结构算法 《算法图解》 极客专栏的《数据结构与算法分析》 《数据结构与算法分析-C语言描述》网络 刘超网络专栏《趣谈网络协议》 熟悉TCP UDP 《图解TCP/IP》 《TCP/IP详解 卷1：协议》MySQL 极客专栏《MySQL实战45讲》 《高性能MySQL》 了解下什么时候需要读写分离、分库分表，带来的问题有哪些？有哪些解决方法 了解下主备、主从、主备切换、主从切换、主主，每种模式适用的场景？带来的问题有哪些？有哪些解决方法Redis 《Redis设计与实现》 缓存雪崩，缓存穿透了解下原因解决方法有哪些linux w3school-linux 熟悉常用linux命令 《鸟哥linux私房菜》分布式架构 极客专栏《从0开始学架构》 极客专栏《左耳听风》]]></content>
      <tags>
        <tag>学习心得</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集器]]></title>
    <url>%2F2017%2F01%2F14%2Fjvm%2F2017-01-14-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。这里讨论的收集器基于JDK1.7Update14之后的HotSpot虚拟机（在这个版本中正式提供了商用的G1收集器，之前G1仍处于实验状态），这个虚拟机包含的所有收集器如图所示。 1. Serial收集器serial是历史最悠久的收集器，是jdk1.3.1以前新生代收集器的唯一选择。是一个单线程的收集器，在它垃圾回收时必须暂停其他所有线程，直到它回收结束写到这里是不是感觉Serial收集器应该被淘汰？但实际上到现在为止，它依然是虚拟机运行在Client模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial收集器对于运行在Client模式下的虚拟机来说是一个很好的选择。 2. ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、StopTheWorld、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 3. Parallel Scavenge收集器ParallelScavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和ParNew都一样，那它有什么特别之处呢？ParallelScavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 它提供两个参数来精确控制吞吐量 * 控制最大垃圾收集停顿时间的**-XX:MaxGCPauseMillis**参数 不要以为把这个参数设置的越小，就是收集的越快，这个以牺牲吞吐量和新生代空间换来的系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。 * 直接设置吞吐量大小的**-XX:GCTimeRatio**参数。 GCTimeRatio参数的值应当是一个大于0且小于100的整数，如果把此参数设置为19，那允许的最大GC时间就占总时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集时间。 除上述两个参数之外，ParallelScavenge收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GCErgonomics）。 自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。 4. Serial Old收集器mark-sweep-compactSerialOld是Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-清理-压缩算法”算法。用途: 这个收集器的主要意义也是在于给Client模式下的虚拟机使用。 Server模式下有两种用途 JDK1.5以及之前的版本中与ParallelScavenge收集器搭配使用 ^1。 作为CMS收集器的后备预案，在并发收集发生ConcurrentModeFailure时使用。 5. Parallel Old收集器ParallelOld是ParallelScavenge收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器是在JDK1.6中才开始提供的，在此之前，新生代的ParallelScavenge收集器一直处于比较尴尬的状态。^2直到ParallelOld收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑ParallelScavenge加ParallelOld收集器。 6. CMS收集器CMS（ConcurrentMarkSweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。是基于标记-清除算法实现的。 运作过程分为四个步骤： 初始标记（CMSinitialmark）需要“Stop The World ” 标记一下GC Root 可以直接关联的对象，速度很快 并发标记（CMSconcurrentmark）进行GCRootsTracing的过程 重新标记（CMSremark）需要“Stop The World”，重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 并发清除（CMSconcurrentsweep） 有三个明显缺点 CMS收集器对cpu资源非常敏感CMS默认启动的回收线程数是（CPU数量+3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大，如果本来CPU负载就比较大，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。 CMS收集器无法处理浮动垃圾（FloatingGarbage）^3，可能出现”ConcurrentModeFailure”失败而导致另一次FullGC的产生。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。在JDK1.5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX:CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK1.6中，CMS收集器的启动阈值已经提升至92%。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次&quot;ConcurrentModeFailure&quot;失败，这时虚拟机将启动后备预案：临时启用SerialOld收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX:CMSInitiatingOccupancyFraction设置得太高很容易导致大量&quot;ConcurrentModeFailure&quot;失败，性能反而降低。 CMS是一款基于“标记—清除”算法实现的收集器，如果读者对前面这种算法介绍还有印象的话，就可能想到这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC。为了解决这个问题，CMS收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的FullGC后，跟着来一次带压缩的（默认值为0，表示每次进入FullGC时都进行碎片整理）。 7. G1收集器G1(Garbage-First) 收集器是当今收集器技术醉前沿的成果之一。是面向服务端应用的垃圾收集器。相对其他收集器有以下特点 并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。 空间整合：与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。但是不是想象的那么简单的,还需要维护一个Remebered Set^4 如果不计算维护RememberedSet^4的操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记（InitialMarking）初始标记阶段仅仅只是标记一下GCRoots能直接关联到的对象，并且修改TAMS（NextTopatMarkStart）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（ConcurrentMarking）并发标记阶段是从GCRoot开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（FinalMarking）最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程RememberedSetLogs里面，最终标记阶段需要把RememberedSetLogs的数据合并到RememberedSet中，这阶段需要停顿线程，但是可并行执行。 筛选回收（LiveDataCountingandEvacuation）最后在筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用RememberedSet来避免全堆扫描的。G1中每个Region都有一个与之对应的RememberedSet，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个WriteBarrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过CardTable把相关引用信息记录到被引用对象所属的Region的RememberedSet之中。当进行内存回收时，在GC根节点的枚举范围中加入RememberedSet即可保证不对全堆扫描也不会有遗漏。 各种垃圾回收器算法]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在同一个类中，一个方法调用另外一个有注解（比如@Async，@Transational）的方法，注解失效的原因和解决方法]]></title>
    <url>%2F2016%2F12%2F05%2Fspring%2F%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%B8%AD%EF%BC%8C%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AA%E6%9C%89%E6%B3%A8%E8%A7%A3%EF%BC%88%E6%AF%94%E5%A6%82%40Async%EF%BC%8C%40Transational%EF%BC%89%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E6%B3%A8%E8%A7%A3%E5%A4%B1%E6%95%88%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/clementad/article/details/47339519]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HotSpot算法实现]]></title>
    <url>%2F2016%2F07%2F15%2Fjvm%2F2016-07-15-HotSpot%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[枚举根结点可达性算法是相当耗时的，以下两点说明 从可达性分析中从GCRoots节点找引用链这个操作为例，可作为GCRoots的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。 可达性分析对执行时间的敏感还体现在GC停顿上，因为这项分析工作必须在一个能确保一致性的快照中进行——这里“一致性”的意思是指在整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，该点不满足的话分析结果准确性就无法得到保证。这点是导致GC进行时必须停顿所有Java执行线程（Sun将这件事情称为”StopTheWorld”）的其中一个重要原因。 为了节省枚举根结点的时间，主流Java虚拟机使用的都是准确式GC，所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。在HotSpot的实现中，是使用一组称为OopMap的数据结构来达到这个目的的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点因为如果程序的每个指令都产生OopMap，这个开销是非常大的，所以约定在程序的某些地方产生OopMap，这些地方称为安全点（Safe Point），即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停注意Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。对于Safepoint，另一个需要考虑的问题是如何在GC发生时让所有线程（这里不包括执行JNI调用的线程）都“跑”到最近的安全点上再停顿下来。这里有两种方式供选择 抢先式中断（PreemptiveSuspension）抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。 主动式中断（VoluntarySuspension）主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 安全区使用安全点完美的解决了如何进入GC，安全点保证了在程序执行时，很快就能进入可以GC的安全点。但是程序没有执行（sleep 或者 blocking）的时候呢。对于这种情况，就需要安全区域（SafeRegion）^1来解决。 到此，简要地介绍了HotSpot虚拟机如何去发起内存回收的问题，但是虚拟机如何具体地进行内存回收动作仍然未涉及，因为内存回收如何进行是由虚拟机所采用的GC收集器决定的，而通常虚拟机中往往不止有一种GC收集器。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux－awk命令]]></title>
    <url>%2F2016%2F03%2F19%2Fjvm%2F2016-03-29-linux-awk%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[废话少说 开整 1.起步上台 我从netstat命令中提取了如下信息作为用例： $ cat netstat.txt Proto Recv-Q Send-Q Local-Address Foreign-Address State tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT tcp 0 0 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 tcp 0 0 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED tcp 0 0 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 tcp 0 0 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT tcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED tcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 tcp 0 0 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT tcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACK tcp 0 0 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED tcp 0 0 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 tcp 0 0 :::22 :::* LISTEN 下面是最简单最常用的awk示例，其输出第1列和第4例，其中单引号中的被大括号括着的就是awk的语句，注意，其只能被单引号包含。其中的$1..$n表示第几例。注：$0表示整个行。 $ awk &apos;{print $1, $4}&apos; netstat.txt Proto Local-Address tcp 0.0.0.0:3306 tcp 0.0.0.0:80 tcp 127.0.0.1:9000 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp coolshell.cn:80 tcp :::22 我们再来看看awk的格式化输出，和C语言的printf没什么两样： $ awk &apos;{printf &quot;%-8s %-8s %-8s %-18s %-22s %-15s\n&quot;,$1,$2,$3,$4,$5,$6}&apos; netstat.txt Proto Recv-Q Send-Q Local-Address Foreign-Address State tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT tcp 0 0 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 tcp 0 0 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED tcp 0 0 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 tcp 0 0 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT tcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED tcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 tcp 0 0 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT tcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACK tcp 0 0 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED tcp 0 0 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 tcp 0 0 :::22 :::* LISTEN 2.脱掉外套 过滤记录我们再来看看如何过滤记录（下面过滤条件为：第三列的值为0 &amp;&amp; 第6列的值为LISTEN） $ awk &apos;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; &apos; netstat.txt tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 :::22 :::* LISTEN 其中的“==”为比较运算符。其他比较运算符：!=, &gt;, &lt;, &gt;=, &lt;= 我们来看看各种过滤记录的方式： $ awk &apos; $3&gt;0 {print $0}&apos; netstat.txt Proto Recv-Q Send-Q Local-Address Foreign-Address State tcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED tcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 tcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACK 如果我们需要表头的话，我们可以引入内建变量NR： $ awk &apos;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; || NR==1 &apos; netstat.txt Proto Recv-Q Send-Q Local-Address Foreign-Address State tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 :::22 :::* LISTEN 再加上格式化输出： $ awk &apos;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; || NR==1 {printf &quot;%-20s %-20s %s\n&quot;,$4,$5,$6}&apos; netstat.txt Local-Address Foreign-Address State 0.0.0.0:3306 0.0.0.0:* LISTEN 0.0.0.0:80 0.0.0.0:* LISTEN 127.0.0.1:9000 0.0.0.0:* LISTEN :::22 :::* LISTEN 内建变量说到了内建变量，我们可以来看看awk的一些内建变量： 代码 含义 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 怎么使用呢，比如：我们如果要输出行号： $ awk &apos;$3==0 &amp;&amp; $6==&quot;ESTABLISHED&quot; || NR==1 {printf &quot;%02s %s %-20s %-20s %s\n&quot;,NR, FNR, $4,$5,$6}&apos; netstat.txt 01 1 Local-Address Foreign-Address State 07 7 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED 08 8 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED 10 10 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED 14 14 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED 17 17 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED 指定分隔符 $ awk &apos;BEGIN{FS=&quot;:&quot;} {print $1,$3,$6}&apos; /etc/passwd root 0 /root bin 1 /bin daemon 2 /sbin adm 3 /var/adm lp 4 /var/spool/lpd sync 5 /sbin shutdown 6 /sbin halt 7 /sbin 上面的命令也等价于：（-F的意思就是指定分隔符） $ awk -F: &apos;{print $1,$3,$6}&apos; /etc/passwd 注：如果你要指定多个分隔符，你可以这样来： awk -F &apos;[;:]&apos; 再来看一个以\t作为分隔符输出的例子（下面使用了/etc/passwd文件，这个文件是以:分隔的）： $ awk -F: &apos;{print $1,$3,$6}&apos; OFS=&quot;\t&quot; /etc/passwd root 0 /root bin 1 /bin daemon 2 /sbin adm 3 /var/adm lp 4 /var/spool/lpd sync 5 /sbin 3.脱掉衬衫字符串匹配我们再来看几个字符串匹配的示例： $ awk &apos;$6 ~ /FIN/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txt 1 Local-Address Foreign-Address State 6 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 9 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 13 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 18 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 $ $ awk &apos;$6 ~ /WAIT/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txt 1 Local-Address Foreign-Address State 5 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT 6 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 9 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 11 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT 13 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 15 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT 18 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 上面的第一个示例匹配FIN状态， 第二个示例匹配WAIT字样的状态。其实 ~ 表示模式开始。/ /中是模式。这就是一个正则表达式的匹配。 其实awk可以像grep一样的去匹配第一行，就像这样： $ awk &apos;/LISTEN/&apos; netstat.txt tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 :::22 :::* LISTEN 我们可以使用/FIN|TIME/来匹配 FIN 或者 TIME : $ awk &apos;$6 ~ /FIN|TIME/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txt 1 Local-Address Foreign-Address State 5 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT 6 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 9 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 11 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT 13 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 15 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT 18 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 再来看看模式取反的例子： $ awk &apos;$6 !~ /WAIT/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txt 1 Local-Address Foreign-Address State 2 0.0.0.0:3306 0.0.0.0:* LISTEN 3 0.0.0.0:80 0.0.0.0:* LISTEN 4 127.0.0.1:9000 0.0.0.0:* LISTEN 7 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED 8 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED 10 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED 12 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED 14 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED 16 coolshell.cn:80 208.115.113.92:50601 LAST_ACK 17 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED 19 :::22 :::* LISTEN 或是： awk &apos;!/WAIT/&apos; netstat.txt 折分文件 awk拆分文件很简单，使用重定向就好了。下面这个例子，是按第6例分隔文件，相当的简单（其中的NR!=1表示不处理表头）。 $ awk &apos;NR!=1{print &gt; $6}&apos; netstat.txt $ ls ESTABLISHED FIN_WAIT1 FIN_WAIT2 LAST_ACK LISTEN netstat.txt TIME_WAIT $ cat ESTABLISHED tcp 0 0 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED tcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED tcp 0 0 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED $ cat FIN_WAIT1 tcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 $ cat FIN_WAIT2 tcp 0 0 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 tcp 0 0 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 tcp 0 0 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 $ cat LAST_ACK tcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACK $ cat LISTEN tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 :::22 :::* LISTEN $ cat TIME_WAIT tcp 0 0 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT tcp 0 0 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT tcp 0 0 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT 你也可以把指定的列输出到文件: awk &apos;NR!=1{print $4,$5 &gt; $6}&apos; netstat.txt 再复杂一点：（注意其中的if-else-if语句，可见awk其实是个脚本解释器） $ awk &apos;NR!=1{if($6 ~ /TIME|ESTABLISHED/) print &gt; &quot;1.txt&quot;; else if($6 ~ /LISTEN/) print &gt; &quot;2.txt&quot;; else print &gt; &quot;3.txt&quot; }&apos; netstat.txt $ ls ?.txt 1.txt 2.txt 3.txt $ cat 1.txt tcp 0 0 coolshell.cn:80 124.205.5.146:18245 TIME_WAIT tcp 0 0 coolshell.cn:80 110.194.134.189:1032 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49809 ESTABLISHED tcp 0 0 coolshell.cn:80 123.169.124.111:49829 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.215.36:36970 TIME_WAIT tcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHED tcp 0 0 coolshell.cn:80 110.194.134.189:4796 ESTABLISHED tcp 0 0 coolshell.cn:80 183.60.212.163:51082 TIME_WAIT tcp 0 0 coolshell.cn:80 123.169.124.111:49840 ESTABLISHED $ cat 2.txt tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN tcp 0 0 :::22 :::* LISTEN $ cat 3.txt tcp 0 0 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2 tcp 0 0 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2 tcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1 tcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACK tcp 0 0 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2 统计 下面的命令计算所有的C文件，CPP文件和H文件的文件大小总和。 $ ls -l *.cpp *.c *.h | awk &apos;{sum+=$5} END {print sum}&apos; 2511401 我们再来看一个统计各个connection状态的用法：（我们可以看到一些编程的影子了，大家都是程序员我就不解释了。注意其中的数组的用法） $ awk &apos;NR!=1{a[$6]++;} END {for (i in a) print i &quot;, &quot; a[i];}&apos; netstat.txt TIME_WAIT, 3 FIN_WAIT1, 1 ESTABLISHED, 6 FIN_WAIT2, 3 LAST_ACK, 1 LISTEN, 4 再来看看统计每个用户的进程的占了多少内存（注：sum的RSS那一列） $ ps aux | awk &apos;NR!=1{a[$1]+=$6;} END { for(i in a) print i &quot;, &quot; a[i]&quot;KB&quot;;}&apos; dbus, 540KB mysql, 99928KB www, 3264924KB root, 63644KB hchen, 6020KB 4.脱掉内衣 awk脚本 在上面我们可以看到一个END关键字。END的意思是“处理完所有的行的标识”，即然说到了END就有必要介绍一下BEGIN，这两个关键字意味着执行前和执行后的意思，语法如下： BEGIN{ 这里面放的是执行前的语句 } END {这里面放的是处理完所有的行后要执行的语句 } {这里面放的是处理每一行时要执行的语句} 为了说清楚这个事，我们来看看下面的示例： 假设有这么一个文件（学生成绩表）： $ cat score.txt Marry 2143 78 84 77 Jack 2321 66 78 45 Tom 2122 48 77 71 Mike 2537 87 97 95 Bob 2415 40 57 62 我们的awk脚本如下（我没有写有命令行上是因为命令行上不易读，另外也在介绍另一种用法）： $ cat cal.awk #!/bin/awk -f #运行前 BEGIN { math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\n&quot; printf &quot;---------------------------------------------\n&quot; } #运行中 { math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5 } #运行后 END { printf &quot;---------------------------------------------\n&quot; printf &quot; TOTAL:%10d %8d %8d \n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\n&quot;, math/NR, english/NR, computer/NR } 我们来看一下执行结果：（也可以这样运行 ./cal.awk score.txt） $ awk -f cal.awk score.txt NAME NO. MATH ENGLISH COMPUTER TOTAL --------------------------------------------- Marry 2143 78 84 77 239 Jack 2321 66 78 45 189 Tom 2122 48 77 71 196 Mike 2537 87 97 95 279 Bob 2415 40 57 62 159 --------------------------------------------- TOTAL: 319 393 350 AVERAGE: 63.80 78.60 70.00 环境变量 即然说到了脚本，我们来看看怎么和环境变量交互：（使用-v参数和ENVIRON，使用ENVIRON的环境变量需要export） $ x=5 $ y=10 $ export y $ echo $x $y 5 10 $ awk -v val=$x &apos;{print $1, $2, $3, $4+val, $5+ENVIRON[&quot;y&quot;]}&apos; OFS=&quot;\t&quot; score.txt Marry 2143 78 89 87 Jack 2321 66 83 55 Tom 2122 48 82 81 Mike 2537 87 102 105 Bob 2415 40 62 72 几个花活最后，我们再来看几个小例子： # 从file文件中找出长度大于80的行 awk &apos;length&gt;80&apos; file # 按连接数查看客户端IP netstat -ntu | awk &apos;{print $5}&apos; | cut -d: -f1 | sort | uniq -c | sort -nr # 打印99乘法表 seq 9 | sed &apos;H;g&apos; | awk -v RS=&apos;&apos; &apos;{for(i=1;i&lt;=NF;i++)printf(&quot;%dx%d=%d%s&quot;, i, NR, i*NR, i==NR?&quot;\n&quot;:&quot;\t&quot;)}&apos;]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nio入门]]></title>
    <url>%2F2015%2F12%2F05%2Fnio%2FNIO-%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[https://www.ibm.com/developerworks/cn/education/java/j-nio/j-nio.html]]></content>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[闭锁]]></title>
    <url>%2F2015%2F11%2F01%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F%E9%97%AD%E9%94%81%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/lmj623565791/article/details/26626391]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死锁]]></title>
    <url>%2F2015%2F10%2F28%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[线程饥饿死锁 java.util.concurrent.*;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadDeadLock &#123; ExecutorService exec = Executors.newSingleThreadExecutor(); /** * 该任务会提交另外一个任务到线程池，并且等待任务的执行结果 * @author bh */ public class RenderPageTask implements Callable&lt;String&gt;&#123; @Override public String call() throws Exception &#123; System.out.println(&quot;RenderPageTask 依赖LoadFileTask任务返回的结果...&quot;); Future&lt;String&gt; header,footer; header = exec.submit(new LoadFileTask(&quot;header.html&quot;)); footer = exec.submit(new LoadFileTask(&quot;footer.html&quot;)); String page = renderBody(); return header.get()+page+footer.get(); &#125; public String renderBody()&#123; return &quot;render body is ok.&quot;; &#125; &#125; public static void main(String[] args) &#123; ThreadDeadLock lock = new ThreadDeadLock(); Future&lt;String&gt; result = lock.exec.submit(lock.new RenderPageTask()); try &#123; System.out.println(&quot;last result:&quot;+result.get()); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125;finally&#123; lock.exec.shutdown(); &#125; &#125;&#125; class LoadFileTask implements Callable&lt;String&gt; &#123; private String fileName; public LoadFileTask(String fileName)&#123; this.fileName = fileName; &#125; @Override public String call() throws Exception &#123; System.out.println(&quot;LoadFileTask execute call...&quot;); return fileName; &#125;&#125; 锁顺序死锁 动态锁顺序死锁通过锁顺序来避免死锁###避免死锁]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有界无界队列对线程池的影响]]></title>
    <url>%2F2015%2F10%2F10%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F%E6%9C%89%E7%95%8C%E3%80%81%E6%97%A0%E7%95%8C%E9%98%9F%E5%88%97%E5%AF%B9ThreadPoolExcutor%E6%89%A7%E8%A1%8C%E7%9A%84%E5%BD%B1%E5%93%8D%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/kusedexingfu/article/details/72491864]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何减少锁的竞争]]></title>
    <url>%2F2015%2F10%2F04%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F%E5%87%8F%E5%B0%91%E9%94%81%E7%9A%84%E7%AB%9E%E4%BA%89%2F</url>
    <content type="text"><![CDATA[缩小锁的范围 1234567891011public synchronized void doSometing()&#123; A(); B();&#125;改为public void doSometing()&#123; synchronized(this)&#123;A()&#125;; B();&#125; 缩小锁的粒度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@ThreadSafepublic class ServerStatusBeforeSplit &#123; @GuardedBy(&quot;this&quot;) public final Set&lt;String&gt; users; @GuardedBy(&quot;this&quot;) public final Set&lt;String&gt; queries; public ServerStatusBeforeSplit() &#123; users = new HashSet&lt;String&gt;(); queries = new HashSet&lt;String&gt;(); &#125; public synchronized void addUser(String u) &#123; users.add(u); &#125; public synchronized void addQuery(String q) &#123; queries.add(q); &#125; public synchronized void removeUser(String u) &#123; users.remove(u); &#125; public synchronized void removeQuery(String q) &#123; queries.remove(q); &#125;&#125;改为public class ServerStatusAfterSplit &#123; @GuardedBy(&quot;users&quot;) public final Set&lt;String&gt; users; @GuardedBy(&quot;queries&quot;) public final Set&lt;String&gt; queries; public ServerStatusAfterSplit() &#123; users = new HashSet&lt;String&gt;(); queries = new HashSet&lt;String&gt;(); &#125; public void addUser(String u) &#123; synchronized (users) &#123; users.add(u); &#125; &#125; public void addQuery(String q) &#123; synchronized (queries) &#123; queries.add(q); &#125; &#125; public void removeUser(String u) &#123; synchronized (users) &#123; users.remove(u); &#125; &#125; public void removeQuery(String q) &#123; synchronized (users) &#123; queries.remove(q); &#125; &#125;&#125; 锁分段ConcurrentHashMap 1234567891011121314151617181920212223242526272829303132333435363738394041public class StripedMap &#123; // Synchronization policy: buckets[n] guarded by locks[n%N_LOCKS] private static final int N_LOCKS = 16; private final Node[] buckets; private final Object[] locks; private static class Node &#123; Node next; Object key; Object value; &#125; public StripedMap(int numBuckets) &#123; buckets = new Node[numBuckets]; locks = new Object[N_LOCKS]; for (int i = 0; i &lt; N_LOCKS; i++) locks[i] = new Object(); &#125; private final int hash(Object key) &#123; return Math.abs(key.hashCode() % buckets.length); &#125; public Object get(Object key) &#123; int hash = hash(key); synchronized (locks[hash % N_LOCKS]) &#123; for (Node m = buckets[hash]; m != null; m = m.next) if (m.key.equals(key)) return m.value; &#125; return null; &#125; public void clear() &#123; for (int i = 0; i &lt; buckets.length; i++) &#123; synchronized (locks[i % N_LOCKS]) &#123; buckets[i] = null; &#125; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[corePoolSize和maxnumPoolSize]]></title>
    <url>%2F2015%2F10%2F03%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2FThreadPoolExecutor%E7%9A%84corePoolSize%E5%92%8CmaximumPoolSize%2F</url>
    <content type="text"><![CDATA[http://freeheron.iteye.com/blog/664278]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[interrupt方法]]></title>
    <url>%2F2015%2F09%2F20%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2Fthread-method-interrupt%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/pursuer211/article/details/40653531]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程实现四种方式]]></title>
    <url>%2F2015%2F09%2F20%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/felixzh/p/6036074.html]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁可重入性]]></title>
    <url>%2F2015%2F09%2F16%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2Fjava%E5%86%85%E7%BD%AE%E9%94%81synchronized%E7%9A%84%E5%8F%AF%E9%87%8D%E5%85%A5%E6%80%A7%2F</url>
    <content type="text"><![CDATA[当线程请求一个由其它线程持有的对象锁时，该线程会阻塞，而当线程请求由自己持有的对象锁时，如果该锁是重入锁,请求就会成功,否则阻塞。 java中获取锁的操作的粒度是“线程”，而不是“调用”，即不是每一次调用都是建立一个锁。 重入锁的一种实现方法是为每个锁关联一个线程持有者和计数器，当计数器为0时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为1；此时其它线程请求该锁，则必须等待；而如果同一个线程再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增；当线程退出同步代码块时，计数器会递减，如果计数器为0，则释放该锁。 看下面的例子，正是由于java的内置锁是可重入的，所以下面这段代码不会发生死锁：123456789101112131415161718public class Child extends Father&#123; public static void main(String[] args) &#123; new Child().doSomething(); &#125; public synchronized void doSomething()&#123; System.out.println(&quot;child&quot;); super.doSomething(); &#125; &#125; class Father&#123; public synchronized void doSomething()&#123; System.out.println(&quot;Father&quot;); &#125;&#125; 输出结果：childFather ###重入的错误理解： 例子解释有问题，不存在父类的锁或者子类的锁，锁是加在实例上的不是类上原文链接 ###正确理解： 知乎问题链接]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[futuretask]]></title>
    <url>%2F2015%2F09%2F14%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2Ffuturetask%2F</url>
    <content type="text"><![CDATA[http://www.importnew.com/25286.html]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全发布]]></title>
    <url>%2F2015%2F09%2F13%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F5-%E5%AE%89%E5%85%A8%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[不安全的发布这种发布会导致其他线程看到尚未未构建完成的对象，另一个线程在调用assertSanity 方法可能会抛出AssertionError(stackoverflow里的相关问题)123456789101112131415161718192021222324252627282930313233/** * StuffIntoPublic * &lt;p/&gt; * Unsafe publication * * @author Brian Goetz and Tim Peierls */public class StuffIntoPublic &#123; public Holder holder; public void initialize() &#123; holder = new Holder(42); &#125;&#125;/** * Holder * &lt;p/&gt; * Class at risk of failure if not properly published * * @author Brian Goetz and Tim Peierls */public class Holder &#123; private int n; public Holder(int n) &#123; this.n = n; &#125; public void assertSanity() &#123; if (n != n) throw new AssertionError(&quot;This statement is false.&quot;); &#125;&#125; 不可变对象与初始化安全性由于不可变对象是一种非常重要的对象，由于java内存模式为不可变对象提供了一种特殊的初始化安全保证。（如果将Holder里的n声明为final类型，那么Holder是不可变的，从而避免出现未正确发布的问题）我们知道即使一个对象的引用对于其他线程是可见的，也并不意味对象状态对于其他线程是可见的。为了确保状态一致得必须使用同步。 任何线程都可以在不需要额外同步的情况下去访问不可变对象，即使在发布这个对象时没有使用同步。这种保证还将延续到不可变对象的final域。在没有额外同步的情况下，也可以安全的访问所有的final域。然而，如果final域所指向的是一个可变对象，那么在访问这些域所指向的对象的状态仍然需要额外同步。 安全发布常用模型可变对象可以用安全的方式来发布 在静态初始化域中初始化一个对象引用（public static Holder holder = new Holder(42);）静态初始化器在jvm在类的初始化阶段执行，由于jvm内部存在同步机制，因此通过这种方式初始化的对象都可以被安全的发布 将对像引用保存到volatile类型的域或AtomicRefrance对象中 将对象的引用保存到一个正确构造的对象的final域中 将对象的引用保存到一个由锁保护的域中事实不可变对象技术上是可变的，不满足不可变对象的要求，但是其状态确实在发布后不会改变，这种对象称为事实不可变对象。在没有额外同步的状态下任何线程都可以使用被安全发布的事实不可变对象 可变对象如果对象在构造后可以修改，那么安全发布只能确保“发布当时”状态的可见性。对于可变对象，不仅在发布对象时使用同步，而且在每次对象访问时同样需要使用同步来确保后续操作的可见性。要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是某个线程安全的或者由某个锁保护起来。 对象的发布需求取决于它的可变性： 不可变对象可以通过任意机制来发布 事实不可变对象必须通过安全方式来发布 可变对象必须通过安全方式来发布，并且必须是线程安全的类或者由某个锁保护起来 安全的共享对象当获得对象的一个引用时，你需要知道在这个引用上可以执行哪些操作。在使用它之前是否需要获得一个锁？是否可以修改他的状态，或者只能读取它？许多并发错误都是由于没有理解共享对象的这些“既定规则”而导致的。当发布一个对象时，必须明确的说明对象的访问方式。 在并发程序中使用和共享对象时，可以使用一些实用的策略，包括： 线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不可变对象]]></title>
    <url>%2F2015%2F09%2F10%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F4-%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[当满足以下条件对象是不可变的 当对象状态创建后就不能被修改 对象的所有域都是final类型 对象是正常创建的（对象创建期间，this没有逸出）不可变对象一定是线程安全的 所有字段都是final修饰 是有final修饰不仅仅是从语义上说明被修饰字段的引用不可改变， 更重要的是这个语义在多线程环境下由Java内存模型保证被修饰字段所引用对象的初始化安全， 既final修饰字段在其他线程可见时 它必定是初始化完成的 相反 非final修饰字段由于缺少该保证 可能到一个线程看到一个字段的时候 其未被初始完成 从而导致一些可变预料的情况例子如图，如果变量没有被final修饰，没初始化完全的时候，就可能被其他线程使用12345678910111213141516171819202122232425/** * OneValueCache * &lt;p/&gt; * Immutable holder for caching a number and its factors * * @author Brian Goetz and Tim Peierls */@Immutablepublic class OneValueCache &#123; private final BigInteger lastNumber; private final BigInteger[] lastFactors; public OneValueCache(BigInteger i, BigInteger[] factors) &#123; lastNumber = i; lastFactors = Arrays.copyOf(factors, factors.length); &#125; public BigInteger[] getFactors(BigInteger i) &#123; if (lastNumber == null || !lastNumber.equals(i)) return null; else return Arrays.copyOf(lastFactors, lastFactors.length); &#125;&#125; 用不可变对象解决因数分解缓存的问题123456789101112131415161718192021222324252627282930313233343536373839/** * UnsafeCachingFactorizer * * Servlet that attempts to cache its last result without adequate atomicity * * @author Brian Goetz and Tim Peierls */@NotThreadSafepublic class UnsafeCachingFactorizer extends GenericServlet implements Servlet &#123; private final AtomicReference&lt;BigInteger&gt; lastNumber = new AtomicReference&lt;BigInteger&gt;(); private final AtomicReference&lt;BigInteger[]&gt; lastFactors = new AtomicReference&lt;BigInteger[]&gt;(); public void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); if (i.equals(lastNumber.get())) encodeIntoResponse(resp, lastFactors.get()); else &#123; BigInteger[] factors = factor(i); lastNumber.set(i); lastFactors.set(factors); encodeIntoResponse(resp, factors); &#125; &#125; void encodeIntoResponse(ServletResponse resp, BigInteger[] factors) &#123; &#125; BigInteger extractFromRequest(ServletRequest req) &#123; return new BigInteger(&quot;7&quot;); &#125; BigInteger[] factor(BigInteger i) &#123; // Doesn&apos;t really factor return new BigInteger[]&#123;i&#125;; &#125;&#125; 加锁解决方案12345678910111213141516171819202122232425262728293031323334353637 * SynchronizedFactorizer * * Servlet that caches last result, but with unnacceptably poor concurrency * * @author Brian Goetz and Tim Peierls */@ThreadSafepublic class SynchronizedFactorizer extends GenericServlet implements Servlet &#123; @GuardedBy(&quot;this&quot;) private BigInteger lastNumber; @GuardedBy(&quot;this&quot;) private BigInteger[] lastFactors; public synchronized void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); if (i.equals(lastNumber)) encodeIntoResponse(resp, lastFactors); else &#123; BigInteger[] factors = factor(i); lastNumber = i; lastFactors = factors; encodeIntoResponse(resp, factors); &#125; &#125; void encodeIntoResponse(ServletResponse resp, BigInteger[] factors) &#123; &#125; BigInteger extractFromRequest(ServletRequest req) &#123; return new BigInteger(&quot;7&quot;); &#125; BigInteger[] factor(BigInteger i) &#123; // Doesn&apos;t really factor return new BigInteger[] &#123; i &#125;; &#125;&#125; 加锁优化（剔除不需要加锁的逻辑）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 * CachedFactorizer * &lt;p/&gt; * Servlet that caches its last request and result * * @author Brian Goetz and Tim Peierls */@ThreadSafepublic class CachedFactorizer extends GenericServlet implements Servlet &#123; @GuardedBy(&quot;this&quot;) private BigInteger lastNumber; @GuardedBy(&quot;this&quot;) private BigInteger[] lastFactors; @GuardedBy(&quot;this&quot;) private long hits; @GuardedBy(&quot;this&quot;) private long cacheHits; public synchronized long getHits() &#123; return hits; &#125; public synchronized double getCacheHitRatio() &#123; return (double) cacheHits / (double) hits; &#125; public void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); BigInteger[] factors = null; synchronized (this) &#123; ++hits; if (i.equals(lastNumber)) &#123; ++cacheHits; factors = lastFactors.clone(); &#125; &#125; if (factors == null) &#123; factors = factor(i); synchronized (this) &#123; lastNumber = i; lastFactors = factors.clone(); &#125; &#125; encodeIntoResponse(resp, factors); &#125; void encodeIntoResponse(ServletResponse resp, BigInteger[] factors) &#123; &#125; BigInteger extractFromRequest(ServletRequest req) &#123; return new BigInteger(&quot;7&quot;); &#125; BigInteger[] factor(BigInteger i) &#123; // Doesn&apos;t really factor return new BigInteger[]&#123;i&#125;; &#125;&#125; 不可变对象+volitatile解决方案1234567891011121314151617181920212223242526272829303132 * VolatileCachedFactorizer * &lt;p/&gt; * Caching the last result using a volatile reference to an immutable holder object * * @author Brian Goetz and Tim Peierls */@ThreadSafepublic class VolatileCachedFactorizer extends GenericServlet implements Servlet &#123; private volatile OneValueCache cache = new OneValueCache(null, null); public void service(ServletRequest req, ServletResponse resp) &#123; BigInteger i = extractFromRequest(req); BigInteger[] factors = cache.getFactors(i); if (factors == null) &#123; factors = factor(i); cache = new OneValueCache(i, factors); &#125; encodeIntoResponse(resp, factors); &#125; void encodeIntoResponse(ServletResponse resp, BigInteger[] factors) &#123; &#125; BigInteger extractFromRequest(ServletRequest req) &#123; return new BigInteger(&quot;7&quot;); &#125; BigInteger[] factor(BigInteger i) &#123; // Doesn&apos;t really factor return new BigInteger[]&#123;i&#125;; &#125;&#125; 当一个线程将volatile类型的cache设置为一个新的引用时，其他线程就会立即看到新缓存的数据]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象共享]]></title>
    <url>%2F2015%2F09%2F03%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F3-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[3.1可见性 加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步 Volatile变量当把变量定义为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者其他处理器不可见的地方，因此在读取volatile类型的变量总是会返回最新写入的值。 写入volatile变量相当于退出同步代码块，读取volatile变量相当于进入同步代码块 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。当且仅当满足以下所有条件时，才应该使用volatile变量： 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁 3.2发布与逸出隐式this逸出和安全的对象构造的例子12345678910111213141516171819202122232425262728293031/** * ThisEscape * &lt;p/&gt; * Implicitly allowing the this reference to escape * * @author Brian Goetz and Tim Peierls */public class ThisEscape &#123; public ThisEscape(EventSource source) &#123; source.registerListener(new EventListener() &#123; public void onEvent(Event e) &#123; doSomething(e); &#125; &#125;); &#125; void doSomething(Event e) &#123; &#125; interface EventSource &#123; void registerListener(EventListener e); &#125; interface EventListener &#123; void onEvent(Event e); &#125; interface Event &#123; &#125;&#125; 利用final和工厂来防止this逸出12345678910111213141516171819202122232425262728293031323334353637383940/** * SafeListener * &lt;p/&gt; * Using a factory method to prevent the this reference from escaping during construction * * @author Brian Goetz and Tim Peierls */public class SafeListener &#123; private final EventListener listener; private SafeListener() &#123; listener = new EventListener() &#123; public void onEvent(Event e) &#123; doSomething(e); &#125; &#125;; &#125; public static SafeListener newInstance(EventSource source) &#123; SafeListener safe = new SafeListener(); source.registerListener(safe.listener); return safe; &#125; void doSomething(Event e) &#123; &#125; interface EventSource &#123; void registerListener(EventListener e); &#125; interface EventListener &#123; void onEvent(Event e); &#125; interface Event &#123; &#125;&#125; 不过本人看了这个，还是不懂咋回事，不懂为什么this逸出了，参考了博客写了下边的例子就知道咋回事了 123456789101112131415161718192021222324252627282930313233343536public class ThisEscape &#123; private String name = null; public ThisEscape(EventSource source) &#123; source.registerListener(new EventListener() &#123; public void onEvent(Event e) &#123; doSomething(e); &#125; &#125;); name = &quot;TEST&quot;; &#125; void doSomething(Event e) &#123; System.out.println(this.name.toString()); &#125; interface EventSource &#123; void registerListener(EventListener e); &#125; interface EventListener &#123; void onEvent(Event e); &#125; interface Event &#123; &#125; public static void main(String[] args) &#123; EventSource e = new EventSource() &#123; public void registerListener(EventListener e) &#123; e.onEvent(null); &#125; &#125;; new ThisEscape(e); &#125;&#125; 执行结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class SafeListener &#123; private final EventListener listener; private String name = null; private SafeListener() &#123; listener = new EventListener() &#123; public void onEvent(Event e) &#123; doSomething(e); &#125; &#125;; name = &quot;TEST&quot;; &#125; public static SafeListener newInstance(EventSource source) &#123; SafeListener safe = new SafeListener(); source.registerListener(safe.listener); return safe; &#125; void doSomething(Event e) &#123; System.out.println(this.name.toString()); &#125; interface EventSource &#123; void registerListener(EventListener e); &#125; interface EventListener &#123; void onEvent(Event e); &#125; interface Event &#123; &#125; public static void main(String[] args) throws InterruptedException &#123; EventSource es = new EventSource()&#123; public void registerListener(EventListener e)&#123; e.onEvent(null); &#125; &#125;; // new ThisEscape(es); SafeListener.newInstance(es); &#125;&#125; 执行结果第一个例子，类没有初始化完全，就使用this 报了空指针异常，this逸出。第二个例子，类完全初始化后，使用this 正常打印。 3.3线程封闭(todo)例子 JDBC Connection，Swing栈封闭引用被封闭在了方法中ThreadLocal类]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全]]></title>
    <url>%2F2015%2F08%2F13%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F2-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[编写线程安全的代码，最核心的是管理对状态的访问，尤其是对共享状态的访问,对象的状态是指存储在状态变量(例如实例或静态域)中的数据 同步机制当多个线程访问某个状态变量并且只有一个线程执行写入操作时，必须采用同步机制来协同这些线程对变量的访问。java中主要同步机制是关键字synchronized,它通过了一种独占的加锁方式，但“同步”这个术语还包括volatile类型的变量，显式锁(Explicit lock)以及原子变量。 多线程访问状态变量避免出错的三个方式如果当多个线程访问同一个可变的状态变量时，没有使用适合的同步，那么程序就会出错。有三种方式可以修复这个问题 不要在线程间共享状态变量 把可变的状态变量改成不可变的 在访问变量时使用同步如果从一开始就设计一个线程安全的类，那么比在以后再将这个类修改为线程安全的类要容易得多。当设计线程安全的类时，良好的面向对象技术、不可修改性，以及明晰的不变性规范都能起到一定的帮助作用。线程安全的程序是否完全由线程安全类构成？答案是否定的，完全由线程安全类构成的程序并不一定就是线程安全的，而在线程安全类中也可以包含非线程安全的类 什么是线程安全？当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类就能表现出正确的行为，那么就称这个类是线程安全的。为什么说ArrayList不是线程安全的ArrayList在多线程下的表现 无状态对象： 既不包含任何域，也不包含任何其他类中域的引用的对象。 无状态对象一定是线程安全的。 竞态条件： 当某个计算的正确性取决于多个线程的交替执行时序时，就会发生竞态条件。 本质是基于一种可能失效的观察结果来做出判断或者执行某个计算。 最常见的竞态条件类型就是“先检查后执行（Check-then-Act）”。 “读取-修改-写入”操作也是一种竞态条件。 例子：单例模式懒汉模式，计数器 原子操作： 对于访问同一个状态的所有操作（包括操作本身）来说，这个操作是一个以原子方式执行的操作。 要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。包含多个原子操作的复合操作，也不是线程安全的，需要加上同步 内置锁对于每个包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护。 重入参考 活跃性和性能通常，在简单性与性能之间存在相互制约的因素。当实现某个同步策略时，一定不要盲目的为了性能而牺牲简单性(可能会破坏安全性)当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O）一定不要持有锁]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2F2015%2F08%2F03%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F1-%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[促使多线程出现的因素： 资源利用比如阻塞io，等待的时间让线程去做其他事情，提高利用率 公平多个用户和程序可能对机器的资源具有相同的权利要求。 最好让他们通过更精细的时间切片共享计算机，而不是让一个程序运行完成然后再启动。 便利编写多个程序通常更容易或更理想，每个程序执行单个任务并使它们在必要时彼此协调，而不是编写单个线程执行所有的任务。 多线程的好处 发挥处理器的强大能力 在多处理器上，多线程可以通过提高处理器资源的利用率来提高系统的吞吐率。在单处理器系统上也可以获得更高的吞吐率，比如说多线程程序在等待某个同步I/O操作时，还有其他线程可以继续运行。 建模的简单性 完成单任务时，很简单，只要把这件事做好就行。但是在完成多任务的时候，不仅要把活干好，还要考虑不同任务之间存在优先级和时间。 异步事件的简化处理 一部分线程接受客户端请求，另一部分处理器请求。如果是单线程程序的话，处理请求时会停顿导致接受请求阻塞，为了避免这个问题单线程程序必须使用非阻塞的I/O，这种I/O的复杂性要远远高于同步I/O。例如unix select和 poll ，java NIO 响应灵敏的用户界面 多线程带来的风险 安全性要额外考虑多线程的安全性的问题，比如多线程计数器（竞态条件） 活跃性死锁，饥饿，活锁 性能保存和恢复上下文，加锁]]></content>
      <tags>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集算法]]></title>
    <url>%2F2015%2F06%2F12%2Fjvm%2F2015-06-12-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[标记-清除算法算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象不足之处： 效率问题，标记和清除两个过程的效率都不高 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 不足之处：这种算法的代价是把内存缩小为原来的一半，代价太高了 但是现在的商业虚拟机都采用这种收集算法来回收新生代。IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（HandlePromotion）^1。 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，“标记-整理”算法的示意图 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（GenerationalCollection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象是生存还是死亡]]></title>
    <url>%2F2015%2F05%2F06%2Fjvm%2F2015-05-06-java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%94%9F%E5%AD%98%E8%BF%98%E6%98%AF%E6%AD%BB%E4%BA%A1%2F</url>
    <content type="text"><![CDATA[java堆里存着几乎所有的对象，垃圾收集器要判断，哪些对象是存活的，哪些是死亡的（没有被引用的对象）即需要被回收的。 判断对象是否存活有两种算法 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。例如微软公司的COM（ComponentObjectModel）技术、使用ActionScript3的FlashPlayer、Python语言和在游戏脚本领域被广泛应用的Squirrel中都使用了引用计数算法进行内存管理。但是，至少主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。以下是互相引用的例子 12345678910111213public class RefrenceCounterGC&#123; public Object instance = null; public static void main(String[] args)&#123; RefresnceCounterGC a = new RefrenceCounterGC(); RefresnceCounterGC b = new RefrenceCounterGC(); a.instance = b; b.instance = a; a=null; b=null; System.gc();// a/b指向的对象被回收了 &#125;&#125;a b引用指向的对象，仍然被相互引用，但是最后仍然被垃圾收集器回收了 可达性分析算法这个算法的基本思路就是通过一系列的称为”GCRoots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（ReferenceChain），当一个对象到GCRoots没有任何引用链相连（用图论的话来说，就是从GCRoots到这个对象不可达）时，则证明此对象是不可用的。在Java语言中，可作为GCRoots的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。引用概念无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。 JDK1.2以前，Java中的引用的定义很传统一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些“食之无味，弃之可惜”的对象就显得无能为力。 在JDK1.2之后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，这4种引用强度依次逐渐减弱。 强引用（StrongReference）就是指在程序代码之中普遍存在的，类似”Objectobj=newObject()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用（SoftReference）用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 弱引用（WeakReference）弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 虚引用（PhantomReference）也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。生存还是死亡即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有与GCRoots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。 如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。从下列代码中我们可以看到一个对象的finalize()被执行，但是它仍然可以存活。123456789101112131415161718192021222324252627282930313233343536373839404142public class FinalizeEscapeGC &#123; public static FinalizeEscapeGC SAVE_HOOK = null; public void isAlive() &#123; System.out.println("yes i am still alive"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println("finalize executed"); FinalizeEscapeGC.SAVE_HOOK = this; &#125; public static void main(String[] args) throws InterruptedException &#123; SAVE_HOOK = new FinalizeEscapeGC(); SAVE_HOOK = null; //进入gc 调用finalize 实现自救 System.gc(); // 因为finalize 优先级很低所以等待0.5秒 Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("I'm dead"); &#125; SAVE_HOOK = null; //下面这段代码与上面的完全相同,但是这次自救却失败了 //这是因为任何一个对象的finalize()方法都只会被系统自动调用一次 System.gc(); Thread.sleep(500); if (SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("I'm dead"); &#125; &#125;&#125; 执行结果123finalize executedyes i am still aliveI&apos;m dead]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java虚拟机中对象的定位]]></title>
    <url>%2F2015%2F04%2F21%2Fjvm%2F2015-04-21-java%E8%99%9A%E6%8B%9F%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9A%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[建立对象是为了使用对象，我们的程序通过栈上的refrence引用来操作堆里的具体对象。由于refrence类型在java虚拟机规范中只规定了一个指向对象的应用，并没有定义这个引用通过何种方式去定位、访问堆内对象的具体位置，所以对象访问方式也是取决与虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种 句柄访问如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 好处：使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。 直接指针如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。 好处：使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。就本书讨论的主要虚拟机SunHotSpot而言，它是使用第二种方式进行对象访问的，但从整个软件开发的范围来看，各种语言和框架使用句柄来访问的情况也十分常见。 相关文章:java虚拟机中对象的创建java虚拟机中对象的内存布局java虚拟机中对象的定位]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java虚拟机中对象的内存布局]]></title>
    <url>%2F2015%2F04%2F03%2Fjvm%2F2015-04-03-java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[在HotSpot虚拟机中，对象的内存布局分为三块区域：对象头(Object Header)、实例数据(Instance Data)、对齐填充(Padding)。 对象头（Object Header） 存储对象自身的运行时数据：如HashCode、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，官方称它为&quot;MarkWord&quot;。对象需要存储的运行时数据很多，其实已经超出了32位、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，MarkWord被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如，在32位的HotSpot虚拟机中，如果对象处于未被锁定的状态下，那么MarkWord的32bit空间中的25bit用于存储对象哈希码，4bit用于存储对象分代年龄，2bit用于存储锁标志位，1bit固定为0，而在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容见表2-1。 类型指针(即对象指向它的类元数据的指针)：虚拟机通过这个指针来确定这个对象是哪个类的实例。(注：并不是所有虚拟机的实现都必须在对象数据里保存类型指针，换句话说，查找对象的类的元数据信息不一定要通过对象本身)另外如果对象是一个数组，那么在对象头中还必须有一块来记录数据的长度，因为虚拟机可以根据普通对象的元数据信息来确定对象的大小，但是从数组的元数据里无法确定数组的大小。 实例数据 (instance Data)对象真正存储的有效信息，也是在程序代码中定义的各种类型的字段内容。无论是父类继承的还是子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义顺序的影响。HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oops（OrdinaryObjectPointers），从分配策略中可以看出，相同宽度的字段总是被分配到一起。在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充(Padding)对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpotVM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 相关文章：java虚拟机中对象的创建java虚拟机中对象的内存布局java虚拟机中对象的定位]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java虚拟机中对象的创建]]></title>
    <url>%2F2015%2F02%2F03%2Fjvm%2F2015-02-03-java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;我们了解虚拟机内存划分的人，都知道对象的内存分配几乎都是在堆上的，这一点在java虚拟机规范中的描述是：所有的对象实例以及数组都会在堆上分配（但是随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配，标量替换优化技术将会导致一些变化，擦扯远了，所以所有的对象实例都在堆上分配就不是那么绝对了） 下面说虚拟机中对象的创建几个步骤 类加载检查&emsp;&emsp;虚拟机遇到new指令时，首先会去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否被装载、解析和初始化过。如果没有那必须先执行相应的类的加载过程。 为对象分配内存&emsp;&emsp;当类加载成功后，类的对象的大小是确定了的。对象内存的划分等同于在堆里划分出一块指定大小的内存。&emsp;&emsp;假设内存是规整的，所有用过的内存放在一边，空闲的放在另一边，中间分界点有个指针，那分配内存就是把指针向空闲区域方向挪动一段于对象大小相等的长度，这种分配方式叫做“指针碰撞”(Bump the Pointer)。&emsp;&emsp;如果内存不是规整的，那么就需要一个表来记录，记录哪些内存是占用的，哪些是空闲的，那分配内存就是在表里找到一块足够大的空间分配给对象实例，并更新这个表的记录，这种分配方式叫做“空闲列表”(Free List)。&emsp;&emsp;选择哪种分配方式与堆是否规整决定，而java堆是否规整又和垃圾收集器是否有压缩整理功能决定。因此，在使用Serial、ParNew等带有Compact过程的收集器时，采用的分配方式是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，采用的是空闲列表。&emsp;&emsp;除了如何划分内存之外还有一个是我们需要考虑的问题，因为java堆是线程共享的，那么多个线程同时操作堆上的内存就会有问题，比如正在给a对象分配内存还没来得及移动指针(或者是没有修改空闲列表的记录)，这时对象b使用原来的指针来分配内存，就会产生问题。解决这个问题有两种方式，一种是对分配内存的动作进行同步处理(实际上虚拟机采用CAS配上错误重试来保证分配内存的原子性)；另一种是采用线程间不共享的内存来分配，每个线程预先在java堆中分配一块内存，成为本地线程分配缓冲(Thread Local Allocation Buffer,TLAB )。哪个线程分配内存就在该线程的TLAB上分配，只有在TLAB用完需要分配新的TLAB时，才需要同步锁定。注：虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。 内存初始化&emsp;&emsp;内存分配完后，需要把将分配到的内存空间初始化为零值(不包换对象头)，如果使用TLAB这一过程也可以提前至TLAB分配时进行。这一步操作保证了对象实例字段在java代码中可以不赋初值就使用，程序能访问到这些字段的数据类型所对应的零值。 对象头必要设置&emsp;&emsp;接下来虚拟机要对对象进行必要的设置，比如该对象是哪个类的实例、如何才能找到类的元数据信息、对象的hash码、对象的gc分代年龄等信息。这些信息均放在对象的对象头(Object Header)中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置 总结以上步骤完成后，从虚拟机的角度来看，一个新对象诞生了，但从java程序角度看，一切才刚刚开始——init方法还没有执行，所有字段的数据类型都是对应的零值。所以一般来说执行new指令后会接着执行init方法，把对象按照程序猿的意愿进行初始化，这样一个真正可以使用的对象才算完成。 下面的代码是HotPot虚拟机bytecodeInterpreter.cpp的代码片段1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162u2 index = Bytes::get_Java_u2(pc+1);ConstantPool* constants = istate-&gt;method()-&gt;constants();// 确保常量池中是已经解释的类if (!constants-&gt;tag_at(index).is_unresolved_klass()) &#123; // Make sure klass is initialized and doesn't have a finalizer // 确保类已经初始化 Klass* entry = constants-&gt;slot_at(index).get_klass(); assert(entry-&gt;is_klass(), "Should be resolved klass"); Klass* k_entry = (Klass*) entry; assert(k_entry-&gt;oop_is_instance(), "Should be InstanceKlass"); InstanceKlass* ik = (InstanceKlass*) k_entry; // 确保对象内存已经初始化 if ( ik-&gt;is_initialized() &amp;&amp; ik-&gt;can_be_fastpath_allocated() ) &#123; // 取对象长度 size_t obj_size = ik-&gt;size_helper(); oop result = NULL; // If the TLAB isn't pre-zeroed then we'll have to do it // 如果TLAB没有预先初始化那么need_zero为true后边会进行初始化 bool need_zero = !ZeroTLAB; // 如果虚拟机启用TLAB，那么在TLAB中分配对象 if (UseTLAB) &#123; result = (oop) THREAD-&gt;tlab().allocate(obj_size); &#125; if (result == NULL) &#123; need_zero = true; // Try allocate in shared eden // 尝试在eden中分配对象retry: HeapWord* compare_to = *Universe::heap()-&gt;top_addr(); HeapWord* new_top = compare_to + obj_size; /*cmpxchg是x86中的CAS指令，这里是一个C++方法通过CAS方式分配空间，如果并发失败，转到retry中重试直至成功分配为止*/ if (new_top &lt;= *Universe::heap()-&gt;end_addr()) &#123; if (Atomic::cmpxchg_ptr(new_top, Universe::heap()-&gt;top_addr(), compare_to) != compare_to) &#123; goto retry; &#125; result = (oop) compare_to; &#125; &#125; if (result != NULL) &#123; // Initialize object (if nonzero size and need) and then the header // 如果需要，则为对象初始化零值 if (need_zero ) &#123; HeapWord* to_zero = (HeapWord*) result + sizeof(oopDesc) / oopSize; obj_size -= sizeof(oopDesc) / oopSize; if (obj_size &gt; 0 ) &#123; memset(to_zero, 0, obj_size * HeapWordSize); &#125; &#125; // 根据是否启用偏向锁来设置对象头信息 if (UseBiasedLocking) &#123; result-&gt;set_mark(ik-&gt;prototype_header()); &#125; else &#123; result-&gt;set_mark(markOopDesc::prototype()); &#125; result-&gt;set_klass_gap(0); result-&gt;set_klass(k_entry); // 将对象引用入栈，继续执行下一条指令 SET_STACK_OBJECT(result, 0); UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1); &#125; &#125;&#125; 相关文章：java虚拟机中对象的创建java虚拟机中对象的内存布局java虚拟机中对象的定位]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[幂等]]></title>
    <url>%2F2015%2F02%2F03%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F%E5%B9%82%E7%AD%89%2F</url>
    <content type="text"><![CDATA[再谈幂等机制一、什么是幂等性？幂等性(Idempotence)。在HTTP/1.1规范中幂等性的定义是： Methods can also have the property of “idempotence” in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request. 幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 二、为什么需要幂等那么我们为什么需要接口具有幂等性呢？设想一下以下情形： 在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。 在分布式环境中，网络环境更加复杂，因前端操作抖动、网络故障、消息重复、响应速度慢等原因，对接口的重复调用概率会比集中式环境下更大，尤其是重复消息在分布式环境中很难避免。 三、如何保证接口的幂等性接口的幂等性实际上就是接口可重复调用，在调用方多次调用的情况下，接口最终得到的结果是一致的。有些接口可以天然的实现幂等性，比如查询接口，对于查询来说，你查询一次和两次，对于系统来说，没有任何影响，查出的结果也是一样。 除了查询功能具有天然的幂等性之外，增加、更新、删除都要保证幂等性。那么如何来保证幂等性呢？ 3.1保证幂等策略 幂等需要通过唯一的业务单号来保证。也就是说相同的业务单号，认为是同一笔业务。使用这个唯一的业务单号来确保，后面多次的相同的业务单号的处理逻辑和执行效果是一致的。下面以支付为例，在不考虑并发的情况下，实现幂等很简单：①先查询一下订单是否已经支付过，②如果已经支付过，则返回支付成功；如果没有支付，进行支付流程，修改订单状态为‘已支付’。 3.2防重复提交策略 上述的保证幂等方案是分成两步的，第②步依赖第①步的查询结果，无法保证原子性的。在高并发下就会出现下面的情况：第二次请求在第一次请求第②步订单状态还没有修改为‘已支付状态’的情况下到来。既然得出了这个结论，余下的问题也就变得简单：把查询和变更状态操作加锁，将并行操作改为串行操作。 列举三种改进方式： 1、悲观锁，select for update，整个执行过程中锁定该订单对应的记录。 2、乐观锁，affectrows = db.update(“update payorder set state=’已支付’ where orderid=$orderid and state=’未支付’ “)，如果affectrows=1，执行充值，否则返回已处理。 3、定义防重复表，orderid为unique key或者primary key，执行前，先insert，若insert成功则执行充值，否则返回已处理 四、总结业务层设计协议时，要求请求方定义不重复的业务流水号。应用实现时，利用数据库乐观锁、插入unique key的日志等方式保证并发时的幂等。 幂等性把关环节，在协议设计评审中，评审重要业务RPC或者http接口是否支持幂等，代码评审中，重点把关请求并发时，是否仍旧能够保证幂等性。设计人员和具体实现人员在实现过程中，也应该时刻自审幂等性的实现是否过关。 最后介绍一下美团点评开发GTI（它是一个轻量的重复操作关卡系统，它能够确保在分布式环境中操作的唯一性。我们可以用它来间接保证每个操作的幂等性），感兴趣可以去研究一下】、]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2F2015%2F02%2F03%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html]]></content>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paxos算法]]></title>
    <url>%2F2015%2F02%2F03%2F%E5%88%86%E5%B8%83%E5%BC%8F%2FPaxos%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Paxos算法解决的问题正是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值（决议）达成一致。 Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。 一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。 Paxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner): Proposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。 Acceptor：参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。 Learner：不参与决策，从Proposers/Acceptors学习最新达成一致的提案（Value）。 在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。 Paxos算法通过一个决议分为两个阶段（Learn阶段之前决议已经形成）： 第一阶段：Prepare阶段。Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。 第二阶段：Accept阶段。Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。 第三阶段：Learn阶段。Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。 Paxos算法流程中的每条消息描述如下： Prepare: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。 Promise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。 两个承诺： 1. 不再接受Proposal ID小于等于（注意：这里是&lt;= ）当前请求的Prepare请求。 2. 不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Propose请求。 一个应答： 不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。 Propose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。 Accept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。 Learn: Proposer收到多数Acceptors的Accept后，决议形成，将形成的决议发送给所有Learners。]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nio系列教程]]></title>
    <url>%2F2015%2F02%2F03%2Fnio%2Fnio%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[http://tutorials.jenkov.com/java-nio/nio-vs-io.htmlhttp://www.iteye.com/magazines/132-Java-NIO]]></content>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程图谱]]></title>
    <url>%2F2015%2F02%2F03%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F%E5%9B%BE%E8%B0%B1%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2015%2F01%2F31%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[java静态代理和动态代理 代理的优点 职责清晰 真实的角色就是实现实际的业务逻辑，不用关心其他非本职责的事务，通过后期的代理完成一件完成事务，附带的结果就是编程简洁清晰。 代理对象可以在客户端和目标对象之间起到中介的作用，这样起到了中介的作用和保护了目标对象的作用。 高扩展性，可以在代理方法前后增加额外的处理逻辑。 被代理的对象一个接口123public interface Subject &#123; void doSomething();&#125; 它的实现类1234567public class SubjectImpl implements Subject &#123; @Override public void doSomething() &#123; System.out.println( "call doSomething()" ); &#125;&#125; 静态代理静态代理是由程序员创建或工具生成代理类的源码，再编译代理类。也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。缺点是被代理对象和代理紧耦合在一起。而且代理类都是针对被代理类创建的。12345678910public class SubjectProxy implements Subject &#123; Subject subject = new SubjectImpl(); @Override public void doSomething() &#123; System.out.println("before"); //调用目标对象之前可以做相关操作 subject.doSomething(); System.out.println("after");//调用目标对象之后可以做相关操作 &#125;&#125; 动态代理动态代理在运行阶段才指定被代理的对象，通过实现InvocationHandler接口，调用具体的方法。123456789101112131415161718public class ProxyHandler implements InvocationHandler &#123; private Object tar; public Object bind(Object tar) &#123; this.tar = tar; return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; System.out.println("before"); //调用目标对象之前可以做相关操作 result = method.invoke(tar, args); System.out.println("after");//调用目标对象之后可以做相关操作 return result; &#125;&#125; 运行12345678public class Test &#123; public static void main(String[] args) &#123; ProxyHandler proxy = new ProxyHandler(); //绑定该类实现的所有接口 Subject sub = (Subject) proxy.bind(new SubjectImpl()); sub.doSomething(); &#125;&#125;]]></content>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
</search>
